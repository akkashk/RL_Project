{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from queue import Queue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_literal = lambda x: x[1:] if x.startswith('-') else '-'+x\n",
    "deepcopy = lambda x: pickle.loads(pickle.dumps(x))\n",
    "\n",
    "def parse_input(input_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    literal_clauseNum: {Literal: Set of clause numbers that are still in consideration for this variable}                        \n",
    "    \n",
    "    clauseNum_clause: {Clause number: Set of literals that could still satisfy this clause}\n",
    "    \n",
    "    literal_boolen: {Literal: boolean on whether literal set of True/False/None, None meaning could be either, doesn't matter}\n",
    "    \n",
    "    input_file:\n",
    "    c DIMACS CNF: conjunction/AND of one or more clauses, where a clause is a disjunction/OR of literals\n",
    "    c Comments start with a c, First lines begins with p and describes the probelm and all clause lines end with a 0\n",
    "    c Can't have same variable in both forms in same clause. So A ~A is not allowed. Can have them in separate clauses.\n",
    "                        \n",
    "    \"\"\"\n",
    "\n",
    "    all_clauses = []  # List of all clauses that appear in input. Used for SAT checking the mapping given by DPLL\n",
    "\n",
    "    literal_clauseNum = defaultdict(set)\n",
    "\n",
    "    def filler():\n",
    "        return None\n",
    "\n",
    "    literal_boolen = defaultdict(filler)\n",
    "\n",
    "    clauseNum_clause = {}\n",
    "\n",
    "    clause_counter = 0\n",
    "\n",
    "    with open(input_file, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            # Do checks on comments\n",
    "            if line.startswith('c') or line.startswith('p') or line.startswith('0') or line.startswith('%'):\n",
    "                continue\n",
    "            if len(line) > 0:\n",
    "                clause = []\n",
    "                clause_counter += 1\n",
    "                for literal in line.split():\n",
    "                    if literal == '0':\n",
    "                        # End of line, ignore in DIMACS CNF format\n",
    "                        continue\n",
    "                    clause.append(literal)\n",
    "                    literal_clauseNum[literal].add(clause_counter)\n",
    "                clauseNum_clause[clause_counter] = set(clause)\n",
    "                all_clauses.append(clause)\n",
    "\n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen, all_clauses\n",
    "\n",
    "def unit_prop(literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    keep_updating = True\n",
    "    while keep_updating:\n",
    "        keep_updating = False # Assuming we've found all unit clauses\n",
    "        for clauseNum in list(clauseNum_clause.keys()):\n",
    "            if clauseNum not in clauseNum_clause:\n",
    "                continue\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            # Clause contains the remaining literals that could potentially satisfy this clause. \n",
    "            if len(clause) == 0:\n",
    "                # Empty clause, so need to return True for empty clause detected\n",
    "                return True, None, None, None\n",
    "            if len(clause) > 1:\n",
    "                # Can't do unit prop \n",
    "                continue\n",
    "\n",
    "            literal = clause.pop()  # Needs to be set to True\n",
    "            clause.add(literal)  # Removed later\n",
    "            literal_boolen[literal] = True\n",
    "            keep_updating = True  # Since we found one unit clause, maybe more\n",
    "\n",
    "    #         print(literal)\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "\n",
    "            # For all clauses that have this literal, they have been satisfied now\n",
    "            # 1) Gather all pairs of (literals, clauseNum) that appear in these clauses so we can remove them from literal_clauseNum\n",
    "            # 2) Delete these clauses from clauseNum_clause\n",
    "            pairs_to_delete = []\n",
    "            for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "                for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "                    pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "    #         print(pairs_to_delete)\n",
    "\n",
    "            for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "                literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "                if clauseNums_with_literal in clauseNum_clause:\n",
    "                    del clauseNum_clause[clauseNums_with_literal]\n",
    "\n",
    "            # For all the clauses with opposite literal, remove the literal from the clause\n",
    "            if switch_literal(literal) not in literal_clauseNum: # if the opposite variable doesn't exist, skip\n",
    "                continue\n",
    "\n",
    "            opposite_literal = switch_literal(literal)\n",
    "            literal_boolen[opposite_literal] = False\n",
    "\n",
    "            for clauseNums_with_literal in literal_clauseNum[opposite_literal]:\n",
    "                clauseNum_clause[clauseNums_with_literal].discard(opposite_literal)\n",
    "\n",
    "            literal_clauseNum[opposite_literal] = set()  # It is not watching any clauses anymore\n",
    "\n",
    "    #         print(\"OPPO\")\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "        \n",
    "    return False, literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "\n",
    "def pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    for literal in list(literal_clauseNum.keys()):\n",
    "        if literal in literal_boolen:\n",
    "            continue\n",
    "        \n",
    "        opposite_literal = switch_literal(literal)\n",
    "        if opposite_literal not in literal_boolen: # The opposite variable has not been assigned yet\n",
    "            # If it doesn't exist or it does but it doesn't have to satisfy any clauses\n",
    "            if opposite_literal not in literal_clauseNum or len(literal_clauseNum[opposite_literal]) == 0:\n",
    "                # LITERAL IS A PURE LITERAL\n",
    "                literal_boolen[literal] = True\n",
    "                \n",
    "                # All the clauses that literal exists in has been made true, so remove the clauses and make literal watch no clause\n",
    "                pairs_to_delete = []\n",
    "                for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "                    for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "                        pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "        #         print(pairs_to_delete)\n",
    "\n",
    "                for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "                    literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "                    if clauseNums_with_literal in clauseNum_clause:\n",
    "                        del clauseNum_clause[clauseNums_with_literal]\n",
    "                        \n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "\n",
    "def maxo(literal_clauseNum, return_counts=False):\n",
    "    \"\"\"\n",
    "    Returns the literal that appears in the most number of clauses\n",
    "    \"\"\"\n",
    "    literal_count = defaultdict(int)\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        literal_count[literal] = len(clauseNums)\n",
    "    if return_counts:\n",
    "        return literal_count\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in literal_count.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def moms(literal_clauseNum, clauseNum_clause, return_counts=False):\n",
    "    \"\"\"\n",
    "    Returns the literal that appears most in the smallest clauses\n",
    "    \"\"\"\n",
    "    # Select the clausesNumbers for clauses of the smaller size\n",
    "    least_size = min(map(len, clauseNum_clause.values()))\n",
    "    literal_count = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            if len(clauseNum_clause[clauseNum]) == least_size:\n",
    "                # Each time a literal appears in a least-size clause we \n",
    "                # increment counter by 1\n",
    "                literal_count[literal] += 1\n",
    "    \n",
    "    if return_counts:\n",
    "        return literal_count\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in literal_count.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def mams(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Combines MAXO and MOMS count statistics from above and chooses the literal that appears most between them\n",
    "    \"\"\"\n",
    "    maxo_ans = maxo(literal_clauseNum, return_counts=True)\n",
    "    moms_ans = moms(literal_clauseNum, clauseNum_clause, return_counts=True)\n",
    "    \n",
    "    # MAXO would return the dict with most keys\n",
    "    for literal in maxo_ans:\n",
    "        maxo_ans[literal] += moms_ans[literal]\n",
    "        # Since using defaultdict we add 0 if literal not in moms_ans\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in maxo_ans.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    \n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def jw(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Jeroslow-Wang Rule\n",
    "    \"\"\"\n",
    "    literal_score = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            literal_score[literal] += 2 ** -len(clause)\n",
    "    \n",
    "    max_lit = None\n",
    "    max_score = 0\n",
    "    for literal, score in literal_score.items():\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_lit = literal\n",
    "            \n",
    "    return max_lit, max_score\n",
    "\n",
    "def jw_2(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    2-sided JW rule. See Heutistics folder\n",
    "    \"\"\"\n",
    "    \n",
    "    literal_score = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            literal_score[literal] += 2 ** -len(clause)\n",
    "    \n",
    "    max_lit = None\n",
    "    max_score = 0\n",
    "    for literal, score in list(literal_score.items()):\n",
    "        other_literal = switch_literal(literal)\n",
    "        total_score = score + literal_score[other_literal]\n",
    "        \n",
    "        if total_score > max_score:\n",
    "            max_score = score\n",
    "            max_lit = literal if score >= literal_score[other_literal] else other_literal\n",
    "            \n",
    "    return max_lit, max_score\n",
    "    \n",
    "    \n",
    "\n",
    "def bohm(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    See Heuristics folder. Lexicographic order of the vector (H1(x), H2(x), ..., Hn(x)) means we first choose highest H1(x)\n",
    "    variable. When tied we then choose amongst tied variable highest H2 variable. When tied then H3 and so on.\n",
    "    \n",
    "    We've had to manage edge cases here but don't mention that in report. Only give formula from paper\n",
    "    \"\"\"\n",
    "    pos_literal_count = defaultdict(lambda: [0, 0, 0])  # This default initialisation only works for 3 SAT\n",
    "    neg_literal_count = defaultdict(lambda: [0, 0, 0])\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if literal.startswith('-'):\n",
    "            for clauseNum in clauseNums:\n",
    "                clause = clauseNum_clause[clauseNum]\n",
    "                neg_literal_count[literal][len(clause)-1] += 1\n",
    "        else:\n",
    "            for clauseNum in clauseNums:\n",
    "                clause = clauseNum_clause[clauseNum]\n",
    "                pos_literal_count[literal][len(clause)-1] += 1\n",
    "                \n",
    "    final_count = []\n",
    "    # Sometimes we only have negative literals left. So then we just use those\n",
    "    for literal, pos_counts in (pos_literal_count.items() or neg_literal_count.items()):\n",
    "        other_literal = switch_literal(literal)\n",
    "        \n",
    "        if literal.startswith('-'):\n",
    "            # pos_literal_counts is empty. So literal and pos_counts actually are neg_literal_counts\n",
    "            neg_counts = pos_literal_count[other_literal]\n",
    "        else:\n",
    "            # pos_literal_counts isn't empty. So continue as normal\n",
    "            neg_counts = neg_literal_count[other_literal]\n",
    "        \n",
    "        final_count.append(([max(p, n) + 2 * min(p, n) for p, n in zip(pos_counts, neg_counts)], literal))\n",
    "            \n",
    "    final_count.sort(reverse=True)\n",
    "    score_vector, literal = final_count[0]\n",
    "    other_literal = switch_literal(literal)\n",
    "    \n",
    "    if literal.startswith('-'):\n",
    "        neg_literal = literal\n",
    "        pos_literal = other_literal\n",
    "    else:\n",
    "        neg_literal = other_literal\n",
    "        pos_literal = literal\n",
    "    \n",
    "    # Since the score for positive and negative literal is the same, choose one which the highest overall score\n",
    "    if sum(pos_literal_count[pos_literal]) >= sum(neg_literal_count[neg_literal]):\n",
    "        literal = pos_literal\n",
    "    else:\n",
    "        literal = neg_literal\n",
    "    \n",
    "    return literal, score_vector\n",
    "    \n",
    "\n",
    "def set_var(literal, boolean, literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    literal_boolen[literal] = boolean\n",
    "\n",
    "    if boolean == False:\n",
    "        literal = switch_literal(literal)\n",
    "        literal_boolen[literal] = True\n",
    "    \n",
    "    # Unit-prop logic below\n",
    "    pairs_to_delete = []\n",
    "    for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "        for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "            pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "    #         print(pairs_to_delete)\n",
    "\n",
    "    for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "        literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "        if clauseNums_with_literal in clauseNum_clause:\n",
    "            del clauseNum_clause[clauseNums_with_literal]\n",
    "\n",
    "    # For all the clauses with opposite literal, remove the literal from the clause\n",
    "    if switch_literal(literal) not in literal_clauseNum: # if the opposite variable doesn't exist, skip\n",
    "        return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "    opposite_literal = switch_literal(literal)\n",
    "    literal_boolen[opposite_literal] = False\n",
    "\n",
    "    for clauseNums_with_literal in literal_clauseNum[opposite_literal]:\n",
    "        clauseNum_clause[clauseNums_with_literal].discard(opposite_literal)\n",
    "\n",
    "    literal_clauseNum[opposite_literal] = set()  # It is not watching any clauses anymore\n",
    "\n",
    "    #         print(\"OPPO\")\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "    \n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "def choose_var(literal_clauseNum, clauseNum_clause, literal_boolen, algo='maxo'):\n",
    "    # Choosing the first literal every time\n",
    "#     remaining_clauses = list(clauseNum_clause.values())\n",
    "#     literal = remaining_clauses[0].pop()\n",
    "#     remaining_clauses[0].add(literal)\n",
    "\n",
    "    # Using heuristics\n",
    "    if algo == 'maxo':\n",
    "        literal, _ = maxo(literal_clauseNum)\n",
    "    elif algo == 'moms':\n",
    "        literal, _ = moms(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'mams':\n",
    "        literal, _ = mams(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'jw':\n",
    "        literal, _ = jw(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'jw_2':\n",
    "        literal, _ = jw_2(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'bohm':\n",
    "        literal, _ = bohm(literal_clauseNum, clauseNum_clause)\n",
    "    \n",
    "\n",
    "    return literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('14', 0.75)\n",
      "('3', 0.25)\n",
      "('-10', 1.375)\n",
      "('15', 0.5)\n",
      "('18', 0.25)\n",
      "('12', 0.75)\n",
      "('12', 0.75)\n",
      "('-12', 1.75)\n",
      "('15', 0.5)\n",
      "('-10', 1.375)\n",
      "('10', 0.625)\n",
      "('3', 0.125)\n",
      "('15', 0.75)\n",
      "('18', 0.25)\n",
      "('-12', 1.375)\n",
      "('15', 1.0)\n",
      "('3', 0.375)\n",
      "('15', 0.75)\n",
      "('18', 0.25)\n",
      "('-12', 1.75)\n",
      "('15', 1.0)\n",
      "('3', 0.5)\n",
      "('14', 1.0)\n",
      "('-10', 1.625)\n",
      "('15', 0.625)\n",
      "('18', 0.75)\n",
      "('-18', 1.25)\n",
      "('15', 0.625)\n",
      "('10', 0.875)\n",
      "('15', 0.875)\n",
      "('15', 0.875)\n",
      "('18', 0.75)\n",
      "('-16', 0.75)\n",
      "('10', 1.0)\n",
      "('-14', 1.0)\n",
      "('-15', 1.25)\n",
      "('-15', 1.0)\n",
      "('15', 1.125)\n",
      "('14', 1.0)\n",
      "('-2', 0.5)\n"
     ]
    }
   ],
   "source": [
    "env = Env('../Tests/SATLIB_20/uf20-0435.cnf')\n",
    "env.reset()\n",
    "while True:\n",
    "    _, _, done = env.step(4)\n",
    "    if done:\n",
    "        break\n",
    "    a, b, c = env.state\n",
    "    print(jw_2(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that are used by the Env class to get state features\n",
    "\n",
    "def number_of_variables(literal_clauseNum):\n",
    "    \"\"\" Returns the number of total variables (including repeats) present in the remaining clauses \"\"\"\n",
    "    return sum(map(len, literal_clauseNum.values()))\n",
    "\n",
    "\n",
    "def horn_clause_ratio(clauseNum_clause):\n",
    "    \"\"\" Returns the ratio of horn clauses to total number of clauses \"\"\"\n",
    "    horn_count = 0\n",
    "    total_count = 0\n",
    "    for clause in clauseNum_clause.values():\n",
    "        if len(clause) > 0:\n",
    "            total_count += 1\n",
    "        if len(list(filter(lambda x: not x.startswith('-'), clause))) == 1:\n",
    "            horn_count = 0\n",
    "\n",
    "    return horn_count / total_count if total_count > 0 else 0\n",
    "\n",
    "\n",
    "def clause_to_variable_ratio(literal_clauseNum):\n",
    "    \"\"\" Returns the clause to variable ratio: c/v which predict problem hardness \"\"\"\n",
    "    clauses = set()\n",
    "    num_literals = 0\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if len(clauseNums) > 0:\n",
    "            clauses = clauses.union(clauseNums)\n",
    "            if literal.startswith('-'):\n",
    "                num_literals += 1\n",
    "            else:\n",
    "                num_literals += 1\n",
    "\n",
    "    return 0 if num_literals == 0 else len(clauses) / num_literals\n",
    "\n",
    "\n",
    "def pos_neg_ratio(literal_clauseNum):\n",
    "    \"\"\"\n",
    "    Returns the number of positive literals (incl repeats) to negative literals (incl repeats) in the clauses.\n",
    "    THIS DOESN'T GIVE USEFUL STATE INFORMATION\n",
    "    \"\"\"\n",
    "    pos_literal_count = 0\n",
    "    neg_literal_count = 0\n",
    "\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if literal.startswith('-'):\n",
    "            neg_literal_count += len(clauseNums)\n",
    "        else:\n",
    "            pos_literal_count += len(clauseNums)\n",
    "\n",
    "    return pos_literal_count / neg_literal_count if neg_literal_count > 0 else pos_literal_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    def __init__(self, input_file):\n",
    "        self.input_file = input_file\n",
    "        self.stack = [] # We use a stack to hold the next states to explore. i.e. we do DFS as less memory requirements than BFS\n",
    "        self.state = None\n",
    "        self.actions = {0: 'maxo', 1: 'moms', 2: 'mams', 3: 'jw', 4: 'jw_2', 5: 'bohm'}\n",
    "    \n",
    "    def reset(self):\n",
    "        # Returns state\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen, _ = parse_input(self.input_file)\n",
    "        self.state = (literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        \"\"\" Returns a single number which we turn into a polynomial inside Estimator \"\"\"\n",
    "        \n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = self.state\n",
    "        num_var = number_of_variables(literal_clauseNum)\n",
    "        horn_clause = horn_clause_ratio(clauseNum_clause)\n",
    "        c_v_ratio = clause_to_variable_ratio(literal_clauseNum)\n",
    "        return [num_var, horn_clause, c_v_ratio]\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns: next_state_1, next_state_2, reward, done\n",
    "        reward = 0 if reached a leaf node, 0 if not\n",
    "        \"\"\"\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = self.state\n",
    "        \n",
    "        unassigned_nodes_start = len(list(filter(lambda x: len(x) > 0, literal_clauseNum.values())))\n",
    "        \n",
    "        # Do unit prop\n",
    "        empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \\\n",
    "            unit_prop(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "        if empty_clause:\n",
    "            isEmpty = len(self.stack) == 0\n",
    "            if not isEmpty:\n",
    "                self.state = self.stack.pop()\n",
    "            return 0, -1, isEmpty\n",
    "        \n",
    "        if clauseNum_clause == {}:\n",
    "            return 0, 0, True\n",
    "        \n",
    "        # Do pure literal elimination\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = \\\n",
    "            pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "        if clauseNum_clause == {}:\n",
    "            return 0, 0, True\n",
    "        \n",
    "        literal = choose_var(literal_clauseNum, clauseNum_clause, literal_boolen, algo=self.actions[action])\n",
    "        \n",
    "        # Set the chosen literal to be True\n",
    "        literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T = \\\n",
    "            set_var(literal, True, deepcopy(literal_clauseNum), deepcopy(clauseNum_clause), dict(literal_boolen))\n",
    "            \n",
    "#         print(\"After setting\", literal, \"to True\")\n",
    "#         print(literal_clauseNum_T)\n",
    "#         print(literal_boolen_T)\n",
    "#         print()\n",
    "        \n",
    "#         unassigned_nodes_T = len(filter(lambda x: len(x) > 0, literal_clauseNum_T.values()))\n",
    "        \n",
    "#         # Do unit prop and pure literal elimnation and record the number of nodes assigned\n",
    "#         empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             unit_prop(literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T)\n",
    "        \n",
    "#         if empty_clause:\n",
    "#             return 0, 0, unassigned_nodes_start, self.q.empty()\n",
    "        \n",
    "#         # Do pure literal elimination\n",
    "#         literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         if clauseNum_clause == {}:\n",
    "#             return 0, 0, unassigned_nodes_start, True\n",
    "        \n",
    "        # Set new state\n",
    "        self.state = (literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T)\n",
    "        \n",
    "        # Set the chosen literal to be False\n",
    "        literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F = \\\n",
    "            set_var(literal, False, literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         print(\"After setting\", literal, \"to False\")\n",
    "#         print(literal_clauseNum_F)\n",
    "#         print(literal_boolen_F)\n",
    "#         print()\n",
    "            \n",
    "#         unassigned_nodes_F = len(filter(lambda x: len(x) > 0, literal_clauseNum_F.values()))\n",
    "            \n",
    "#         # Do unit prop and pure literal elimnation and record the number of nodes assigned\n",
    "#         empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             unit_prop(literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F)\n",
    "        \n",
    "#         if empty_clause:\n",
    "#             return 0, 0, unassigned_nodes_start, self.q.empty()\n",
    "        \n",
    "#         # Do pure literal elimination\n",
    "#         literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         if clauseNum_clause == {}:\n",
    "#             return 0, 0, unassigned_nodes_start, True\n",
    "\n",
    "        # Add new state to queue\n",
    "        self.stack.append((literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F))\n",
    "        \n",
    "        # return get_state_representation(literal_clauseNum_T), get_state_representation(literal_clauseNum_F), -1, False\n",
    "        return None, -1, False\n",
    "        # Using unassigned_nodes_start - unassigned_nodes_end as cost has been > 0 in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Estimator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # We create a separate model for each action in the environment's\n",
    "        # action space. Alternatively we could somehow encode the action\n",
    "        # into the features, but this way it's easier to code up.\n",
    "        self.models = []\n",
    "        for _ in range(actions):\n",
    "            model = SGDRegressor(learning_rate=\"constant\", eta0=0.001, penalty='l2')\n",
    "            # We need to call partial_fit once to initialize the model\n",
    "            # or we get a NotFittedError when trying to make a prediction\n",
    "            # This is quite hacky.\n",
    "            model.partial_fit([self.featurize_state(np.zeros(state_space))], [0])\n",
    "            self.models.append(model)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit([self.featurize_state(np.zeros(state_space))], [np.zeros(state_space)])\n",
    "    \n",
    "    def featurize_state(self, state):\n",
    "        # Needs to return a 1D array\n",
    "        if use_poly:\n",
    "            state = int(state)\n",
    "            return np.array([state**i for i in range(1, poly_degree+1)])\n",
    "        else:\n",
    "            return np.array(state)\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state_feature = self.featurize_state(state)\n",
    "        state_feature = self.scaler.transform([state_feature]) # Returns a 2D array\n",
    "        return np.array([m.predict(state_feature)[0] for m in self.models])\n",
    "    \n",
    "    def update(self, state, action, reward):\n",
    "        model = self.models[action]\n",
    "        state_feature = self.featurize_state(state)\n",
    "        \n",
    "        self.scaler.partial_fit([state_feature])\n",
    "        state_feature = self.scaler.transform([state_feature]) # Returns a 2D array\n",
    "        model.partial_fit(state_feature, [reward])\n",
    "        \n",
    "#         print(\"After update:\", model.predict(state_feature)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "    \n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        epsilon: The probability to select a random action . float between 0 and 1.\n",
    "        nA: Number of actions in the environment.\n",
    "    \n",
    "    Returns:\n",
    "        A function that takes the observation as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "    \n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        if epsilon > np.random.rand():\n",
    "            return np.ones(nA) / nA\n",
    "        else:\n",
    "            action_value = estimator.predict(observation)\n",
    "            action = np.argmax(action_value)\n",
    "            ans = np.zeros(nA)\n",
    "            ans[action] = 1\n",
    "            return ans\n",
    "\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, estimator, discount_factor=1.0, epsilon=0.1, epsilon_decay=1.0, train_phase=True):\n",
    "    \"\"\"\n",
    "    Goes through the environment only once (stops when we reach a finishing state in the environment)\n",
    "    \"\"\"\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "    \n",
    "#     policy = make_epsilon_greedy_policy(estimator, epsilon * epsilon_decay**i_episode, actions)\n",
    "#     Since we do not iterate over in q_learning, we do not have i_episode above. See if that is useful here and below (near end)\n",
    "    policy = make_epsilon_greedy_policy(estimator, epsilon*epsilon_decay, actions)\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "#         action_prob = policy(state)\n",
    "#         action = np.random.choice(np.arange(len(action_prob)), p=action_prob)\n",
    "        action = 4\n",
    "        _, reward, done = env.step(action)\n",
    "        \n",
    "        # Stats\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "#             td_target = reward\n",
    "#             if train_phase:\n",
    "#                 estimator.update(state, action, td_target)\n",
    "            break\n",
    "\n",
    "#         next_state = env.get_state()\n",
    "\n",
    "#         q_values = estimator.predict(next_state)\n",
    "#         td_target = reward + discount_factor * np.max(q_values)\n",
    "        \n",
    "#         current_value = estimator.predict(state)[action]\n",
    "#         td_error = td_target - current_value\n",
    "        \n",
    "#         alpha = 0.8\n",
    "#         update_target = current_value + alpha*td_error\n",
    "#         if train_phase:\n",
    "#             estimator.update(state, action, update_target)\n",
    "\n",
    "#         state = next_state\n",
    "\n",
    "    return episode_reward, episode_length, estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(training_files, epochs, ϵ):\n",
    "    \"\"\"\n",
    "    One episode is one file. Each call to q_learning function does one episode only and returns. \n",
    "    An Env can be instantiated with one file only, so can only do one episode.\n",
    "    \n",
    "    In one epoch, you go through all the files in your training dataset.\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length = [], []\n",
    "    estimator = Estimator()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "        \n",
    "        # shuffle(training_files)  # Shuffles files in-place\n",
    "\n",
    "        for j, filepath in enumerate(training_files):\n",
    "            \"\"\" Each file in one episode \"\"\"\n",
    "            \n",
    "            if j % 100 == 0:\n",
    "                print(j)\n",
    "            \n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length, estimator = q_learning(env, estimator, epsilon=ϵ)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "            \n",
    "        # Average reward per episode in this epoch\n",
    "        epoch_reward.append(curr_epoch_reward / len(training_files))\n",
    "\n",
    "        # Average length of each episode in this epoch\n",
    "        epoch_length.append(curr_epoch_length / len(training_files))\n",
    "            \n",
    "    return epoch_reward, epoch_length, estimator\n",
    "\n",
    "\n",
    "def test(test_files, epochs=10, ϵ=1.1, estimator=None):\n",
    "    \"\"\"\n",
    "    This method is used to either:\n",
    "    \n",
    "     - Run a random policy on the test data and returns the avg. reward and length per epoch (epoch runs over the test_files).\n",
    "     This can be done by only passing on first two parameters (and optionally epochs for longer runs)\n",
    "     \n",
    "     - Run an epilon-greedy policy with the given estimator. Pass an estimator that we receive from the train() method and set \n",
    "     the ϵ value appropriately to make an epsilon-greedy policy. Runs this policy over the test_files for given number of epochs.\n",
    "    \n",
    "    Returns dictionary of {epoch: average reward} and {epoch: average length per episode/file}\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length = [], []\n",
    "    \n",
    "    if estimator is None:\n",
    "        estimator = Estimator()  # Never used if epsilon > 1 \n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "\n",
    "        shuffle(test_files)\n",
    "        \n",
    "        for filepath in test_files:\n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length, _ = q_learning(env, estimator, epsilon=ϵ, train_phase=False)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "            \n",
    "        # Average reward per training example in this epoch\n",
    "        epoch_reward.append(curr_epoch_reward / len(test_files))\n",
    "\n",
    "        # Average episode length per example in this epoch\n",
    "        epoch_length.append(curr_epoch_length / len(test_files))\n",
    "            \n",
    "            \n",
    "    return epoch_reward, epoch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 1000\n",
      "Number of test files: 0\n",
      "Epoch Number: 1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akkash/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "# import time\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "use_poly = False  # Set this to True if you want the Estimator to change state to a polynomial. State must be a single number.\n",
    "poly_degree = 7   # Degree of polynomial is use_poly is set to True\n",
    "actions = 6       # Number of actions available to use by the agent\n",
    "state_space = 3   # Number of variables we return as state of environment. Used to initialise Scaler and SGD in Estimator\n",
    "\n",
    "directory = '../Tests/SATLIB_50/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "files = os.listdir(directory)\n",
    "files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "# shuffle(files)\n",
    "\n",
    "split = int(len(files) * 1.0)\n",
    "training_files = files[:split]\n",
    "test_files = files[split:]\n",
    "\n",
    "print(\"Number of training files:\", len(training_files))\n",
    "print(\"Number of test files:\", len(test_files))\n",
    "\n",
    "episode_reward_train, episode_length_train, estimator = train(training_files, epochs=1, ϵ=0.1)\n",
    "print(\"Done training\")\n",
    "print()\n",
    "\n",
    "# episode_reward_test, episode_length_test = test(test_files, epochs=2, ϵ=0.1, estimator=estimator)\n",
    "# print(\"Done testing\")\n",
    "# print()\n",
    "\n",
    "# episode_reward_rand, episode_length_rand = test(test_files, epochs=2)\n",
    "# print(\"Done testing random policy\")\n",
    "\n",
    "\n",
    "# e = time.time()\n",
    "# print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for last 10 epochs in training: -199.731\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(episode_reward_train, label='Training')\n",
    "# plt.plot(episode_reward_test, label='Testing')\n",
    "# plt.plot(episode_reward_rand, label='Testing rand')\n",
    "\n",
    "# plt.xlabel('Epoch number')\n",
    "# plt.ylabel('Average reward per epoch')\n",
    "# plt.legend()\n",
    "\n",
    "last_n = 10\n",
    "train_avg = np.mean(np.array(episode_reward_train)[-last_n:])\n",
    "# test_avg = np.mean(np.array(episode_reward_test)[-last_n:])\n",
    "# rand_avg = np.mean(np.array(episode_reward_rand)[-last_n:])\n",
    "\n",
    "print(\"Average reward for last\", last_n, \"epochs in training:\", round(train_avg, 3))\n",
    "# print(\"Average reward for last\", last_n, \"epochs in testing:\", round(test_avg, 3))\n",
    "# print(\"Average reward for last\", last_n, \"epochs in testing random policy:\", round(rand_avg, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'episode_length_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2a60bd07ca57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_length_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_length_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Testing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_length_rand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Testing rand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'episode_length_test' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHpJapxBL0mNM+glqXH/B8t+lcrNvOXrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffaa9aa1cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_length_train, label='Training')\n",
    "plt.plot(episode_length_test, label='Testing')\n",
    "plt.plot(episode_length_rand, label='Testing rand')\n",
    "\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Average episode length per epoch')\n",
    "plt.legend()\n",
    "\n",
    "train_avg = np.mean(np.array(episode_length_train)[-last_n:])\n",
    "test_avg = np.mean(np.array(episode_length_test)[-last_n:])\n",
    "rand_avg = np.mean(np.array(episode_length_rand)[-last_n:])\n",
    "\n",
    "print(\"Average length for last\", last_n, \"epochs in training:\", round(train_avg, 3))\n",
    "print(\"Average length for last\", last_n, \"epochs in testing:\", round(test_avg, 3))\n",
    "print(\"Average length for last\", last_n, \"epochs in testing random policy:\", round(rand_avg, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f61de218080>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlYSTvhmZiXx/1+F86toSK61AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61de3a88d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(0, 2.5, 100) \n",
    "# xs = range(300)\n",
    "\n",
    "policy = make_epsilon_greedy_policy(estimator, 0.1, actions)\n",
    "ys = [np.random.choice(np.arange(actions), p=policy(i)) for i in xs]\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Action - between 0/1/2/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183.14029739, 191.53904755, 802.91524697, 210.98955766,\n",
       "       237.46574782, 209.91730567])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = 5\n",
    "\n",
    "estimator.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f61de00dba8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61dde6c438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(10, 12))\n",
    "\n",
    "q_values = np.array([estimator.predict(s) for s in xs])\n",
    "\n",
    "for i in range(actions):\n",
    "    plt.plot(xs, q_values[:, i], label='Action '+str(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Q-value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
