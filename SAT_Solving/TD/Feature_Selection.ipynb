{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from queue import Queue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from random import shuffle\n",
    "from itertools import combinations\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_literal = lambda x: x[1:] if x.startswith('-') else '-'+x\n",
    "deepcopy = lambda x: pickle.loads(pickle.dumps(x))\n",
    "\n",
    "def parse_input(input_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    literal_clauseNum: {Literal: Set of clause numbers that are still in consideration for this variable}                        \n",
    "    \n",
    "    clauseNum_clause: {Clause number: Set of literals that could still satisfy this clause}\n",
    "    \n",
    "    literal_boolen: {Literal: boolean on whether literal set of True/False/None, None meaning could be either, doesn't matter}\n",
    "    \n",
    "    input_file:\n",
    "    c DIMACS CNF: conjunction/AND of one or more clauses, where a clause is a disjunction/OR of literals\n",
    "    c Comments start with a c, First lines begins with p and describes the probelm and all clause lines end with a 0\n",
    "    c Can't have same variable in both forms in same clause. So A ~A is not allowed. Can have them in separate clauses.\n",
    "                        \n",
    "    \"\"\"\n",
    "\n",
    "    all_clauses = []  # List of all clauses that appear in input. Used for SAT checking the mapping given by DPLL\n",
    "\n",
    "    literal_clauseNum = defaultdict(set)\n",
    "\n",
    "    def filler():\n",
    "        return None\n",
    "\n",
    "    literal_boolen = defaultdict(filler)\n",
    "\n",
    "    clauseNum_clause = {}\n",
    "\n",
    "    clause_counter = 0\n",
    "\n",
    "    with open(input_file, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            # Do checks on comments\n",
    "            if line.startswith('c') or line.startswith('p') or line.startswith('0') or line.startswith('%'):\n",
    "                continue\n",
    "            if len(line) > 0:\n",
    "                clause = []\n",
    "                clause_counter += 1\n",
    "                for literal in line.split():\n",
    "                    if literal == '0':\n",
    "                        # End of line, ignore in DIMACS CNF format\n",
    "                        continue\n",
    "                    clause.append(literal)\n",
    "                    literal_clauseNum[literal].add(clause_counter)\n",
    "                clauseNum_clause[clause_counter] = set(clause)\n",
    "                all_clauses.append(clause)\n",
    "\n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen, all_clauses\n",
    "\n",
    "def unit_prop(literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    keep_updating = True\n",
    "    while keep_updating:\n",
    "        keep_updating = False # Assuming we've found all unit clauses\n",
    "        for clauseNum in list(clauseNum_clause.keys()):\n",
    "            if clauseNum not in clauseNum_clause:\n",
    "                continue\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            # Clause contains the remaining literals that could potentially satisfy this clause. \n",
    "            if len(clause) == 0:\n",
    "                # Empty clause, so need to return True for empty clause detected\n",
    "                return True, None, None, None\n",
    "            if len(clause) > 1:\n",
    "                # Can't do unit prop \n",
    "                continue\n",
    "\n",
    "            literal = clause.pop()  # Needs to be set to True\n",
    "            clause.add(literal)  # Removed later\n",
    "            literal_boolen[literal] = True\n",
    "            keep_updating = True  # Since we found one unit clause, maybe more\n",
    "\n",
    "    #         print(literal)\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "\n",
    "            # For all clauses that have this literal, they have been satisfied now\n",
    "            # 1) Gather all pairs of (literals, clauseNum) that appear in these clauses so we can remove them from literal_clauseNum\n",
    "            # 2) Delete these clauses from clauseNum_clause\n",
    "            pairs_to_delete = []\n",
    "            for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "                for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "                    pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "    #         print(pairs_to_delete)\n",
    "\n",
    "            for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "                literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "                if clauseNums_with_literal in clauseNum_clause:\n",
    "                    del clauseNum_clause[clauseNums_with_literal]\n",
    "\n",
    "            # For all the clauses with opposite literal, remove the literal from the clause\n",
    "            if switch_literal(literal) not in literal_clauseNum: # if the opposite variable doesn't exist, skip\n",
    "                continue\n",
    "\n",
    "            opposite_literal = switch_literal(literal)\n",
    "            literal_boolen[opposite_literal] = False\n",
    "\n",
    "            for clauseNums_with_literal in literal_clauseNum[opposite_literal]:\n",
    "                clauseNum_clause[clauseNums_with_literal].discard(opposite_literal)\n",
    "\n",
    "            literal_clauseNum[opposite_literal] = set()  # It is not watching any clauses anymore\n",
    "\n",
    "    #         print(\"OPPO\")\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "        \n",
    "    return False, literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "\n",
    "def pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    for literal in list(literal_clauseNum.keys()):\n",
    "        if literal in literal_boolen:\n",
    "            continue\n",
    "        \n",
    "        opposite_literal = switch_literal(literal)\n",
    "        if opposite_literal not in literal_boolen: # The opposite variable has not been assigned yet\n",
    "            # If it doesn't exist or it does but it doesn't have to satisfy any clauses\n",
    "            if opposite_literal not in literal_clauseNum or len(literal_clauseNum[opposite_literal]) == 0:\n",
    "                # LITERAL IS A PURE LITERAL\n",
    "                literal_boolen[literal] = True\n",
    "                \n",
    "                # All the clauses that literal exists in has been made true, so remove the clauses and make literal watch no clause\n",
    "                pairs_to_delete = []\n",
    "                for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "                    for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "                        pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "        #         print(pairs_to_delete)\n",
    "\n",
    "                for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "                    literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "                    if clauseNums_with_literal in clauseNum_clause:\n",
    "                        del clauseNum_clause[clauseNums_with_literal]\n",
    "                        \n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "\n",
    "def maxo(literal_clauseNum, return_counts=False):\n",
    "    \"\"\"\n",
    "    Returns the literal that appears in the most number of clauses\n",
    "    \"\"\"\n",
    "    literal_count = defaultdict(int)\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        literal_count[literal] = len(clauseNums)\n",
    "    if return_counts:\n",
    "        return literal_count\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in literal_count.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def moms(literal_clauseNum, clauseNum_clause, return_counts=False):\n",
    "    \"\"\"\n",
    "    Returns the literal that appears most in the smallest clauses\n",
    "    \"\"\"\n",
    "    # Select the clausesNumbers for clauses of the smaller size\n",
    "    least_size = min(map(len, clauseNum_clause.values()))\n",
    "    literal_count = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            if len(clauseNum_clause[clauseNum]) == least_size:\n",
    "                # Each time a literal appears in a least-size clause we \n",
    "                # increment counter by 1\n",
    "                literal_count[literal] += 1\n",
    "    \n",
    "    if return_counts:\n",
    "        return literal_count\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in literal_count.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def mams(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Combines MAXO and MOMS count statistics from above and chooses the literal that appears most between them\n",
    "    \"\"\"\n",
    "    maxo_ans = maxo(literal_clauseNum, return_counts=True)\n",
    "    moms_ans = moms(literal_clauseNum, clauseNum_clause, return_counts=True)\n",
    "    \n",
    "    # MAXO would return the dict with most keys\n",
    "    for literal in maxo_ans:\n",
    "        maxo_ans[literal] += moms_ans[literal]\n",
    "        # Since using defaultdict we add 0 if literal not in moms_ans\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in maxo_ans.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    \n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def jw(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Jeroslow-Wang Rule\n",
    "    \"\"\"\n",
    "    literal_score = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            literal_score[literal] += 2 ** -len(clause)\n",
    "    \n",
    "    max_lit = None\n",
    "    max_score = 0\n",
    "    for literal, score in literal_score.items():\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_lit = literal\n",
    "            \n",
    "    return max_lit, max_score\n",
    "\n",
    "def jw_2(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    2-sided JW rule. See Heutistics folder\n",
    "    \"\"\"\n",
    "    \n",
    "    literal_score = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            literal_score[literal] += 2 ** -len(clause)\n",
    "    \n",
    "    max_lit = None\n",
    "    max_score = 0\n",
    "    for literal, score in list(literal_score.items()):\n",
    "        other_literal = switch_literal(literal)\n",
    "        total_score = score + literal_score[other_literal]\n",
    "        \n",
    "        if total_score > max_score:\n",
    "            max_score = score\n",
    "            max_lit = literal if score >= literal_score[other_literal] else other_literal\n",
    "            \n",
    "    return max_lit, max_score\n",
    "\n",
    "\n",
    "def bohm(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    See Heuristics folder. Lexicographic order of the vector (H1(x), H2(x), ..., Hn(x)) means we first choose highest H1(x)\n",
    "    variable. When tied we then choose amongst tied variable highest H2 variable. When tied then H3 and so on.\n",
    "    \n",
    "    We've had to manage edge cases here but don't mention that in report. Only give formula from paper\n",
    "    \"\"\"\n",
    "    pos_literal_count = defaultdict(lambda: [0, 0, 0])  # This default initialisation only works for 3 SAT\n",
    "    neg_literal_count = defaultdict(lambda: [0, 0, 0])\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if literal.startswith('-'):\n",
    "            for clauseNum in clauseNums:\n",
    "                clause = clauseNum_clause[clauseNum]\n",
    "                neg_literal_count[literal][len(clause)-1] += 1\n",
    "        else:\n",
    "            for clauseNum in clauseNums:\n",
    "                clause = clauseNum_clause[clauseNum]\n",
    "                pos_literal_count[literal][len(clause)-1] += 1\n",
    "                \n",
    "    final_count = []\n",
    "    # Sometimes we only have negative literals left. So then we just use those\n",
    "    for literal, pos_counts in (pos_literal_count.items() or neg_literal_count.items()):\n",
    "        other_literal = switch_literal(literal)\n",
    "        \n",
    "        if literal.startswith('-'):\n",
    "            # pos_literal_counts is empty. So literal and pos_counts actually are neg_literal_counts\n",
    "            neg_counts = pos_literal_count[other_literal]\n",
    "        else:\n",
    "            # pos_literal_counts isn't empty. So continue as normal\n",
    "            neg_counts = neg_literal_count[other_literal]\n",
    "        \n",
    "        final_count.append(([max(p, n) + 2 * min(p, n) for p, n in zip(pos_counts, neg_counts)], literal))\n",
    "            \n",
    "    final_count.sort(reverse=True)\n",
    "    score_vector, literal = final_count[0]\n",
    "    other_literal = switch_literal(literal)\n",
    "    \n",
    "    if literal.startswith('-'):\n",
    "        neg_literal = literal\n",
    "        pos_literal = other_literal\n",
    "    else:\n",
    "        neg_literal = other_literal\n",
    "        pos_literal = literal\n",
    "    \n",
    "    # Since the score for positive and negative literal is the same, choose one which the highest overall score\n",
    "    if sum(pos_literal_count[pos_literal]) >= sum(neg_literal_count[neg_literal]):\n",
    "        literal = pos_literal\n",
    "    else:\n",
    "        literal = neg_literal\n",
    "    \n",
    "    return literal, score_vector\n",
    "    \n",
    "\n",
    "def set_var(literal, boolean, literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    literal_boolen[literal] = boolean\n",
    "\n",
    "    if boolean == False:\n",
    "        literal = switch_literal(literal)\n",
    "        literal_boolen[literal] = True\n",
    "    \n",
    "    # Unit-prop logic below\n",
    "    pairs_to_delete = []\n",
    "    for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "        for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "            pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "    #         print(pairs_to_delete)\n",
    "\n",
    "    for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "        literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "        if clauseNums_with_literal in clauseNum_clause:\n",
    "            del clauseNum_clause[clauseNums_with_literal]\n",
    "\n",
    "    # For all the clauses with opposite literal, remove the literal from the clause\n",
    "    if switch_literal(literal) not in literal_clauseNum: # if the opposite variable doesn't exist, skip\n",
    "        return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "    opposite_literal = switch_literal(literal)\n",
    "    literal_boolen[opposite_literal] = False\n",
    "\n",
    "    for clauseNums_with_literal in literal_clauseNum[opposite_literal]:\n",
    "        clauseNum_clause[clauseNums_with_literal].discard(opposite_literal)\n",
    "\n",
    "    literal_clauseNum[opposite_literal] = set()  # It is not watching any clauses anymore\n",
    "\n",
    "    #         print(\"OPPO\")\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "    \n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "def choose_var(literal_clauseNum, clauseNum_clause, literal_boolen, algo='maxo'):\n",
    "    # Choosing the first literal every time\n",
    "#     remaining_clauses = list(clauseNum_clause.values())\n",
    "#     literal = remaining_clauses[0].pop()\n",
    "#     remaining_clauses[0].add(literal)\n",
    "\n",
    "    # Using heuristics\n",
    "    if algo == 'maxo':\n",
    "        literal, _ = maxo(literal_clauseNum)\n",
    "    elif algo == 'moms':\n",
    "        literal, _ = moms(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'mams':\n",
    "        literal, _ = mams(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'jw':\n",
    "        literal, _ = jw(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'jw_2':\n",
    "        literal, _ = jw_2(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'bohm':\n",
    "        literal, _ = bohm(literal_clauseNum, clauseNum_clause)\n",
    "    \n",
    "\n",
    "    return literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that are used by the Env class to get state features\n",
    "\n",
    "def number_of_variables(literal_clauseNum):\n",
    "    \"\"\" Returns the number of total variables (including repeats) present in the remaining clauses \"\"\"\n",
    "    return sum(map(len, literal_clauseNum.values()))\n",
    "\n",
    "\n",
    "def horn_clause_ratio(clauseNum_clause):\n",
    "    \"\"\" Returns the ratio of horn clauses to total number of clauses \"\"\"\n",
    "    horn_count = 0\n",
    "    total_count = 0\n",
    "    for clause in clauseNum_clause.values():\n",
    "        if len(clause) > 0:\n",
    "            total_count += 1\n",
    "        if len(list(filter(lambda x: not x.startswith('-'), clause))) == 1:\n",
    "            horn_count += 1\n",
    "\n",
    "    return horn_count / total_count if total_count > 0 else 0\n",
    "\n",
    "\n",
    "def horn_clause_count(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    For each variable, we count the number of Horn clauses it is present in\n",
    "    \"\"\"\n",
    "    literal_count = defaultdict(int)\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            if len(list(filter(lambda x: not x.startswith('-'), clause))) == 1:\n",
    "                literal_count[literal] += 1\n",
    "                \n",
    "    counts = list(literal_count.values())\n",
    "    return np.array(counts) if len(counts) > 0 else np.array([0])\n",
    "\n",
    "\n",
    "def clause_to_variable_ratio(literal_clauseNum):\n",
    "    \"\"\" Returns the clause to variable ratio: c/v which predict problem hardness \"\"\"\n",
    "    clauses = set()\n",
    "    num_literals = 0\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if len(clauseNums) > 0:\n",
    "            clauses = clauses.union(clauseNums)\n",
    "            if literal.startswith('-'):\n",
    "                num_literals += 1\n",
    "            else:\n",
    "                num_literals += 1\n",
    "\n",
    "    return 0 if num_literals == 0 else len(clauses) / num_literals\n",
    "\n",
    "\n",
    "def pos_neg_ratio(literal_clauseNum):\n",
    "    \"\"\"\n",
    "    Returns the number of positive literals (incl repeats) to negative literals (incl repeats) in the clauses.\n",
    "    THIS DOESN'T GIVE USEFUL STATE INFORMATION WHEN USED ALONE\n",
    "    \"\"\"\n",
    "    pos_literal_count = 0\n",
    "    neg_literal_count = 0\n",
    "\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if literal.startswith('-'):\n",
    "            neg_literal_count += len(clauseNums)\n",
    "        else:\n",
    "            pos_literal_count += len(clauseNums)\n",
    "\n",
    "    return pos_literal_count / neg_literal_count if neg_literal_count > 0 else pos_literal_count\n",
    "\n",
    "def pos_neg_ratio_per_var():\n",
    "    pass\n",
    "\n",
    "\n",
    "def CVIG(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Caluse-variable incidence graph. We create a bipartite graph (a matrix) with literals in columns and clauses in rows.\n",
    "    See Features_2 PDF file.\n",
    "    \"\"\"\n",
    "    if len(clauseNum_clause) == 0:\n",
    "        return 0\n",
    "    \n",
    "    literal_index_mapping = {}\n",
    "    clauseNum_index_mapping = {}\n",
    "    \n",
    "    for i, literal in enumerate(literal_clauseNum.keys()):\n",
    "        literal_index_mapping[literal] = i\n",
    "        \n",
    "    for i, clauseNum in enumerate(clauseNum_clause):\n",
    "        clauseNum_index_mapping[clauseNum] = i\n",
    "    \n",
    "    graph = np.zeros((len(literal_index_mapping), len(clauseNum_index_mapping)))\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            graph[literal_index_mapping[literal]] [clauseNum_index_mapping[clauseNum]] = 1/len(clauseNums)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def VIG(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Variable incidence graph.\n",
    "    \"\"\"\n",
    "    if len(clauseNum_clause) == 0:\n",
    "        return 0\n",
    "    \n",
    "    literal_index_mapping = {}\n",
    "    \n",
    "    for i, literal in enumerate(literal_clauseNum.keys()):\n",
    "        literal_index_mapping[literal] = i\n",
    "        \n",
    "    graph = np.zeros((len(literal_index_mapping), len(literal_index_mapping)))\n",
    "    \n",
    "    for clause in clauseNum_clause.values():\n",
    "        if len(clause) < 2:\n",
    "            continue\n",
    "        for x, y in combinations(clause, 2):\n",
    "            w = 1 / (comb(len(clause), 2))  # Try combinations with replacement to add self-loops\n",
    "            graph[literal_index_mapping[x]][literal_index_mapping[y]] = w\n",
    "            graph[literal_index_mapping[y]][literal_index_mapping[x]] = w\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    def __init__(self, input_file):\n",
    "        self.input_file = input_file\n",
    "        self.stack = [] # We use a stack to hold the next states to explore. i.e. we do DFS as less memory requirements than BFS\n",
    "        self.state = None\n",
    "        self.actions = {0: 'maxo', 1: 'moms', 2: 'mams', 3: 'jw', 4: 'jw_2', 5: 'bohm'}\n",
    "        self.action_penalty = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}  # Penalty to give each action\n",
    "    \n",
    "    def reset(self):\n",
    "        # Returns state\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen, _ = parse_input(self.input_file)\n",
    "        self.state = (literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = self.state\n",
    "        \n",
    "        num_var = number_of_variables(literal_clauseNum)\n",
    "        horn_clause = horn_clause_ratio(clauseNum_clause)\n",
    "#         var_horn_counts = horn_clause_count(literal_clauseNum, clauseNum_clause)\n",
    "#         var_horn_mean, var_horn_var = np.mean(var_horn_counts), np.var(var_horn_counts)\n",
    "        \n",
    "        pn_ratio = pos_neg_ratio(literal_clauseNum)\n",
    "        c_v_ratio = clause_to_variable_ratio(literal_clauseNum)\n",
    "        \n",
    "        cvig_graph = CVIG(literal_clauseNum, clauseNum_clause)\n",
    "        cvig_mean, cvig_var = np.mean(cvig_graph), np.var(cvig_graph)  # axis=0 gives more different results if we want this to return vector\n",
    "        \n",
    "        vig_graph = VIG(literal_clauseNum, clauseNum_clause)\n",
    "        vig_mean, vig_var = np.mean(vig_graph), np.var(vig_graph)\n",
    "        \n",
    "        return [num_var, c_v_ratio, pn_ratio, horn_clause, cvig_mean, cvig_var, vig_mean, vig_var]\n",
    "#         return [num_var, horn_clause, var_horn_mean, var_horn_var, pn_ratio, c_v_ratio, cvig_mean, cvig_var, vig_mean, vig_var]\n",
    "#         return num_var\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns: next_state_1, next_state_2, reward, done\n",
    "        reward = 0 if reached a leaf node, 0 if not\n",
    "        \"\"\"\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = self.state\n",
    "        \n",
    "        num_clauses_start = 0\n",
    "        for clause in clauseNum_clause.values():\n",
    "            if len(clause) > 0:\n",
    "                num_clauses_start += 1\n",
    "                \n",
    "        if num_clauses_start > 0:\n",
    "            fraction_of_clauses_removed = num_clauses_start/num_clauses_start\n",
    "        else:\n",
    "            fraction_of_clauses_removed = 0\n",
    "        \n",
    "        unassigned_nodes_start = len(list(filter(lambda x: len(x) > 0, literal_clauseNum.values())))\n",
    "        \n",
    "        # Do unit prop\n",
    "        empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \\\n",
    "            unit_prop(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "        if empty_clause:\n",
    "            isEmpty = len(self.stack) == 0\n",
    "            if not isEmpty:\n",
    "                self.state = self.stack.pop()\n",
    "            # return None, -1 + self.action_penalty[action] + fraction_of_clauses_removed, isEmpty\n",
    "            return None, -1, isEmpty\n",
    "        \n",
    "        if clauseNum_clause == {}:\n",
    "            # return None, 1 + self.action_penalty[action] + fraction_of_clauses_removed, True\n",
    "            return None, 1, True\n",
    "        \n",
    "        # Do pure literal elimination\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = \\\n",
    "            pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "        if clauseNum_clause == {}:\n",
    "            # return None, 1 + self.action_penalty[action] + fraction_of_clauses_removed, True\n",
    "            return None, 1, True\n",
    "        \n",
    "        literal = choose_var(literal_clauseNum, clauseNum_clause, literal_boolen, algo=self.actions[action])\n",
    "        \n",
    "        \n",
    "        # Set the chosen literal to be True\n",
    "        literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T = \\\n",
    "            set_var(literal, True, deepcopy(literal_clauseNum), deepcopy(clauseNum_clause), dict(literal_boolen))\n",
    "            \n",
    "#         print(\"After setting\", literal, \"to True\")\n",
    "#         print(literal_clauseNum_T)\n",
    "#         print(literal_boolen_T)\n",
    "#         print()\n",
    "        \n",
    "#         unassigned_nodes_T = len(filter(lambda x: len(x) > 0, literal_clauseNum_T.values()))\n",
    "        \n",
    "#         # Do unit prop and pure literal elimnation and record the number of nodes assigned\n",
    "#         empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             unit_prop(literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T)\n",
    "        \n",
    "#         if empty_clause:\n",
    "#             return 0, 0, unassigned_nodes_start, self.q.empty()\n",
    "        \n",
    "#         # Do pure literal elimination\n",
    "#         literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         if clauseNum_clause == {}:\n",
    "#             return 0, 0, unassigned_nodes_start, True\n",
    "        \n",
    "        # Set new state\n",
    "        self.state = (literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T)\n",
    "        \n",
    "        # Set the chosen literal to be False\n",
    "        literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F = \\\n",
    "            set_var(literal, False, literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         print(\"After setting\", literal, \"to False\")\n",
    "#         print(literal_clauseNum_F)\n",
    "#         print(literal_boolen_F)\n",
    "#         print()\n",
    "            \n",
    "#         unassigned_nodes_F = len(filter(lambda x: len(x) > 0, literal_clauseNum_F.values()))\n",
    "            \n",
    "#         # Do unit prop and pure literal elimnation and record the number of nodes assigned\n",
    "#         empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             unit_prop(literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F)\n",
    "        \n",
    "#         if empty_clause:\n",
    "#             return 0, 0, unassigned_nodes_start, self.q.empty()\n",
    "        \n",
    "#         # Do pure literal elimination\n",
    "#         literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         if clauseNum_clause == {}:\n",
    "#             return 0, 0, unassigned_nodes_start, True\n",
    "\n",
    "        # Add new state to queue\n",
    "        self.stack.append((literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F))\n",
    "        \n",
    "        num_clauses_end = 0\n",
    "        for clause in clauseNum_clause.values():\n",
    "            if len(clause) > 0:\n",
    "                num_clauses_end += 1\n",
    "        \n",
    "        if num_clauses_start > 0:\n",
    "            fraction_of_clauses_removed = (num_clauses_start - num_clauses_end)/num_clauses_start\n",
    "        else:\n",
    "            fraction_of_clauses_removed = 0\n",
    "        \n",
    "        if clauseNum_clause_T == {} or clauseNum_clause_F == {}:  # We have satisfied\n",
    "            fraction_of_clauses_removed = 1\n",
    "            # return None, 1 + self.action_penalty[action] + fraction_of_clauses_removed, True\n",
    "            return None, 1, True\n",
    "        else:\n",
    "            # return None, -1 + self.action_penalty[action] + fraction_of_clauses_removed, False\n",
    "            return None, -1, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.layers import Input, Dense\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "# import keras.backend as K\n",
    "\n",
    "# class Estimator():\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.create_model()\n",
    "        \n",
    "#         self.model = Model(inputs=self.input, outputs=self.output)\n",
    "#         self.action_index = K.placeholder(dtype=tf.int32, name='action_index')\n",
    "#         self.target = K.placeholder(dtype=tf.float32, name='target')\n",
    "        \n",
    "#         self.chosen_action_qval = tf.gather(self.output, self.action_index, axis=1)\n",
    "#         self.loss = tf.reduce_mean(tf.squared_difference(self.target, self.chosen_action_qval))\n",
    "        \n",
    "#         self.optimiser = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "#         self.train_op = self.optimiser.minimize(self.loss)\n",
    "        \n",
    "    \n",
    "#     def create_model(self):\n",
    "#         self.input = Input(shape=(state_space,))\n",
    "#         self.h1 = Dense(4, activation='sigmoid')(self.input)\n",
    "# #         self.h2 = Dense(16, activation='sigmoid')(self.h1)\n",
    "#         self.output = Dense(actions, activation=None)(self.h1)\n",
    "        \n",
    "        \n",
    "#     def featurize_state(self, state):\n",
    "#         # Needs to return a 1D array\n",
    "#         return np.array(state)\n",
    "    \n",
    "#     def predict(self, state):\n",
    "#         state = self.featurize_state(state)\n",
    "#         if len(self.input.shape) != len(state.shape):\n",
    "#             state = np.expand_dims(state, 0)\n",
    "#         return np.squeeze(self.model.predict(state))\n",
    "    \n",
    "#     def update(self, state, action_index, target):\n",
    "#         \"\"\" action: action_index of the literal we chose \"\"\"\n",
    "#         state = self.featurize_state(state)\n",
    "#         sess = tf.get_default_session()\n",
    "#         if len(self.input.shape) != len(state.shape):\n",
    "#             state = np.expand_dims(state, 0)\n",
    "#         # Update shapes of targets and action_index to incorporate batch size\n",
    "# #         target = np.expand_dims(target, 1)\n",
    "# #         action_index = np.expand_dims(action_index, 1)\n",
    "#         _, loss = sess.run([self.train_op, self.loss], feed_dict={self.input: state, self.action_index: action_index, \n",
    "#                                                                   self.target: target, K.learning_phase(): 1})\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Estimator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # We create a separate model for each action in the environment's\n",
    "        # action space. Alternatively we could somehow encode the action\n",
    "        # into the features, but this way it's easier to code up.\n",
    "        self.models = []\n",
    "        for _ in range(actions):\n",
    "            model = SGDRegressor(learning_rate=\"constant\", eta0=0.001, penalty='l2')\n",
    "            # We need to call partial_fit once to initialize the model\n",
    "            # or we get a NotFittedError when trying to make a prediction\n",
    "            # This is quite hacky.\n",
    "            model.partial_fit([self.featurize_state(np.zeros(state_space))], [0])\n",
    "            self.models.append(model)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit([self.featurize_state(np.zeros(state_space))], [np.zeros(state_space)])\n",
    "    \n",
    "    def featurize_state(self, state):\n",
    "        # Needs to return a 1D array\n",
    "        if use_poly:\n",
    "            state = int(state)\n",
    "            return np.array([state**i for i in range(1, poly_degree+1)])\n",
    "        else:\n",
    "            return np.array(state)\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state_feature = self.featurize_state(state)\n",
    "        state_feature = self.scaler.transform([state_feature]) # Returns a 2D array\n",
    "        return np.array([m.predict(state_feature)[0] for m in self.models])\n",
    "    \n",
    "    def update(self, state, action, reward):\n",
    "        model = self.models[action]\n",
    "        state_feature = self.featurize_state(state)\n",
    "        \n",
    "        self.scaler.partial_fit([state_feature])\n",
    "        state_feature = self.scaler.transform([state_feature]) # Returns a 2D array\n",
    "        model.partial_fit(state_feature, [reward])\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "#         print(\"After update:\", model.predict(state_feature)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "    \n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        epsilon: The probability to select a random action . float between 0 and 1.\n",
    "        nA: Number of actions in the environment.\n",
    "    \n",
    "    Returns:\n",
    "        A function that takes the observation as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "    \n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        if epsilon > np.random.rand():\n",
    "            return np.ones(nA) / nA\n",
    "        else:\n",
    "            action_value = estimator.predict(observation)\n",
    "            action = np.argmax(action_value)\n",
    "            ans = np.zeros(nA)\n",
    "            ans[action] = 1\n",
    "            return ans\n",
    "\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, estimator, discount_factor=1.0, epsilon=0.1, epsilon_decay=1.0, train_phase=True):\n",
    "    \"\"\"\n",
    "    Goes through the environment only once (stops when we reach a finishing state in the environment)\n",
    "    \"\"\"\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "    loss = 0\n",
    "    \n",
    "#     policy = make_epsilon_greedy_policy(estimator, epsilon * epsilon_decay**i_episode, actions)\n",
    "#     Since we do not iterate over in q_learning, we do not have i_episode above. See if that is useful here and below (near end)\n",
    "    policy = make_epsilon_greedy_policy(estimator, epsilon*epsilon_decay, actions)\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action_prob = policy(state)\n",
    "        action = np.random.choice(np.arange(len(action_prob)), p=action_prob)\n",
    "#         action = 5\n",
    "        _, reward, done = env.step(action)\n",
    "        \n",
    "        # Stats\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            td_target = reward\n",
    "            if train_phase:\n",
    "                loss += estimator.update(state, action, td_target)\n",
    "            break\n",
    "\n",
    "        next_state = env.get_state()\n",
    "\n",
    "        q_values = estimator.predict(next_state)\n",
    "        td_target = reward + discount_factor * np.max(q_values)\n",
    "        \n",
    "        current_value = estimator.predict(state)[action]\n",
    "        td_error = td_target - current_value\n",
    "        \n",
    "        alpha = 0.8\n",
    "        update_target = current_value + alpha*td_error\n",
    "        if train_phase:\n",
    "            loss += estimator.update(state, action, update_target)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    return episode_reward, episode_length, estimator, loss\n",
    "\n",
    "\n",
    "def q_learning_test(env, estimator, epsilon):\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "    \n",
    "    policy = make_epsilon_greedy_policy(estimator, epsilon, actions)\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action_prob = policy(state)\n",
    "        action = np.random.choice(np.arange(len(action_prob)), p=action_prob)\n",
    "#         action = 0\n",
    "        _, reward, done = env.step(action)\n",
    "        \n",
    "        # Stats\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        state = env.get_state()\n",
    "\n",
    "    return episode_reward, episode_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(training_files, epochs, ϵ, epsilon_decay=0.97):\n",
    "    \"\"\"\n",
    "    One episode is one file. Each call to q_learning function does one episode only and returns. \n",
    "    An Env can be instantiated with one file only, so can only do one episode.\n",
    "    \n",
    "    In one epoch, you go through all the files in your training dataset.\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length, losses = [], [], []\n",
    "    estimator = Estimator()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "        curr_epoch_loss = 0\n",
    "\n",
    "        \n",
    "#         shuffle(training_files)  # Shuffles files in-place\n",
    "\n",
    "        for j, filepath in enumerate(training_files):\n",
    "            \"\"\" Each file in one episode \"\"\"\n",
    "            \n",
    "            if j % 1000 == 0:\n",
    "                part = j // 1000\n",
    "                print(part)\n",
    "                epsilon_decay_j = epsilon_decay**part\n",
    "                epoch_reward.append(curr_epoch_reward / 1000)\n",
    "                epoch_length.append(curr_epoch_length / 1000)\n",
    "                losses.append(curr_epoch_loss / 1000)\n",
    "                \n",
    "                print(epoch_reward[-1], epoch_length[-1], losses[-1])\n",
    "                \n",
    "                curr_epoch_length = 0\n",
    "                curr_epoch_reward = 0\n",
    "                curr_epoch_loss = 0\n",
    "                \n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length, estimator, loss = q_learning(env, estimator, epsilon=ϵ, epsilon_decay=epsilon_decay_j)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "            curr_epoch_loss += loss\n",
    "            \n",
    "        epoch_reward.append(curr_epoch_reward / 1000)\n",
    "        epoch_length.append(curr_epoch_length / 1000)\n",
    "        losses.append(curr_epoch_loss / 1000)\n",
    "            \n",
    "        # Average reward per episode in this epoch\n",
    "#         epoch_reward.append(curr_epoch_reward / len(training_files))\n",
    "\n",
    "        # Average length of each episode in this epoch\n",
    "#         epoch_length.append(curr_epoch_length / len(training_files))\n",
    "        \n",
    "        # Average loss of each episode in this epoch\n",
    "#         losses.append(curr_epoch_loss / len(training_files))\n",
    "        \n",
    "#         print(\"Reward:\", epoch_reward[-1])\n",
    "#         print(\"Length:\", epoch_length[-1])\n",
    "#         print(\"Loss:\", losses[-1])\n",
    "            \n",
    "    return epoch_reward, epoch_length, estimator, losses\n",
    "\n",
    "\n",
    "def test(test_files, epochs=10, ϵ=1.1, estimator=None):\n",
    "    \"\"\"\n",
    "    This method is used to either:\n",
    "    \n",
    "     - Run a random policy on the test data and returns the avg. reward and length per epoch (epoch runs over the test_files).\n",
    "     This can be done by only passing on first two parameters (and optionally epochs for longer runs)\n",
    "     \n",
    "     - Run an epilon-greedy policy with the given estimator. Pass an estimator that we receive from the train() method and set \n",
    "     the ϵ value appropriately to make an epsilon-greedy policy. Runs this policy over the test_files for given number of epochs.\n",
    "    \n",
    "    Returns dictionary of {epoch: average reward} and {epoch: average length per episode/file}\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length = [], []\n",
    "    \n",
    "    if estimator is None:\n",
    "        estimator = Estimator()  # Never used if epsilon > 1 \n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "\n",
    "        shuffle(test_files)\n",
    "        \n",
    "        for filepath in test_files:\n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length = q_learning_test(env, estimator, ϵ)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "            \n",
    "        # Average reward per training example in this epoch\n",
    "        epoch_reward.append(curr_epoch_reward / len(test_files))\n",
    "\n",
    "        # Average episode length per example in this epoch\n",
    "        epoch_length.append(curr_epoch_length / len(test_files))\n",
    "            \n",
    "            \n",
    "    return epoch_reward, epoch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun\n",
    "# import time\n",
    "\n",
    "\n",
    "use_poly = False  # Set this to True if you want the Estimator to change state to a polynomial. State must be a single number.\n",
    "poly_degree = 7   # Degree of polynomial is use_poly is set to True\n",
    "actions = 6       # Number of actions available to use by the agent\n",
    "state_space = 7   # Number of variables we return as state of environment. Used to initialise Scaler and SGD in Estimator\n",
    "\n",
    "directory = '../Tests/CNFGEN_20/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "files = os.listdir(directory)\n",
    "files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "# shuffle(files)\n",
    "\n",
    "split = int(len(files) * 0.2)\n",
    "training_files = files[:split]\n",
    "# test_files = files[split:]\n",
    "test_files = files[60000:61000]\n",
    "\n",
    "# directory = '../Tests/SATLIB_20/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "# files = os.listdir(directory)\n",
    "# files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "# split = int(len(files) * 1.0)\n",
    "# test_files = files[split:split+int(len(files) * 0.01)] \n",
    "\n",
    "\n",
    "print(\"Number of training files:\", len(training_files))\n",
    "print(\"Number of test files:\", len(test_files))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    \n",
    "#     episode_reward_train, episode_length_train, estimator, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "#     episode_reward_train_2, episode_length_train_2, estimator_2, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "#     episode_reward_train_3, episode_length_train_3, estimator_3, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.97)\n",
    "    print(\"Done training\")\n",
    "    print()\n",
    "\n",
    "    s = time.time()\n",
    "    episode_reward_test, episode_length_test = test(test_files, epochs=1, ϵ=0.1, estimator=estimator_2)\n",
    "    e = time.time()\n",
    "    print(\"Done testing in\", (round(e-s, 2)), \"s\")\n",
    "    print()\n",
    "\n",
    "    # s = time.time()\n",
    "    # episode_reward_rand, episode_length_rand = test(test_files, epochs=1)\n",
    "    # e = time.time()\n",
    "    # print(\"Done testing random policy in \", (round(e-s, 2)), \"s\")\n",
    "    # print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread(vals):\n",
    "    vals_range = vals - np.mean(vals)\n",
    "    return np.abs(np.min(vals_range)) + np.abs(np.max(vals_range))\n",
    "\n",
    "def VAR(mat):\n",
    "    return np.array([spread(mat[:, cols]) for cols in range(mat.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1000\n"
     ]
    }
   ],
   "source": [
    "# Measure the variance in each state\n",
    "\n",
    "use_poly = False\n",
    "actions = 6       # Number of actions available to use by the agent\n",
    "state_space = 7   # Number of variables we return as state of environment. Used to initialise Scaler and SGD in Estimator\n",
    "\n",
    "directory = '../Tests/CNFGEN_20/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "files = os.listdir(directory)\n",
    "files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "files = files[:1000]\n",
    "\n",
    "print(\"Number of files:\", len(files))\n",
    "\n",
    "states = []\n",
    "\n",
    "for filepath in files:\n",
    "    env = Env(filepath)\n",
    "    states.append(env.reset())\n",
    "    \n",
    "    while True:\n",
    "        _, _, done = env.step(5)\n",
    "        states.append(env.get_state())\n",
    "        \n",
    "        if states[-1][0] > 300:\n",
    "            print(\"DOUBT\")\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "states = np.array(states)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.160e+02, 3.000e+01, 9.102e+03, 1.588e+03, 3.940e+02, 9.300e+01,\n",
       "        4.900e+01, 3.800e+01, 1.300e+01, 5.000e+00]),\n",
       " array([0.        , 0.00512821, 0.01025641, 0.01538462, 0.02051282,\n",
       "        0.02564103, 0.03076923, 0.03589744, 0.04102564, 0.04615385,\n",
       "        0.05128205]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(states[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.56598993e+02 1.76975468e+00 9.71955840e-01 3.98670319e-01\n",
      " 1.34307805e-02 4.05418497e-03 6.04852383e-02 2.44432580e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "mean = np.mean(states, axis=0)\n",
    "labels = ['num_var', 'c_v_ratio', 'pn_ratio', 'horn_clause', 'cvig_mean', 'cvig_var', 'vig_mean', 'vig_var']\n",
    "plt.bar(labels, mean)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.73000000e+02 3.00000000e+00 4.50000000e+00 1.00000000e+00\n",
      " 4.27350427e-02 4.09087589e-02 1.00810870e-01 3.86937500e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "var = VAR(states)  # np.var(states, axis=0)\n",
    "labels = ['num_var', 'c_v_ratio', 'pn_ratio', 'horn_clause', 'cvig_mean', 'cvig_var', 'vig_mean', 'vig_var']\n",
    "plt.bar(labels, var)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174.33062260936646, 169.51501954159244, 462.9839974537843, 250.8338221392823, 318.1873359037806, 1009.0501337337809, 166.6702040618007, 158.30029712257075]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "percent_vary = [(v / m) * 100 for m, v in zip(list(mean), list(var))]\n",
    "print(percent_vary)\n",
    "plt.bar(labels, percent_vary)\n",
    "# plt.ylim(0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.92\n"
     ]
    }
   ],
   "source": [
    "# Given the mean and variance, we vary each dimension along all possible values to see what policy it follows\n",
    "\n",
    "import time\n",
    "\n",
    "def policy_use(mean, var, estimator):\n",
    "    counts = [0]*6\n",
    "    count = 0\n",
    "    length = 4\n",
    "\n",
    "    s = time.time()\n",
    "    for i0 in np.linspace(mean[0]-var[0]/2, mean[0]+var[0]/2, length):\n",
    "        for i1 in np.linspace(mean[1]-var[1]/2, mean[1]+var[1]/2, length):\n",
    "    #         for i2 in np.linspace(mean[2]-var[2]/2, mean[2]+var[2]/2, length):\n",
    "                for i3 in np.linspace(mean[3]-var[3]/2, mean[3]+var[3]/2, length):\n",
    "                    for i4 in np.linspace(mean[4]-var[4]/2, mean[4]+var[4]/2, length):\n",
    "                        for i5 in np.linspace(mean[5]-var[5]/2, mean[5]+var[5]/2, length):\n",
    "                            for i6 in np.linspace(mean[6]-var[6]/2, mean[6]+var[6]/2, length):\n",
    "                                for i7 in np.linspace(mean[7]-var[7]/2, mean[7]+var[7]/2, length):\n",
    "                                    state = [i0, i1, i3, i4, i5, i6, i7]\n",
    "                                    qvals = estimator.predict(state)\n",
    "                                    counts[np.argmax(qvals)] += 1\n",
    "\n",
    "                                    count += 1\n",
    "                                    if count % 1000000 == 0:\n",
    "                                        print(count)\n",
    "                                        \n",
    "    return counts\n",
    "                 \n",
    "s = time.time()\n",
    "counts = policy_use(mean, var, estimator)\n",
    "e = time.time()\n",
    "print(\"Time taken:\", round(e-s, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/aks73/python/Python-3.5.1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m(692)\u001b[0;36mtransform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    690 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    691 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 692 \u001b[0;31m                \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    693 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    694 \u001b[0;31m                \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-91-1e3fd9a8b3a5>\u001b[0m(31)\u001b[0;36mpredict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     29 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m        \u001b[0mstate_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 31 \u001b[0;31m        \u001b[0mstate_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Returns a 2D array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> state\n",
      "[20.098993288590606, 0.2697546849315706, -1.2780441603277668, -0.10132968055451358, -0.007936740845204869, -0.016400194459147012, 0.010079803243038837, 0.005096382974455801]\n",
      "ipdb> d\n",
      "> \u001b[0;32m/home/aks73/python/Python-3.5.1/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m(692)\u001b[0;36mtransform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    690 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    691 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 692 \u001b[0;31m                \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    693 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    694 \u001b[0;31m                \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.mean_\n",
      "array([3.31795341e+02, 0.00000000e+00, 1.59645758e+00, 6.54113423e-03,\n",
      "       2.26102894e-03, 2.33211449e-02, 1.16462925e-02])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5836, 44, 4268, 6200, 36, 0]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max VIF: 1608.8365868939647\n",
      "dropping '6' at index: 6\n",
      "\n",
      "Max VIF: 163.03834944360673\n",
      "dropping '1' at index: 1\n",
      "\n",
      "Max VIF: 90.13093379255172\n",
      "dropping '4' at index: 3\n",
      "\n",
      "Max VIF: 23.26143850088851\n",
      "dropping '7' at index: 4\n",
      "\n",
      "Max VIF: 14.163697516536345\n",
      "dropping '3' at index: 2\n",
      "\n",
      "Max VIF: 9.30007669734368\n",
      "dropping '2' at index: 1\n",
      "\n",
      "Remaining variables:\n",
      "Int64Index([0, 5], dtype='int64')\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_vif_(X, thresh=5.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        vif = [variance_inflation_factor(X[variables].values, ix) for ix in range(X[variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print(\"Max VIF:\", max(vif))\n",
    "            print('dropping \\'' + str(X[variables].columns[maxloc]) + '\\' at index: ' + str(maxloc))\n",
    "            print()\n",
    "            del variables[maxloc]\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[variables]\n",
    "\n",
    "\n",
    "calculate_vif_(pd.DataFrame(states))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-116-6508c3874178>\u001b[0m(14)\u001b[0;36mcalculate_vif_\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     12 \u001b[0;31m        \u001b[0mmaxloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvif\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dropping \\''\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaxloc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\' at index: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m            \u001b[0;32mdel\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaxloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m            \u001b[0mdropped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> maxloc\n",
      "6\n",
      "ipdb> X[variables].columns[maxloc]\n",
      "6\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "labels =    ['num_var', 'c_v_ratio', 'pn_ratio', 'horn_clause', 'cvig_mean', 'cvig_var', 'vig_mean', 'vig_var']\n",
    "# The below works well\n",
    "remaining = ['num_var', 'c_v_ratio', 'cvig_mean', 'cvig_var']\n",
    "\n",
    "\"\"\"\n",
    "When trying other metrics such as using pn_ratio and vig instead of cvig and vig incl. cig etc. All produced worse results.\n",
    "\n",
    "Removing any of these features also produced worse results.\n",
    "\n",
    "Using horn_clause as a feature and looking at the SGD weight-age for this, it is very low. So this is redundant. Similar for \n",
    "other Horn clause based metrics\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Metrics/SATLIB_50_action_penalty.pickle', 'rb') as fin:\n",
    "    episode_reward_train, episode_length_train, estimator, episode_reward_test, episode_length_test, episode_reward_rand, episode_length_rand = pickle.load(fin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
