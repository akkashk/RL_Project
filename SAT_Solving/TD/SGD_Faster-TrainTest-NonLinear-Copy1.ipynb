{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from queue import Queue\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from random import shuffle\n",
    "from itertools import combinations\n",
    "from scipy.special import comb\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_literal = lambda x: x[1:] if x.startswith('-') else '-'+x\n",
    "deepcopy = lambda x: pickle.loads(pickle.dumps(x))\n",
    "\n",
    "def parse_input(input_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    literal_clauseNum: {Literal: Set of clause numbers that are still in consideration for this variable}                        \n",
    "    \n",
    "    clauseNum_clause: {Clause number: Set of literals that could still satisfy this clause}\n",
    "    \n",
    "    literal_boolen: {Literal: boolean on whether literal set of True/False/None, None meaning could be either, doesn't matter}\n",
    "    \n",
    "    input_file:\n",
    "    c DIMACS CNF: conjunction/AND of one or more clauses, where a clause is a disjunction/OR of literals\n",
    "    c Comments start with a c, First lines begins with p and describes the probelm and all clause lines end with a 0\n",
    "    c Can't have same variable in both forms in same clause. So A ~A is not allowed. Can have them in separate clauses.\n",
    "                        \n",
    "    \"\"\"\n",
    "\n",
    "    all_clauses = []  # List of all clauses that appear in input. Used for SAT checking the mapping given by DPLL\n",
    "\n",
    "    literal_clauseNum = defaultdict(set)\n",
    "\n",
    "    def filler():\n",
    "        return None\n",
    "\n",
    "    literal_boolen = defaultdict(filler)\n",
    "\n",
    "    clauseNum_clause = {}\n",
    "\n",
    "    clause_counter = 0\n",
    "\n",
    "    with open(input_file, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            # Do checks on comments\n",
    "            if line.startswith('c') or line.startswith('p') or line.startswith('0') or line.startswith('%'):\n",
    "                continue\n",
    "            if len(line) > 0:\n",
    "                clause = []\n",
    "                clause_counter += 1\n",
    "                for literal in line.split():\n",
    "                    if literal == '0':\n",
    "                        # End of line, ignore in DIMACS CNF format\n",
    "                        continue\n",
    "                    clause.append(literal)\n",
    "                    literal_clauseNum[literal].add(clause_counter)\n",
    "                clauseNum_clause[clause_counter] = set(clause)\n",
    "                all_clauses.append(clause)\n",
    "\n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen, all_clauses\n",
    "\n",
    "def unit_prop(literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    keep_updating = True\n",
    "    while keep_updating:\n",
    "        keep_updating = False # Assuming we've found all unit clauses\n",
    "        for clauseNum in list(clauseNum_clause.keys()):\n",
    "            if clauseNum not in clauseNum_clause:\n",
    "                continue\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            # Clause contains the remaining literals that could potentially satisfy this clause. \n",
    "            if len(clause) == 0:\n",
    "                # Empty clause, so need to return True for empty clause detected\n",
    "                return True, None, None, None\n",
    "            if len(clause) > 1:\n",
    "                # Can't do unit prop \n",
    "                continue\n",
    "\n",
    "            literal = clause.pop()  # Needs to be set to True\n",
    "            clause.add(literal)  # Removed later\n",
    "            literal_boolen[literal] = True\n",
    "            keep_updating = True  # Since we found one unit clause, maybe more\n",
    "\n",
    "    #         print(literal)\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "\n",
    "            # For all clauses that have this literal, they have been satisfied now\n",
    "            # 1) Gather all pairs of (literals, clauseNum) that appear in these clauses so we can remove them from literal_clauseNum\n",
    "            # 2) Delete these clauses from clauseNum_clause\n",
    "            pairs_to_delete = []\n",
    "            for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "                for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "                    pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "    #         print(pairs_to_delete)\n",
    "\n",
    "            for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "                literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "                if clauseNums_with_literal in clauseNum_clause:\n",
    "                    del clauseNum_clause[clauseNums_with_literal]\n",
    "\n",
    "            # For all the clauses with opposite literal, remove the literal from the clause\n",
    "            if switch_literal(literal) not in literal_clauseNum: # if the opposite variable doesn't exist, skip\n",
    "                continue\n",
    "\n",
    "            opposite_literal = switch_literal(literal)\n",
    "            literal_boolen[opposite_literal] = False\n",
    "\n",
    "            for clauseNums_with_literal in literal_clauseNum[opposite_literal]:\n",
    "                clauseNum_clause[clauseNums_with_literal].discard(opposite_literal)\n",
    "\n",
    "            literal_clauseNum[opposite_literal] = set()  # It is not watching any clauses anymore\n",
    "\n",
    "    #         print(\"OPPO\")\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "        \n",
    "    return False, literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "\n",
    "def pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    for literal in list(literal_clauseNum.keys()):\n",
    "        if literal in literal_boolen:\n",
    "            continue\n",
    "        \n",
    "        opposite_literal = switch_literal(literal)\n",
    "        if opposite_literal not in literal_boolen: # The opposite variable has not been assigned yet\n",
    "            # If it doesn't exist or it does but it doesn't have to satisfy any clauses\n",
    "            if opposite_literal not in literal_clauseNum or len(literal_clauseNum[opposite_literal]) == 0:\n",
    "                # LITERAL IS A PURE LITERAL\n",
    "                literal_boolen[literal] = True\n",
    "                \n",
    "                # All the clauses that literal exists in has been made true, so remove the clauses and make literal watch no clause\n",
    "                pairs_to_delete = []\n",
    "                for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "                    for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "                        pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "        #         print(pairs_to_delete)\n",
    "\n",
    "                for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "                    literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "                    if clauseNums_with_literal in clauseNum_clause:\n",
    "                        del clauseNum_clause[clauseNums_with_literal]\n",
    "                        \n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "\n",
    "def maxo(literal_clauseNum, return_counts=False):\n",
    "    \"\"\"\n",
    "    Returns the literal that appears in the most number of clauses\n",
    "    \"\"\"\n",
    "    literal_count = defaultdict(int)\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        literal_count[literal] = len(clauseNums)\n",
    "    if return_counts:\n",
    "        return literal_count\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in literal_count.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def moms(literal_clauseNum, clauseNum_clause, return_counts=False):\n",
    "    \"\"\"\n",
    "    Returns the literal that appears most in the smallest clauses\n",
    "    \"\"\"\n",
    "    # Select the clausesNumbers for clauses of the smaller size\n",
    "    least_size = min(map(len, clauseNum_clause.values()))\n",
    "    literal_count = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            if len(clauseNum_clause[clauseNum]) == least_size:\n",
    "                # Each time a literal appears in a least-size clause we \n",
    "                # increment counter by 1\n",
    "                literal_count[literal] += 1\n",
    "    \n",
    "    if return_counts:\n",
    "        return literal_count\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in literal_count.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def mams(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Combines MAXO and MOMS count statistics from above and chooses the literal that appears most between them\n",
    "    \"\"\"\n",
    "    maxo_ans = maxo(literal_clauseNum, return_counts=True)\n",
    "    moms_ans = moms(literal_clauseNum, clauseNum_clause, return_counts=True)\n",
    "    \n",
    "    # MAXO would return the dict with most keys\n",
    "    for literal in maxo_ans:\n",
    "        maxo_ans[literal] += moms_ans[literal]\n",
    "        # Since using defaultdict we add 0 if literal not in moms_ans\n",
    "    \n",
    "    max_lit = None\n",
    "    max_count = 0\n",
    "    for literal, count in maxo_ans.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_lit = literal\n",
    "    \n",
    "    return max_lit, max_count\n",
    "\n",
    "\n",
    "def jw(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Jeroslow-Wang Rule\n",
    "    \"\"\"\n",
    "    literal_score = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            literal_score[literal] += 2 ** -len(clause)\n",
    "    \n",
    "    max_lit = None\n",
    "    max_score = 0\n",
    "    for literal, score in literal_score.items():\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_lit = literal\n",
    "            \n",
    "    return max_lit, max_score\n",
    "\n",
    "def jw_2(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    2-sided JW rule. See Heutistics folder\n",
    "    \"\"\"\n",
    "    \n",
    "    literal_score = defaultdict(int)\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            literal_score[literal] += 2 ** -len(clause)\n",
    "    \n",
    "    max_lit = None\n",
    "    max_score = 0\n",
    "    for literal, score in list(literal_score.items()):\n",
    "        other_literal = switch_literal(literal)\n",
    "        total_score = score + literal_score[other_literal]\n",
    "        \n",
    "        if total_score > max_score:\n",
    "            max_score = score\n",
    "            max_lit = literal if score >= literal_score[other_literal] else other_literal\n",
    "            \n",
    "    return max_lit, max_score\n",
    "\n",
    "\n",
    "def bohm(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    See Heuristics folder. Lexicographic order of the vector (H1(x), H2(x), ..., Hn(x)) means we first choose highest H1(x)\n",
    "    variable. When tied we then choose amongst tied variable highest H2 variable. When tied then H3 and so on.\n",
    "    \n",
    "    We've had to manage edge cases here but don't mention that in report. Only give formula from paper\n",
    "    \"\"\"\n",
    "    pos_literal_count = defaultdict(lambda: [0, 0, 0])  # This default initialisation only works for 3 SAT\n",
    "    neg_literal_count = defaultdict(lambda: [0, 0, 0])\n",
    "    \n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if literal.startswith('-'):\n",
    "            for clauseNum in clauseNums:\n",
    "                clause = clauseNum_clause[clauseNum]\n",
    "                neg_literal_count[literal][len(clause)-1] += 1\n",
    "        else:\n",
    "            for clauseNum in clauseNums:\n",
    "                clause = clauseNum_clause[clauseNum]\n",
    "                pos_literal_count[literal][len(clause)-1] += 1\n",
    "                \n",
    "    final_count = []\n",
    "    # Sometimes we only have negative literals left. So then we just use those\n",
    "    for literal, pos_counts in (pos_literal_count.items() or neg_literal_count.items()):\n",
    "        other_literal = switch_literal(literal)\n",
    "        \n",
    "        if literal.startswith('-'):\n",
    "            # pos_literal_counts is empty. So literal and pos_counts actually are neg_literal_counts\n",
    "            neg_counts = pos_literal_count[other_literal]\n",
    "        else:\n",
    "            # pos_literal_counts isn't empty. So continue as normal\n",
    "            neg_counts = neg_literal_count[other_literal]\n",
    "        \n",
    "        final_count.append(([max(p, n) + 2 * min(p, n) for p, n in zip(pos_counts, neg_counts)], literal))\n",
    "            \n",
    "    final_count.sort(reverse=True)\n",
    "    score_vector, literal = final_count[0]\n",
    "    other_literal = switch_literal(literal)\n",
    "    \n",
    "    if literal.startswith('-'):\n",
    "        neg_literal = literal\n",
    "        pos_literal = other_literal\n",
    "    else:\n",
    "        neg_literal = other_literal\n",
    "        pos_literal = literal\n",
    "    \n",
    "    # Since the score for positive and negative literal is the same, choose one which the highest overall score\n",
    "    if sum(pos_literal_count[pos_literal]) >= sum(neg_literal_count[neg_literal]):\n",
    "        literal = pos_literal\n",
    "    else:\n",
    "        literal = neg_literal\n",
    "    \n",
    "    return literal, score_vector\n",
    "    \n",
    "\n",
    "def set_var(literal, boolean, literal_clauseNum, clauseNum_clause, literal_boolen):\n",
    "    literal_boolen[literal] = boolean\n",
    "\n",
    "    if boolean == False:\n",
    "        literal = switch_literal(literal)\n",
    "        literal_boolen[literal] = True\n",
    "    \n",
    "    # Unit-prop logic below\n",
    "    pairs_to_delete = []\n",
    "    for clauseNums_with_literal in literal_clauseNum[literal]:\n",
    "        for literals_in_clauseNums in clauseNum_clause[clauseNums_with_literal]:\n",
    "            pairs_to_delete.append((literals_in_clauseNums, clauseNums_with_literal))\n",
    "\n",
    "    #         print(pairs_to_delete)\n",
    "\n",
    "    for literals_in_clauseNums, clauseNums_with_literal in pairs_to_delete:\n",
    "        literal_clauseNum[literals_in_clauseNums].discard(clauseNums_with_literal)\n",
    "        if clauseNums_with_literal in clauseNum_clause:\n",
    "            del clauseNum_clause[clauseNums_with_literal]\n",
    "\n",
    "    # For all the clauses with opposite literal, remove the literal from the clause\n",
    "    if switch_literal(literal) not in literal_clauseNum: # if the opposite variable doesn't exist, skip\n",
    "        return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "    opposite_literal = switch_literal(literal)\n",
    "    literal_boolen[opposite_literal] = False\n",
    "\n",
    "    for clauseNums_with_literal in literal_clauseNum[opposite_literal]:\n",
    "        clauseNum_clause[clauseNums_with_literal].discard(opposite_literal)\n",
    "\n",
    "    literal_clauseNum[opposite_literal] = set()  # It is not watching any clauses anymore\n",
    "\n",
    "    #         print(\"OPPO\")\n",
    "    #         print(literal_clauseNum)\n",
    "    #         print(clauseNum_clause)\n",
    "    \n",
    "    return literal_clauseNum, clauseNum_clause, literal_boolen\n",
    "\n",
    "def choose_var(literal_clauseNum, clauseNum_clause, literal_boolen, algo='maxo'):\n",
    "    # Choosing the first literal every time\n",
    "#     remaining_clauses = list(clauseNum_clause.values())\n",
    "#     literal = remaining_clauses[0].pop()\n",
    "#     remaining_clauses[0].add(literal)\n",
    "\n",
    "    # Using heuristics\n",
    "    if algo == 'maxo':\n",
    "        literal, _ = maxo(literal_clauseNum)\n",
    "    elif algo == 'moms':\n",
    "        literal, _ = moms(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'mams':\n",
    "        literal, _ = mams(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'jw':\n",
    "        literal, _ = jw(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'jw_2':\n",
    "        literal, _ = jw_2(literal_clauseNum, clauseNum_clause)\n",
    "    elif algo == 'bohm':\n",
    "        literal, _ = bohm(literal_clauseNum, clauseNum_clause)\n",
    "    \n",
    "\n",
    "    return literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that are used by the Env class to get state features\n",
    "\n",
    "def number_of_variables(literal_clauseNum):\n",
    "    \"\"\" Returns the number of total variables (including repeats) present in the remaining clauses \"\"\"\n",
    "    return sum(map(len, literal_clauseNum.values()))\n",
    "\n",
    "\n",
    "def horn_clause_ratio(clauseNum_clause):\n",
    "    \"\"\" Returns the ratio of horn clauses to total number of clauses \"\"\"\n",
    "    horn_count = 0\n",
    "    total_count = 0\n",
    "    for clause in clauseNum_clause.values():\n",
    "        if len(clause) > 0:\n",
    "            total_count += 1\n",
    "        if len(list(filter(lambda x: not x.startswith('-'), clause))) == 1:\n",
    "            horn_count += 1\n",
    "\n",
    "    return horn_count / total_count if total_count > 0 else 0\n",
    "\n",
    "\n",
    "def horn_clause_count(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    For each variable, we count the number of Horn clauses it is present in\n",
    "    \"\"\"\n",
    "    literal_count = defaultdict(int)\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            clause = clauseNum_clause[clauseNum]\n",
    "            if len(list(filter(lambda x: not x.startswith('-'), clause))) == 1:\n",
    "                literal_count[literal] += 1\n",
    "                \n",
    "    counts = list(literal_count.values())\n",
    "    return np.array(counts) if len(counts) > 0 else np.array([0])\n",
    "\n",
    "\n",
    "def clause_to_variable_ratio(literal_clauseNum):\n",
    "    \"\"\" Returns the clause to variable ratio: c/v which predict problem hardness \"\"\"\n",
    "    clauses = set()\n",
    "    num_literals = 0\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if len(clauseNums) > 0:\n",
    "            clauses = clauses.union(clauseNums)\n",
    "            if literal.startswith('-'):\n",
    "                num_literals += 1\n",
    "            else:\n",
    "                num_literals += 1\n",
    "\n",
    "    return 0 if num_literals == 0 else len(clauses) / num_literals\n",
    "\n",
    "\n",
    "def pos_neg_ratio(literal_clauseNum):\n",
    "    \"\"\"\n",
    "    Returns the number of positive literals (incl repeats) to negative literals (incl repeats) in the clauses.\n",
    "    THIS DOESN'T GIVE USEFUL STATE INFORMATION WHEN USED ALONE\n",
    "    \"\"\"\n",
    "    pos_literal_count = 0\n",
    "    neg_literal_count = 0\n",
    "\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        if literal.startswith('-'):\n",
    "            neg_literal_count += len(clauseNums)\n",
    "        else:\n",
    "            pos_literal_count += len(clauseNums)\n",
    "\n",
    "    return pos_literal_count / neg_literal_count if neg_literal_count > 0 else pos_literal_count\n",
    "\n",
    "def pos_neg_ratio_per_var():\n",
    "    pass\n",
    "\n",
    "\n",
    "def CVIG(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Caluse-variable incidence graph. We create a bipartite graph (a matrix) with literals in columns and clauses in rows.\n",
    "    See Features_2 PDF file.\n",
    "    \"\"\"\n",
    "    if len(clauseNum_clause) == 0:\n",
    "        return 0\n",
    "    \n",
    "    literal_index_mapping = {}\n",
    "    clauseNum_index_mapping = {}\n",
    "    \n",
    "    for i, literal in enumerate(literal_clauseNum.keys()):\n",
    "        literal_index_mapping[literal] = i\n",
    "        \n",
    "    for i, clauseNum in enumerate(clauseNum_clause):\n",
    "        clauseNum_index_mapping[clauseNum] = i\n",
    "    \n",
    "    graph = np.zeros((len(literal_index_mapping), len(clauseNum_index_mapping)))\n",
    "    for literal, clauseNums in literal_clauseNum.items():\n",
    "        for clauseNum in clauseNums:\n",
    "            graph[literal_index_mapping[literal]] [clauseNum_index_mapping[clauseNum]] = 1/len(clauseNums)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def VIG(literal_clauseNum, clauseNum_clause):\n",
    "    \"\"\"\n",
    "    Variable incidence graph.\n",
    "    \"\"\"\n",
    "    if len(clauseNum_clause) == 0:\n",
    "        return 0\n",
    "    \n",
    "    literal_index_mapping = {}\n",
    "    \n",
    "    for i, literal in enumerate(literal_clauseNum.keys()):\n",
    "        literal_index_mapping[literal] = i\n",
    "        \n",
    "    graph = np.zeros((len(literal_index_mapping), len(literal_index_mapping)))\n",
    "    \n",
    "    for clause in clauseNum_clause.values():\n",
    "        if len(clause) < 2:\n",
    "            continue\n",
    "        for x, y in combinations(clause, 2):\n",
    "            w = 1 / (comb(len(clause), 2))  # Try combinations with replacement to add self-loops\n",
    "            graph[literal_index_mapping[x]][literal_index_mapping[y]] = w\n",
    "            graph[literal_index_mapping[y]][literal_index_mapping[x]] = w\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = Env('../Tests/SATLIB_20/uf20-026.cnf')\n",
    "# print(env.reset())\n",
    "# while True:\n",
    "#     _, _, done = env.step(4)\n",
    "#     if done:\n",
    "#         break\n",
    "#     print(env.get_state())\n",
    "# #     a, b, c = env.state\n",
    "# #     print(jw_2(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    def __init__(self, input_file):\n",
    "        self.input_file = input_file\n",
    "        self.stack = [] # We use a stack to hold the next states to explore. i.e. we do DFS as less memory requirements than BFS\n",
    "        self.state = None\n",
    "        self.actions = {0: 'maxo', 1: 'moms', 2: 'mams', 3: 'jw', 4: 'jw_2', 5: 'bohm'}\n",
    "        self.action_penalty = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: -0.25}  # Penalty to give each action\n",
    "    \n",
    "    def reset(self):\n",
    "        # Returns state\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen, _ = parse_input(self.input_file)\n",
    "        self.state = (literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = self.state\n",
    "        \n",
    "        num_var = number_of_variables(literal_clauseNum)\n",
    "        horn_clause = horn_clause_ratio(clauseNum_clause)\n",
    "#         var_horn_counts = horn_clause_count(literal_clauseNum, clauseNum_clause)\n",
    "#         var_horn_mean, var_horn_var = np.mean(var_horn_counts), np.var(var_horn_counts)\n",
    "        \n",
    "        pn_ratio = pos_neg_ratio(literal_clauseNum)\n",
    "        c_v_ratio = clause_to_variable_ratio(literal_clauseNum)\n",
    "        \n",
    "        cvig_graph = CVIG(literal_clauseNum, clauseNum_clause)\n",
    "        cvig_mean, cvig_var = np.mean(cvig_graph), np.var(cvig_graph)  # axis=0 gives more different results if we want this to return vector\n",
    "        \n",
    "        vig_graph = VIG(literal_clauseNum, clauseNum_clause)\n",
    "        vig_mean, vig_var = np.mean(vig_graph), np.var(vig_graph)\n",
    "        \n",
    "        return [num_var, c_v_ratio, pn_ratio, horn_clause, cvig_mean, cvig_var, vig_mean, vig_var]\n",
    "#         return [num_var, horn_clause, var_horn_mean, var_horn_var, pn_ratio, c_v_ratio, cvig_mean, cvig_var, vig_mean, vig_var]\n",
    "#         return num_var\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns: next_state_1, next_state_2, reward, done\n",
    "        reward = 0 if reached a leaf node, 0 if not\n",
    "        \"\"\"\n",
    "        if self.state is None:\n",
    "            set_trace()\n",
    "        \n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = self.state\n",
    "        \n",
    "        num_clauses_start = 0\n",
    "        for clause in clauseNum_clause.values():\n",
    "            if len(clause) > 0:\n",
    "                num_clauses_start += 1\n",
    "                \n",
    "        if num_clauses_start > 0:\n",
    "            fraction_of_clauses_removed = num_clauses_start/num_clauses_start\n",
    "        else:\n",
    "            fraction_of_clauses_removed = 0\n",
    "        \n",
    "        unassigned_nodes_start = len(list(filter(lambda x: len(x) > 0, literal_clauseNum.values())))\n",
    "        \n",
    "        # Do unit prop\n",
    "        empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \\\n",
    "            unit_prop(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "        if empty_clause:\n",
    "            isEmpty = len(self.stack) == 0\n",
    "            if isEmpty:\n",
    "                self.state = {}, {}, {}\n",
    "            else:\n",
    "                self.state = self.stack.pop()\n",
    "            \n",
    "            return None, -1 + self.action_penalty[action] + fraction_of_clauses_removed, isEmpty\n",
    "#             return None, -1 + self.action_penalty[action], isEmpty\n",
    "        \n",
    "        if clauseNum_clause == {}:\n",
    "            self.state = {}, {}, {}\n",
    "            # return None, 1 + self.action_penalty[action] + fraction_of_clauses_removed, True\n",
    "            return None, 1 + self.action_penalty[action], True\n",
    "        \n",
    "        # Do pure literal elimination\n",
    "        literal_clauseNum, clauseNum_clause, literal_boolen = \\\n",
    "            pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "        if clauseNum_clause == {}:\n",
    "            self.state = {}, {}, {}\n",
    "            # return None, 1 + self.action_penalty[action] + fraction_of_clauses_removed, True\n",
    "            return None, 1 + self.action_penalty[action], True\n",
    "        \n",
    "        literal = choose_var(literal_clauseNum, clauseNum_clause, literal_boolen, algo=self.actions[action])\n",
    "        \n",
    "        \n",
    "        # Set the chosen literal to be True\n",
    "        literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T = \\\n",
    "            set_var(literal, True, deepcopy(literal_clauseNum), deepcopy(clauseNum_clause), dict(literal_boolen))\n",
    "            \n",
    "#         print(\"After setting\", literal, \"to True\")\n",
    "#         print(literal_clauseNum_T)\n",
    "#         print(literal_boolen_T)\n",
    "#         print()\n",
    "        \n",
    "#         unassigned_nodes_T = len(filter(lambda x: len(x) > 0, literal_clauseNum_T.values()))\n",
    "        \n",
    "#         # Do unit prop and pure literal elimnation and record the number of nodes assigned\n",
    "#         empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             unit_prop(literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T)\n",
    "        \n",
    "#         if empty_clause:\n",
    "#             return 0, 0, unassigned_nodes_start, self.q.empty()\n",
    "        \n",
    "#         # Do pure literal elimination\n",
    "#         literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         if clauseNum_clause == {}:\n",
    "#             return 0, 0, unassigned_nodes_start, True\n",
    "        \n",
    "        # Set new state\n",
    "        self.state = (literal_clauseNum_T, clauseNum_clause_T, literal_boolen_T)\n",
    "        \n",
    "        # Set the chosen literal to be False\n",
    "        literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F = \\\n",
    "            set_var(literal, False, literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         print(\"After setting\", literal, \"to False\")\n",
    "#         print(literal_clauseNum_F)\n",
    "#         print(literal_boolen_F)\n",
    "#         print()\n",
    "            \n",
    "#         unassigned_nodes_F = len(filter(lambda x: len(x) > 0, literal_clauseNum_F.values()))\n",
    "            \n",
    "#         # Do unit prop and pure literal elimnation and record the number of nodes assigned\n",
    "#         empty_clause, literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             unit_prop(literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F)\n",
    "        \n",
    "#         if empty_clause:\n",
    "#             return 0, 0, unassigned_nodes_start, self.q.empty()\n",
    "        \n",
    "#         # Do pure literal elimination\n",
    "#         literal_clauseNum, clauseNum_clause, literal_boolen = \n",
    "#             pure_literal(literal_clauseNum, clauseNum_clause, literal_boolen)\n",
    "            \n",
    "#         if clauseNum_clause == {}:\n",
    "#             return 0, 0, unassigned_nodes_start, True\n",
    "\n",
    "        # Add new state to queue\n",
    "        self.stack.append((literal_clauseNum_F, clauseNum_clause_F, literal_boolen_F))\n",
    "        \n",
    "        num_clauses_end = 0\n",
    "        for clause in clauseNum_clause_T.values():\n",
    "            if len(clause) > 0:\n",
    "                num_clauses_end += 1\n",
    "        \n",
    "        if num_clauses_start > 0:\n",
    "            fraction_of_clauses_removed = (num_clauses_start - num_clauses_end)/num_clauses_start\n",
    "        else:\n",
    "            fraction_of_clauses_removed = 0\n",
    "        \n",
    "        if clauseNum_clause_T == {} or clauseNum_clause_F == {}:  # We have satisfied\n",
    "            fraction_of_clauses_removed = 1\n",
    "            self.state = {}, {}, {}\n",
    "            # return None, 1 + self.action_penalty[action] + fraction_of_clauses_removed, True\n",
    "            return None, 1 + self.action_penalty[action], True\n",
    "        else:\n",
    "            return None, -1 + self.action_penalty[action] + fraction_of_clauses_removed, False\n",
    "#             return None, -1 + self.action_penalty[action], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import SGDRegressor\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# class Estimator():\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         # We create a separate model for each action in the environment's\n",
    "#         # action space. Alternatively we could somehow encode the action\n",
    "#         # into the features, but this way it's easier to code up.\n",
    "#         self.models = []\n",
    "#         for _ in range(actions):\n",
    "#             model = SGDRegressor(learning_rate=\"constant\", eta0=0.001, penalty='l2')\n",
    "#             # We need to call partial_fit once to initialize the model\n",
    "#             # or we get a NotFittedError when trying to make a prediction\n",
    "#             # This is quite hacky.\n",
    "#             model.partial_fit([self.featurize_state(np.zeros(state_space))], [0])\n",
    "#             self.models.append(model)\n",
    "#         self.scaler = StandardScaler()\n",
    "#         self.scaler.fit([self.featurize_state(np.zeros(state_space))], [np.zeros(state_space)])\n",
    "    \n",
    "#     def featurize_state(self, state):\n",
    "#         # Needs to return a 1D array\n",
    "#         if use_poly:\n",
    "#             state = int(state)\n",
    "#             return np.array([state**i for i in range(1, poly_degree+1)])\n",
    "#         else:\n",
    "#             return np.array(state)\n",
    "    \n",
    "#     def predict(self, state):\n",
    "#         state_feature = self.featurize_state(state)\n",
    "#         state_feature = self.scaler.transform([state_feature]) # Returns a 2D array\n",
    "#         return np.array([m.predict(state_feature)[0] for m in self.models])\n",
    "    \n",
    "#     def update(self, state, action, reward):\n",
    "#         model = self.models[action]\n",
    "#         state_feature = self.featurize_state(state)\n",
    "        \n",
    "#         self.scaler.partial_fit([state_feature])\n",
    "#         state_feature = self.scaler.transform([state_feature]) # Returns a 2D array\n",
    "#         model.partial_fit(state_feature, [reward])\n",
    "        \n",
    "#         return 0\n",
    "        \n",
    "# #         print(\"After update:\", model.predict(state_feature)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aks73/python/Python-3.5.1/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "class Estimator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.create_model()\n",
    "        \n",
    "        self.model = Model(inputs=self.input, outputs=self.output)\n",
    "        self.action_index = K.placeholder(dtype=tf.int32, name='action_index')\n",
    "        self.target = K.placeholder(dtype=tf.float32, name='target')\n",
    "        \n",
    "        self.chosen_action_qval = tf.gather(self.output, self.action_index, axis=1)\n",
    "        self.loss = tf.reduce_mean(tf.squared_difference(self.target, self.chosen_action_qval))\n",
    "        \n",
    "        self.optimiser = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.train_op = self.optimiser.minimize(self.loss)\n",
    "        \n",
    "    \n",
    "    def create_model(self):\n",
    "        self.input = Input(shape=(state_space,))\n",
    "        self.h1 = Dense(4, activation='sigmoid')(self.input)\n",
    "        self.h2 = Dense(2, activation='sigmoid')(self.h1)\n",
    "        self.output = Dense(actions, activation=None)(self.h2)\n",
    "        \n",
    "        \n",
    "    def featurize_state(self, state):\n",
    "        # Needs to return a 1D array\n",
    "        return np.array(state)\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state = self.featurize_state(state)\n",
    "        if len(self.input.shape) != len(state.shape):\n",
    "            state = np.expand_dims(state, 0)\n",
    "        return np.squeeze(self.model.predict(state))\n",
    "    \n",
    "    def update(self, state, action_index, target):\n",
    "        \"\"\" action: action_index of the literal we chose \"\"\"\n",
    "        state = self.featurize_state(state)\n",
    "        sess = tf.get_default_session()\n",
    "        if len(self.input.shape) != len(state.shape):\n",
    "            state = np.expand_dims(state, 0)\n",
    "        # Update shapes of targets and action_index to incorporate batch size\n",
    "#         target = np.expand_dims(target, 1)\n",
    "#         action_index = np.expand_dims(action_index, 1)\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict={self.input: state, self.action_index: action_index, \n",
    "                                                                  self.target: target, K.learning_phase(): 1})\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "    \n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        epsilon: The probability to select a random action . float between 0 and 1.\n",
    "        nA: Number of actions in the environment.\n",
    "    \n",
    "    Returns:\n",
    "        A function that takes the observation as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "    \n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        if epsilon > np.random.rand():\n",
    "            return np.ones(nA) / nA\n",
    "        else:\n",
    "            action_value = estimator.predict(observation)\n",
    "            action = np.argmax(action_value)\n",
    "            ans = np.zeros(nA)\n",
    "            ans[action] = 1\n",
    "            return ans\n",
    "\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_test(env, estimator, epsilon):\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "#     states = []\n",
    "    episode_actions = []\n",
    "    \n",
    "    policy = make_epsilon_greedy_policy(estimator, epsilon, actions)\n",
    "\n",
    "    state = env.reset()\n",
    "#     states.append(state)\n",
    "\n",
    "    while True:\n",
    "#         action_prob = policy(state)\n",
    "#         action = np.random.choice(np.arange(len(action_prob)), p=action_prob)\n",
    "        action = 1\n",
    "        episode_actions.append(action)\n",
    "        _, reward, done = env.step(action)\n",
    "        \n",
    "        # Stats\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        state = env.get_state()\n",
    "#         states.append(state)\n",
    "\n",
    "    return episode_reward, episode_length, episode_actions # , states\n",
    "\n",
    "\n",
    "def test(test_files, epochs=10, ϵ=1.1, estimator=None):\n",
    "    \"\"\"\n",
    "    This method is used to either:\n",
    "    \n",
    "     - Run a random policy on the test data and returns the avg. reward and length per epoch (epoch runs over the test_files).\n",
    "     This can be done by only passing on first two parameters (and optionally epochs for longer runs)\n",
    "     \n",
    "     - Run an epilon-greedy policy with the given estimator. Pass an estimator that we receive from the train() method and set \n",
    "     the ϵ value appropriately to make an epsilon-greedy policy. Runs this policy over the test_files for given number of epochs.\n",
    "    \n",
    "    Returns dictionary of {epoch: average reward} and {epoch: average length per episode/file}\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length, states, epoch_actions = [], [], [], []\n",
    "    \n",
    "    if estimator is None:\n",
    "        estimator = Estimator()  # Never used if epsilon > 1 \n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "\n",
    "        shuffle(test_files)\n",
    "        \n",
    "        for filepath in test_files:\n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length, episode_actions = q_learning_test(env, estimator, ϵ)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "#             states.extend(episode_states)\n",
    "            epoch_actions.extend(episode_actions)\n",
    "            \n",
    "        # Average reward per training example in this epoch\n",
    "        epoch_reward.append(curr_epoch_reward / len(test_files))\n",
    "\n",
    "        # Average episode length per example in this epoch\n",
    "        epoch_length.append(curr_epoch_length / len(test_files))\n",
    "            \n",
    "            \n",
    "    return epoch_reward, epoch_length, epoch_actions #, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def DQN_make_epsilon_greedy_policy(estimator, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "\n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        nA: Number of actions in the environment.\n",
    "\n",
    "    Returns:\n",
    "        A function that takes the (sess, observation, epsilon) as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "\n",
    "    \"\"\"\n",
    "    def policy_fn(observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        q_values = estimator.predict(observation)\n",
    "        best_action = np.argmax(q_values)\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn\n",
    "\n",
    "\n",
    "def copy_params(copy_from_est, copy_to_est):\n",
    "    copy_to_est.model = copy_from_est.model \n",
    "\n",
    "\n",
    "def DQN(training_files, batch_size=512, discount_factor=1.0):\n",
    "    \n",
    "    q_estimator = Estimator()\n",
    "    target_estimator = Estimator()\n",
    "    \n",
    "    replay_memory = []\n",
    "    rewards_every_1000 = []\n",
    "    length_every_1000 = []\n",
    "    \n",
    "    # The epsilon decay schedule\n",
    "    epsilons = np.linspace(1.0, 0.1, 500000)\n",
    "    \n",
    "    # The policy we're following\n",
    "    policy = DQN_make_epsilon_greedy_policy(q_estimator, actions)\n",
    "    \n",
    "    print(\"Starting populating memory\")\n",
    "    # Populate memory\n",
    "    for i, filepath in enumerate(training_files[:1000]):\n",
    "        env = Env(filepath)\n",
    "        state = env.reset()\n",
    "        \n",
    "        while True:\n",
    "            action_probs = policy(state, epsilons[min(len(replay_memory), len(epsilons)-1)])\n",
    "            action =  np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "            _, reward, done = env.step(action)\n",
    "            next_state = env.get_state()\n",
    "            replay_memory.append((state, action, reward, next_state, done))\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "    max_memory = len(replay_memory) * 3\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Starting training\")\n",
    "    \n",
    "    curr_reward = 0\n",
    "    curr_length = 0\n",
    "    output_stats_every = 500\n",
    "    \n",
    "    for i, filepath in enumerate(training_files[1000:]):\n",
    "        \n",
    "        env = Env(filepath)\n",
    "        state = env.reset()\n",
    "        \n",
    "        if i % output_stats_every == 0:\n",
    "            print(i, curr_reward / output_stats_every, curr_length / output_stats_every)\n",
    "            rewards_every_1000.append(curr_reward / output_stats_every)\n",
    "            length_every_1000.append(curr_length / output_stats_every)\n",
    "            \n",
    "            curr_reward = 0\n",
    "            curr_length = 0\n",
    "            \n",
    "            # Copy model parameters over\n",
    "            copy_params(q_estimator, target_estimator)\n",
    "        \n",
    "        # Epsilon for this time step\n",
    "        epsilon = epsilons[min(len(replay_memory)-1, len(epsilons)-1)]\n",
    "        \n",
    "        while True:\n",
    "            action_probs = policy(state, epsilon)\n",
    "            action =  np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "            _, reward, done = env.step(action)\n",
    "            \n",
    "            next_state = env.get_state()\n",
    "            \n",
    "            replay_memory.append((state, action, reward, next_state, done))\n",
    "            if len(replay_memory) > max_memory:\n",
    "                replay_memory.pop(0)\n",
    "                \n",
    "            # Update stats\n",
    "            curr_reward += reward\n",
    "            curr_length += 1\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Sample a minibatch from the replay memory\n",
    "        samples = random.sample(replay_memory, batch_size)\n",
    "        states_batch, action_batch, reward_batch, next_states_batch, done_batch = map(np.array, zip(*samples))\n",
    "        \n",
    "        # Calculate q values and targets\n",
    "        q_values_next = target_estimator.predict(next_states_batch)\n",
    "        targets_batch = reward_batch + np.invert(done_batch).astype(np.float32) * discount_factor * np.amax(q_values_next, axis=1)\n",
    "        \n",
    "        q_estimator.update(states_batch, action_batch, targets_batch)\n",
    "        \n",
    "        \n",
    "    return rewards_every_1000, length_every_1000, q_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 20000\n",
      "Number of test files: 1000\n",
      "Starting populating memory\n",
      "Starting training\n",
      "0 0.0 0.0\n",
      "500 -6.751576695082405 15.36\n",
      "1000 -6.25685459301753 14.24\n",
      "1500 -6.569313903163832 14.906\n",
      "2000 -6.322112863137822 14.528\n",
      "2500 -6.440938093082343 14.842\n",
      "3000 -6.342812850213525 14.526\n",
      "3500 -6.266044472621859 14.302\n",
      "4000 -6.538725358803097 14.88\n",
      "4500 -6.380263334504246 14.608\n",
      "5000 -6.620655685845304 15.086\n",
      "5500 -6.506929735163908 14.826\n",
      "6000 -6.407743590209486 14.728\n",
      "6500 -6.173551680986822 14.116\n",
      "7000 -6.328370668932327 14.352\n",
      "7500 -6.653318533662865 15.258\n",
      "8000 -6.56048211405593 14.978\n",
      "8500 -6.650725905409718 15.146\n",
      "9000 -6.308495362833547 14.342\n",
      "9500 -6.644677566160474 15.134\n",
      "10000 -6.319811175942544 14.494\n",
      "10500 -6.454658403787536 14.966\n",
      "11000 -6.103737923166775 13.992\n",
      "11500 -6.572999427208518 15.15\n",
      "12000 -6.457431758265277 14.874\n",
      "12500 -6.496366595728712 14.782\n",
      "13000 -6.302744525318524 14.322\n",
      "13500 -6.555922551162576 15.058\n",
      "14000 -6.363544668585579 14.534\n",
      "14500 -6.646065792895166 15.266\n",
      "15000 -6.621050360769309 15.288\n",
      "15500 -6.487232486318019 14.826\n",
      "16000 -6.5456170939467695 15.008\n",
      "16500 -6.404923758569032 14.722\n",
      "17000 -6.622494166281948 15.1\n",
      "17500 -6.554963213652772 15.076\n",
      "18000 -6.428652820037783 14.78\n",
      "18500 -6.433702060639876 14.812\n",
      "Done training in 1514.35 s\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e3ebaa41fb13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mepisode_reward_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_length_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mϵ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_reward_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_length_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "actions = 6       # Number of actions available to use by the agent\n",
    "state_space = 8   # Number of variables we return as state of environment. Used to initialise Scaler and SGD in Estimator\n",
    "\n",
    "directory = '../Tests/CNFGEN_20/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "files = os.listdir(directory)\n",
    "files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "\n",
    "split = int(len(files) * 0.2)\n",
    "training_files = files[:split]\n",
    "shuffle(training_files)\n",
    "\n",
    "test_files = files[60000:61000]\n",
    "\n",
    "print(\"Number of training files:\", len(training_files))\n",
    "print(\"Number of test files:\", len(test_files))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    \n",
    "    s = time.time()\n",
    "    episode_reward_train, episode_length_train, estimator = DQN(training_files)\n",
    "#     episode_reward_train_2, episode_length_train_2, estimator_2, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "#     episode_reward_train_3, episode_length_train_3, estimator_3, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "    e = time.time()\n",
    "    print(\"Done training in\", (round(e-s, 2)), \"s\")\n",
    "    print()\n",
    "    est = estimator\n",
    "\n",
    "    s = time.time()\n",
    "    episode_reward_test, episode_length_test, episode_actions = test(test_files, epochs=1, ϵ=0, estimator=est)\n",
    "    print(episode_reward_test, episode_length_test)\n",
    "    \n",
    "    print(np.bincount(episode_actions))\n",
    "    e = time.time()\n",
    "    print(\"Done testing in\", (round(e-s, 2)), \"s\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "#     s = time.time()\n",
    "#     episode_reward_rand, episode_length_rand, episode_actions = test(test_files, epochs=1)\n",
    "#     e = time.time()\n",
    "#     print(np.bincount(episode_actions))\n",
    "#     print(episode_reward_rand, episode_length_rand)\n",
    "#     print(\"Done testing random policy in \", (round(e-s, 2)), \"s\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-14-9ebbbbcd27e6>\u001b[0m(42)\u001b[0;36mstep\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     40 \u001b[0;31m        \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreached\u001b[0m \u001b[0ma\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     41 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m---> 42 \u001b[0;31m        \u001b[0mliteral_clauseNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclauseNum_clause\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliteral_boolen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m        \u001b[0mnum_clauses_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> self.state\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-22-9b5a59680a54>\u001b[0m(92)\u001b[0;36mDQN\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     90 \u001b[0;31m            \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     91 \u001b[0;31m            \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 92 \u001b[0;31m            \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     93 \u001b[0;31m            \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     94 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> action\n",
      "1\n",
      "ipdb> d\n",
      "> \u001b[0;32m<ipython-input-14-9ebbbbcd27e6>\u001b[0m(42)\u001b[0;36mstep\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     40 \u001b[0;31m        \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreached\u001b[0m \u001b[0ma\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     41 \u001b[0;31m        \"\"\"\n",
      "\u001b[0m\u001b[0;32m---> 42 \u001b[0;31m        \u001b[0mliteral_clauseNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclauseNum_clause\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliteral_boolen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m        \u001b[0mnum_clauses_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> l\n",
      "\u001b[1;32m     37 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     38 \u001b[0m        \"\"\"\n",
      "\u001b[1;32m     39 \u001b[0m        \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext_state_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     40 \u001b[0m        \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreached\u001b[0m \u001b[0ma\u001b[0m \u001b[0mleaf\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     41 \u001b[0m        \"\"\"\n",
      "\u001b[0;32m---> 42 \u001b[0;31m        \u001b[0mliteral_clauseNum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclauseNum_clause\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mliteral_boolen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     43 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     44 \u001b[0m        \u001b[0mnum_clauses_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     45 \u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mclause\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclauseNum_clause\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     46 \u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclause\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     47 \u001b[0m                \u001b[0mnum_clauses_start\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, estimator, discount_factor=1.0, epsilon=0.1, epsilon_decay=1.0, train_phase=True):\n",
    "    \"\"\"\n",
    "    Goes through the environment only once (stops when we reach a finishing state in the environment)\n",
    "    \"\"\"\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "    loss = 0\n",
    "    \n",
    "#     policy = make_epsilon_greedy_policy(estimator, epsilon * epsilon_decay**i_episode, actions)\n",
    "#     Since we do not iterate over in q_learning, we do not have i_episode above. See if that is useful here and below (near end)\n",
    "    policy = make_epsilon_greedy_policy(estimator, epsilon*epsilon_decay, actions)\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action_prob = policy(state)\n",
    "        action = np.random.choice(np.arange(len(action_prob)), p=action_prob)\n",
    "#         action = 5\n",
    "        _, reward, done = env.step(action)\n",
    "        \n",
    "        # Stats\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            td_target = reward\n",
    "            if train_phase:\n",
    "                loss += estimator.update(state, action, td_target)\n",
    "            break\n",
    "\n",
    "        next_state = env.get_state()\n",
    "\n",
    "        q_values = estimator.predict(next_state)\n",
    "        td_target = reward + discount_factor * np.max(q_values)\n",
    "        \n",
    "        current_value = estimator.predict(state)[action]\n",
    "        td_error = td_target - current_value\n",
    "        \n",
    "        alpha = 0.8\n",
    "        update_target = current_value + alpha*td_error\n",
    "        if train_phase:\n",
    "            loss += estimator.update(state, action, update_target)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    return episode_reward, episode_length, estimator, loss\n",
    "\n",
    "\n",
    "def q_learning_test(env, estimator, epsilon):\n",
    "    episode_length = 0\n",
    "    episode_reward = 0\n",
    "#     states = []\n",
    "    episode_actions = []\n",
    "    \n",
    "    policy = make_epsilon_greedy_policy(estimator, epsilon, actions)\n",
    "\n",
    "    state = env.reset()\n",
    "#     states.append(state)\n",
    "\n",
    "    while True:\n",
    "#         action_prob = policy(state)\n",
    "#         action = np.random.choice(np.arange(len(action_prob)), p=action_prob)\n",
    "        action = 1\n",
    "        episode_actions.append(action)\n",
    "        _, reward, done = env.step(action)\n",
    "        \n",
    "        # Stats\n",
    "        episode_length += 1\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        state = env.get_state()\n",
    "#         states.append(state)\n",
    "\n",
    "    return episode_reward, episode_length, episode_actions # , states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(training_files, epochs, ϵ, epsilon_decay=0.97):\n",
    "    \"\"\"\n",
    "    One episode is one file. Each call to q_learning function does one episode only and returns. \n",
    "    An Env can be instantiated with one file only, so can only do one episode.\n",
    "    \n",
    "    In one epoch, you go through all the files in your training dataset.\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length, losses = [], [], []\n",
    "    estimator = Estimator()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "        curr_epoch_loss = 0\n",
    "\n",
    "        \n",
    "#         shuffle(training_files)  # Shuffles files in-place\n",
    "\n",
    "        for j, filepath in enumerate(training_files):\n",
    "            \"\"\" Each file in one episode \"\"\"\n",
    "            \n",
    "            if j % 1000 == 0:\n",
    "                part = j // 1000\n",
    "                print(part)\n",
    "                epsilon_decay_j = epsilon_decay**part\n",
    "                epoch_reward.append(curr_epoch_reward / 1000)\n",
    "                epoch_length.append(curr_epoch_length / 1000)\n",
    "                losses.append(curr_epoch_loss / 1000)\n",
    "                \n",
    "                print(epoch_reward[-1], epoch_length[-1], losses[-1])\n",
    "                \n",
    "                curr_epoch_length = 0\n",
    "                curr_epoch_reward = 0\n",
    "                curr_epoch_loss = 0\n",
    "                \n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length, estimator, loss = q_learning(env, estimator, epsilon=ϵ, epsilon_decay=epsilon_decay_j)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "            curr_epoch_loss += loss\n",
    "            \n",
    "        epoch_reward.append(curr_epoch_reward / 1000)\n",
    "        epoch_length.append(curr_epoch_length / 1000)\n",
    "        losses.append(curr_epoch_loss / 1000)\n",
    "            \n",
    "        # Average reward per episode in this epoch\n",
    "#         epoch_reward.append(curr_epoch_reward / len(training_files))\n",
    "\n",
    "        # Average length of each episode in this epoch\n",
    "#         epoch_length.append(curr_epoch_length / len(training_files))\n",
    "        \n",
    "        # Average loss of each episode in this epoch\n",
    "#         losses.append(curr_epoch_loss / len(training_files))\n",
    "        \n",
    "#         print(\"Reward:\", epoch_reward[-1])\n",
    "#         print(\"Length:\", epoch_length[-1])\n",
    "#         print(\"Loss:\", losses[-1])\n",
    "            \n",
    "    return epoch_reward, epoch_length, estimator, losses\n",
    "\n",
    "\n",
    "def test(test_files, epochs=10, ϵ=1.1, estimator=None):\n",
    "    \"\"\"\n",
    "    This method is used to either:\n",
    "    \n",
    "     - Run a random policy on the test data and returns the avg. reward and length per epoch (epoch runs over the test_files).\n",
    "     This can be done by only passing on first two parameters (and optionally epochs for longer runs)\n",
    "     \n",
    "     - Run an epilon-greedy policy with the given estimator. Pass an estimator that we receive from the train() method and set \n",
    "     the ϵ value appropriately to make an epsilon-greedy policy. Runs this policy over the test_files for given number of epochs.\n",
    "    \n",
    "    Returns dictionary of {epoch: average reward} and {epoch: average length per episode/file}\n",
    "    \"\"\"\n",
    "    epoch_reward, epoch_length, states, epoch_actions = [], [], [], []\n",
    "    \n",
    "    if estimator is None:\n",
    "        estimator = Estimator()  # Never used if epsilon > 1 \n",
    "    \n",
    "    for i in range(epochs):\n",
    "    # We iterate over all the files onces and then repeat it. Better than just repeating same file over multiple times\n",
    "    # We get knowledge of other files too when re-iterating over already seen files\n",
    "    \n",
    "        print(\"Epoch Number:\", i+1)\n",
    "        curr_epoch_length = 0\n",
    "        curr_epoch_reward = 0\n",
    "\n",
    "        shuffle(test_files)\n",
    "        \n",
    "        for filepath in test_files:\n",
    "            env = Env(filepath)\n",
    "            episode_reward, episode_length, episode_actions = q_learning_test(env, estimator, ϵ)\n",
    "            \n",
    "            curr_epoch_reward += episode_reward\n",
    "            curr_epoch_length += episode_length\n",
    "#             states.extend(episode_states)\n",
    "            epoch_actions.extend(episode_actions)\n",
    "            \n",
    "        # Average reward per training example in this epoch\n",
    "        epoch_reward.append(curr_epoch_reward / len(test_files))\n",
    "\n",
    "        # Average episode length per example in this epoch\n",
    "        epoch_length.append(curr_epoch_length / len(test_files))\n",
    "            \n",
    "            \n",
    "    return epoch_reward, epoch_length, epoch_actions #, states\n",
    "\n",
    "\n",
    "\n",
    "def spread(vals):\n",
    "    vals_range = vals - np.mean(vals)\n",
    "    return np.abs(np.min(vals_range)) + np.abs(np.max(vals_range))\n",
    "\n",
    "def VAR(mat):\n",
    "    return np.array([spread(mat[:, cols]) for cols in range(mat.shape[1])])\n",
    "\n",
    "def policy_use(states, estimator, length):\n",
    "    counts = [0]*6\n",
    "    count = 0\n",
    "    \n",
    "    mean = np.mean(states, axis=0)\n",
    "    var = VAR(states)\n",
    "\n",
    "#     for i0 in np.linspace(mean[0]-var[0]/2, mean[0]+var[0]/2, length):\n",
    "#         for i1 in np.linspace(mean[1]-var[1]/2, mean[1]+var[1]/2, length):\n",
    "#             for i2 in np.linspace(mean[2]-var[2]/2, mean[2]+var[2]/2, length):\n",
    "#                 for i3 in np.linspace(mean[3]-var[3]/2, mean[3]+var[3]/2, length):\n",
    "#                     for i4 in np.linspace(mean[4]-var[4]/2, mean[4]+var[4]/2, length):\n",
    "#                         for i5 in np.linspace(mean[5]-var[5]/2, mean[5]+var[5]/2, length):\n",
    "#                             for i6 in np.linspace(mean[6]-var[6]/2, mean[6]+var[6]/2, length):\n",
    "#                                 for i7 in np.linspace(mean[7]-var[7]/2, mean[7]+var[7]/2, length):\n",
    "#                                     state = [i0, i1, i2, i3, i4, i5, i6, i7]\n",
    "#                                     qvals = estimator.predict(state)\n",
    "#                                     counts[np.argmax(qvals)] += 1\n",
    "\n",
    "#                                     count += 1\n",
    "#                                     if count % 10000 == 0:\n",
    "#                                         print(count)\n",
    "\n",
    "\n",
    "    for _ in range(length):\n",
    "        i0 = np.random.uniform(mean[0]-var[0]/2, mean[0]+var[0]/2)\n",
    "        i1 = np.random.uniform(mean[1]-var[1]/2, mean[1]+var[1]/2)\n",
    "        i2 = np.random.uniform(mean[2]-var[2]/2, mean[2]+var[2]/2)\n",
    "        i3 = np.random.uniform(mean[3]-var[3]/2, mean[3]+var[3]/2)\n",
    "        i4 = np.random.uniform(mean[4]-var[4]/2, mean[4]+var[4]/2)\n",
    "        i5 = np.random.uniform(mean[5]-var[5]/2, mean[5]+var[5]/2)\n",
    "        i6 = np.random.uniform(mean[6]-var[6]/2, mean[6]+var[6]/2)\n",
    "        i7 = np.random.uniform(mean[7]-var[7]/2, mean[7]+var[7]/2)\n",
    "        state = [i0, i1, i2, i3, i4, i5, i6, i7]\n",
    "        qvals = estimator.predict(state)\n",
    "        counts[np.argmax(qvals)] += 1\n",
    "\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(count)\n",
    "                                        \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 20000\n",
      "Number of test files: 1000\n",
      "Epoch Number: 1\n",
      "0\n",
      "0.0 0.0 0.0\n",
      "1\n",
      "-6.769181012061118 16.248 14.796685197723685\n",
      "2\n",
      "-6.807984864433279 16.32 23.466677201744524\n",
      "3\n",
      "-6.409313061467233 15.434 20.48893621036191\n",
      "4\n",
      "-6.089758379456219 14.724 15.70781210421295\n",
      "5\n",
      "-6.088898564509719 14.761 17.31776048621863\n",
      "6\n",
      "-6.27018814947433 15.202 17.572234122705744\n",
      "7\n",
      "-6.09447959585616 14.638 15.942972313470946\n",
      "8\n",
      "-6.128399099917788 14.867 14.374638171679988\n",
      "9\n",
      "-6.091524160792828 14.806 14.870783682445424\n",
      "10\n",
      "-5.997848627050571 14.635 13.956413064888716\n",
      "11\n",
      "-6.075373708728466 14.855 15.15929475919214\n",
      "12\n",
      "-6.206938376947781 15.082 14.732373648118676\n",
      "13\n",
      "-6.153443940150515 14.907 14.574486432791057\n",
      "14\n",
      "-6.216314568030713 15.094 15.82692513767892\n",
      "15\n",
      "-6.171257423149282 14.848 14.940954923218493\n",
      "16\n",
      "-6.150873534023815 15.053 14.792097522780296\n",
      "17\n",
      "-6.043577430010379 14.836 13.776585925627192\n",
      "18\n",
      "-6.051911470763597 14.747 14.089137690306028\n",
      "19\n",
      "-5.981020935666724 14.705 13.627918968325766\n",
      "Done training in 1777.0 s\n",
      "\n",
      "Epoch Number: 1\n",
      "[-5.665971015744776] [13.858]\n",
      "[    0 13858]\n",
      "Done testing in 26.23 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "# import time\n",
    "\n",
    "\n",
    "use_poly = False  # Set this to True if you want the Estimator to change state to a polynomial. State must be a single number.\n",
    "poly_degree = 7   # Degree of polynomial is use_poly is set to True\n",
    "actions = 6       # Number of actions available to use by the agent\n",
    "state_space = 8   # Number of variables we return as state of environment. Used to initialise Scaler and SGD in Estimator\n",
    "\n",
    "directory = '../Tests/CNFGEN_20/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "files = os.listdir(directory)\n",
    "files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "# shuffle(files)\n",
    "\n",
    "split = int(len(files) * 0.2)\n",
    "training_files = files[:split]\n",
    "# test_files = files[split:]\n",
    "test_files = files[60000:61000]\n",
    "\n",
    "# directory = '../Tests/SATLIB_20/'  # RLSAT problems are very simple. SATLIB probelms give more interesting Q-values.\n",
    "# files = os.listdir(directory)\n",
    "# files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "# split = int(len(files) * 1.0)\n",
    "# test_files = files[split:split+int(len(files) * 0.01)] \n",
    "\n",
    "\n",
    "print(\"Number of training files:\", len(training_files))\n",
    "print(\"Number of test files:\", len(test_files))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    \n",
    "    s = time.time()\n",
    "    episode_reward_train, episode_length_train, estimator, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "#     episode_reward_train_2, episode_length_train_2, estimator_2, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "#     episode_reward_train_3, episode_length_train_3, estimator_3, losses = train(training_files, epochs=1, ϵ=0.3, epsilon_decay=0.95)\n",
    "    e = time.time()\n",
    "    print(\"Done training in\", (round(e-s, 2)), \"s\")\n",
    "    print()\n",
    "    est = estimator\n",
    "\n",
    "    s = time.time()\n",
    "    \n",
    "    episode_reward_test, episode_length_test, episode_actions = test(test_files, epochs=1, ϵ=0, estimator=est)\n",
    "    print(episode_reward_test, episode_length_test)\n",
    "    \n",
    "    print(np.bincount(episode_actions))\n",
    "    \n",
    "#     est=estimator_2\n",
    "#     episode_reward_test, episode_length_test, episode_actions = test(test_files, epochs=1, ϵ=0, estimator=est)\n",
    "#     print(episode_reward_test, episode_length_test)\n",
    "    \n",
    "    e = time.time()\n",
    "    print(\"Done testing in\", (round(e-s, 2)), \"s\")\n",
    "    print()\n",
    "    \n",
    "#     counts = policy_use(np.array(states), est, 50000)\n",
    "#     print(counts)\n",
    "\n",
    "#     print(np.bincount(episode_actions))\n",
    "    \n",
    "#     s = time.time()\n",
    "#     episode_reward_rand, episode_length_rand, episode_actions = test(test_files, epochs=1)\n",
    "#     e = time.time()\n",
    "#     print(np.bincount(episode_actions))\n",
    "#     print(episode_reward_rand, episode_length_rand)\n",
    "#     print(\"Done testing random policy in \", (round(e-s, 2)), \"s\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %debug\n",
    "\n",
    "# from matplotlib2tikz import save as tikz_save\n",
    "\n",
    "# Average all 3 and save them\n",
    "# avg_l1 = np.array(episode_length_train)\n",
    "# avg_l2 = np.array(episode_length_train_2)\n",
    "# avg_l3 = np.array(episode_length_train_3)\n",
    "\n",
    "# avgs_l = np.array([avg_l1, avg_l2, avg_l3])\n",
    "# avgs_l = np.mean(avgs_l, axis=0)\n",
    "\n",
    "# avg_r1 = np.array(episode_reward_train)\n",
    "# avg_r2 = np.array(episode_reward_train_2)\n",
    "# avg_r3 = np.array(episode_reward_train_3)\n",
    "\n",
    "# avgs_r = np.array([avg_r1, avg_r2, avg_r3])\n",
    "# avgs_r = np.mean(avgs_r, axis=0)\n",
    "\n",
    "\n",
    "# with open('metrics_nonLIW_4.pickle', 'wb') as fout:\n",
    "#     pickle.dump((avgs_r, avgs_l), fout)\n",
    "    \n",
    "    \n",
    "# with open('metrics_nonLIW_4.pickle', 'rb') as fin:\n",
    "#     episode_reward_train_3, episode_length_train_3 = pickle.load(fin)\n",
    "    \n",
    "# with open('metrics.pickle', 'rb') as fin:\n",
    "#     episode_reward_train, episode_length_train, estimator, episode_reward_train_2, episode_length_train_2, estimator_2, episode_reward_train_3, episode_length_train_3, estimator_3 = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SATLIB_50_unit_reward.pickle', 'wb') as fout:\n",
    "#         pickle.dump((episode_reward_train, episode_length_train, estimator, episode_reward_test, episode_length_test, episode_reward_rand, episode_length_rand), fout)\n",
    "\n",
    "# with open('SATLIB_50.pickle', 'rb') as fin:\n",
    "#         episode_reward_train, episode_length_train, estimator, episode_reward_test, episode_length_test, episode_reward_rand, episode_length_rand = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward for last 10 epochs in training: -10.293\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time_taken_avg = np.array(episode_reward_train)\n",
    "# time_taken_avg_2 = np.array(episode_reward_train_2)\n",
    "# time_taken_avg_3 = np.array(episode_reward_train_3)\n",
    "\n",
    "# avgs = np.array([time_taken_avg, time_taken_avg_2, time_taken_avg_3])\n",
    "# avgs = np.mean(avgs, axis=0)\n",
    "\n",
    "\n",
    "# plt.plot(avgs[1:], label='Training')\n",
    "# plt.plot(time_taken_avg[1:], label='Run 1')\n",
    "# plt.plot(time_taken_avg_2[1:], label='Run 2')\n",
    "# plt.plot(time_taken_avg_3[1:], label='Run 3')\n",
    "# plt.legend()\n",
    "\n",
    "# print(np.max(avgs[1:]))\n",
    "# print(np.max(episode_reward_train[1:]), np.max(episode_reward_train_2[1:]), np.max(episode_reward_train_3[1:]))\n",
    "\n",
    "# plt.xlabel(\"Number of episodes (1000s)\")\n",
    "# plt.ylabel(\"Average reward\")\n",
    "\n",
    "# tikz_save('td_reward.tikz', figureheight='\\\\figureheight', figurewidth='\\\\figurewidth')\n",
    "\n",
    "\n",
    "plt.plot(episode_reward_train[1:], label='Training')\n",
    "plt.plot(episode_reward_train_2[1:], label='Training_4')\n",
    "# plt.plot(episode_reward_test, label='Testing')\n",
    "# plt.plot(episode_reward_rand, label='Testing rand')\n",
    "\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Average reward per epoch')\n",
    "plt.xticks([0, 5, 10, 15, 20])\n",
    "plt.xlim(-1, 21)\n",
    "# plt.legend()\n",
    "\n",
    "last_n = 10\n",
    "train_avg = np.mean(np.array(episode_reward_train)[-last_n:])\n",
    "# test_avg = np.mean(np.array(episode_reward_test)[-last_n:])\n",
    "# rand_avg = np.mean(np.array(episode_reward_rand)[-last_n:])\n",
    "\n",
    "print(\"Average reward for last\", last_n, \"epochs in training:\", round(train_avg, 3))\n",
    "# print(\"Average reward for last\", last_n, \"epochs in testing:\", round(test_avg, 3))\n",
    "# print(\"Average reward for last\", last_n, \"epochs in testing random policy:\", round(rand_avg, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length for last 10 epochs in training: 11.346\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time_taken_avg = np.array(episode_length_train)\n",
    "# time_taken_avg_2 = np.array(episode_length_train_2)\n",
    "# time_taken_avg_3 = np.array(episode_length_train_3)\n",
    "\n",
    "# avgs = np.array([time_taken_avg, time_taken_avg_2, time_taken_avg_3])\n",
    "# avgs = np.mean(avgs, axis=0)\n",
    "\n",
    "\n",
    "# plt.plot(avgs[1:], label='Training')\n",
    "# plt.plot(time_taken_avg[1:], label='Run 1')\n",
    "# plt.plot(time_taken_avg_2[1:], label='Run 2')\n",
    "# plt.plot(time_taken_avg_3[1:], label='Run 3')\n",
    "# plt.legend()\n",
    "\n",
    "# print(np.min(avgs[1:]))\n",
    "\n",
    "# plt.xlabel(\"Number of episodes (1000s)\")\n",
    "# plt.ylabel(\"Average steps\")\n",
    "# # plt.ylim(8, 11)\n",
    "\n",
    "# tikz_save('td_time.tikz', figureheight='\\\\figureheight', figurewidth='\\\\figurewidth')\n",
    "\n",
    "plt.plot(episode_length_train[1:], label='Training')\n",
    "plt.plot(episode_length_train_2[1:], label='Training_4')\n",
    "# plt.plot(episode_length_test, label='Testing')\n",
    "# plt.plot(episode_length_rand, label='Testing rand')\n",
    "\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Average episode length per epoch')\n",
    "plt.xticks([0, 5, 10, 15, 20])\n",
    "plt.xlim(-1, 21)\n",
    "# plt.legend()\n",
    "\n",
    "train_avg = np.mean(np.array(episode_length_train)[-last_n:])\n",
    "# test_avg = np.mean(np.array(episode_length_test)[-last_n:])\n",
    "# rand_avg = np.mean(np.array(episode_length_rand)[-last_n:])\n",
    "\n",
    "print(\"Average length for last\", last_n, \"epochs in training:\", round(train_avg, 3))\n",
    "# print(\"Average length for last\", last_n, \"epochs in testing:\", round(test_avg, 3))\n",
    "# print(\"Average length for last\", last_n, \"epochs in testing random policy:\", round(rand_avg, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Please add the following lines to your LaTeX preamble:\n",
      "\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{fontspec} % This line only for XeLaTeX and LuaLaTeX\n",
      "\\usepackage{pgfplots}\n",
      "=========================================================\n",
      "Horizontal alignment will be ignored as no 'x tick label text width' has been passed in the 'extra' parameter\n",
      "Horizontal alignment will be ignored as no 'y tick label text width' has been passed in the 'extra' parameter\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFNFJREFUeJzt3X+QXWV9x/HPJ8mSH/Ij0awWAhhQDAOdQnBlVKzyQ4mgSGphCrWKLWNaW1vUugVrR+JMp1W3OE6nVhsUxRoBiRozjBhQg+AvYENYIIRoSlFZkCyVCEjAJfn2j/MsXNb9cXf3nj337PN+zdzJueece8732XPuJ+c+997nOiIEAJj5ZlVdAABgehD4AJAJAh8AMkHgA0AmCHwAyASBDwCZIPABIBMEPgBkgsAHgEzMqbqARosXL46lS5dWXQYA1MbmzZsfjojOZtZtq8BfunSpent7qy4DAGrD9s+aXZcuHQDIBIEPAJkg8AEgEwQ+AGSCwAeATBD4AJAJAh8AMkHgA0AmCHwAyASBDwCZIPABIBMEPgBkgsAHgEwQ+ACQCQIfADJB4ANAJgh8AMgEgQ8AmSDwASATBD4AZILAB4BMEPgAkAkCHwAyQeADQCYIfADIxJwyN277PkmPSdoj6emI6CpzfwCA0ZUa+MlJEfHwNOwHmJD1W/q1esNW7do9WHUpaNKiBR26+IyjtXL5kqpLqaXpCHyg7azf0q/uq/s0uDeqLgUT8MgTg+pe1ydJhP4klN2HH5Kus73Z9qqS9wU0rWfjdsK+pgb3hHo2bq+6jFoq+wr/NRHRb/uFkq63fU9E3Ni4QvqPYJUkHXrooSWXAxQe2LW76hIwBRy/ySn1Cj8i+tO/OyV9XdLxI6yzJiK6IqKrs7OzzHKAZxy0cH7VJWAKOH6TU1rg236e7f2GpiWdKumusvYHTET3imXqmOWqy8AkdMy2ulcsq7qMWiqzS+dFkr5ue2g/X46Ib5W4P6BpQ2/48SmdeuFTOlNTWuBHxL2Sjilr+8BUrVy+hOBAVvimLQBkgsAHgEwQ+ACQCQIfADJB4ANAJgh8AMgEgQ8AmSDwASATBD4AZILAB4BMEPgAkAkCHwAyQeADQCYIfADIBIEPAJkg8AEgEwQ+AGSCwAeATBD4AJAJAh8AMkHgA0AmCHwAyASBDwCZIPABIBMEPgBkovTAtz3b9hbb15S9LwDA6OZMwz4ukLRN0v7TsC+MYf2Wfq3esFW7dg9WVsOiBR26+IyjtXL5kspqAHJV6hW+7YMlvUnSZ8vcD8a3fku/uq/uqzTsJemRJwbVva5P67f0V1oHkKOyu3Q+KekfJO0teT8YR8/G7RrcG1WXIUka3BPq2bi96jKA7JQW+LbfLGlnRGweZ71Vtntt9w4MDJRVTvYe2LW76hKeo93qAXJQ5hX+CZLeYvs+SVdKOtn2l4avFBFrIqIrIro6OztLLCdvBy2cX3UJz9Fu9QA5KC3wI+KDEXFwRCyVdI6k70bEn5W1P4yte8Uydcxy1WVIkjpmW90rllVdBpCd6fiUDtrA0Kdi+JQOkC9HtMcbeZLU1dUVvb29VZcBALVhe3NEdDWzLt+0BYBMEPgAkAkCHwAyQeADQCYIfADIBIEPAJkg8AEgEwQ+AGSCwAeATBD4AJAJAh8AMkHgA0AmCHwAyASBDwCZIPABIBMEPgBkgsAHgEwQ+ACQCQIfADJB4ANAJgh8AMgEgQ8AmSDwASATBD4AZILAB4BMlBb4tufZvsV2n+2ttj9S1r4AAOObM94KtjslvUvS0sb1I+IvxnnoU5JOjojHbXdI+r7tayPix1OoFwAwSeMGvqRvSLpJ0rcl7Wl2wxERkh5PdzvSLSZaIACgNZoJ/AURceFkNm57tqTNkl4q6VMRcfNktgMAmLpm+vCvsX36ZDYeEXsi4lhJB0s63vbvD1/H9irbvbZ7BwYGJrMbAEATmgn8C1SE/pO2H0u3Ryeyk4jYJWmTpDeOsGxNRHRFRFdnZ+dENgsAmIBxAz8i9ouIWRExL03vFxH7j/c42522F6bp+ZLeIOmeqZcMAJiMZvrwZfstkl6b7t4QEdc08bADJV2e+vFnSfpKk48DAJSgmY9lflTSKyStTbMusH1CRHxwrMdFxB2Slk+9RABAKzRzhX+6pGMjYq8k2b5c0hZJYwY+AKC9NPtN24UN0weUUQgAoFzNXOH/q6QttjdJsoq+/ItKrQoA0HLjBn5EXGH7BhX9+JJ0YUT8stSqAAAtN2qXju0j07/HqfjEzf3pdlCaBwCokbGu8N8vaZWkS0ZYFpJOLqUiAEApRg38iFiVJk+LiCcbl9meV2pVAICWa+ZTOj9sch4AoI2NeoVv+/ckLZE03/ZyFZ/QkaT9JS2YhtoAAC00Vh/+CknvVDHS5SV6NvAflfSP5ZYFAGi1sfrwL1cxFs4fR8RXp7EmAEAJmunDf/nQqJeSZHuR7X8usSYAQAmaCfzT0nj2kqSIeETF+DoAgBppJvBn2547dCeNbT93jPUBAG2ombF01kr6ju3Pq3jj9p2SLi+zKABA6zUzls7HbPdJer2Kb9hulPTisgsDALRWs8MjP6Qi7M9WMaTCttIqAgCUYqwvXr1M0rnp9rCkqyQ5Ik6aptoAAC00VpfOPZJukvTmiNghSbbfNy1VAQBabqwunbdKelDSJtuX2j5Fz37bFgBQM6MGfkSsj4hzJB0paZOk90p6oe1P2z51ugoEALTGuG/aRsRvIuLLEXGGinF1tki6sPTKAAAt1eyndCQV37KNiDURcUpZBQEAyjGhwAcA1BeBDwCZKC3wbR9ie5Ptu21vtX1BWfsCAIyvmbF0JutpSX8fEbfZ3k/SZtvXR8TdrdzJ+i39Wr1hq3btHmzlZme0RQs6dPEZR2vl8iVVlwI0pd2f53V5TpUW+BHxoIrP8SsiHrO9TcVPJrYs8Ndv6Vf31X0a3But2mQWHnliUN3r+iSp7U9QoA7P87o8p6alD9/2UknLJd3cyu32bNze1idBOxvcE+rZuL3qMoBx1eV5XofnVOmBb3tfSV+V9N6IeHSE5ats99ruHRgYmNC2H9i1u0VV5om/H+qgTudpu9daauDb7lAR9msj4msjrZM+198VEV2dnZ0T2v5BC+e3oMp88fdDHdTpPG33Wsv8lI4lfU7Stoj4RBn76F6xTB2zGN5nMjpmW90rllVdBjCuujzP6/CcKvMK/wRJb5d0su3b062lv4W7cvkS9Zx9jBbO72jlZme8RQs61HPWMW395hIwpA7P87o8pxzRPm+GdHV1RW9vb9VlAEBt2N4cEV3NrMs3bQEgEwQ+AGSCwAeATBD4AJAJAh8AMkHgA0AmCHwAyASBDwCZIPABIBMEPgBkgsAHgEwQ+ACQCQIfADJB4ANAJgh8AMgEgQ8AmSDwASATBD4AZILAB4BMEPgAkAkCHwAyQeADQCYIfADIBIEPAJkg8AEgE6UFvu3LbO+0fVdZ+wAANG9Oidv+gqT/kPTFEveBmli/pV+rN2zVrt2DVZfyOxYt6NDFZxytlcuXVF0KaqaV5/V0nIelBX5E3Gh7aVnbR32s39Kv7qv7NLg3qi5lRI88MajudX2SROijaa0+r6fjPKQPH6Xr2bi9bcN+yOCeUM/G7VWXgRop47wu+zysPPBtr7Lda7t3YGCg6nJQggd27a66hKbUpU60h7LOlzLPw8oDPyLWRERXRHR1dnZWXQ5KcNDC+VWX0JS61In2UNb5UuZ5WHngY+brXrFMHbNcdRlj6phtda9YVnUZqJEyzuuyz8MyP5Z5haQfSVpm+37b55e1L7S3lcuXqOfsY7RwfkfVpYxo0YIO9Zx1DG/YYkJafV5Px3noiPZ5M62rqyt6e3urLgMAasP25ojoamZdunQAIBMEPgBkgsAHgEwQ+ACQCQIfADJB4ANAJgh8AMgEgQ8AmSDwASATBD4AZILAB4BMEPgAkAkCHwAyQeADQCYIfADIBIEPAJkg8AEgEwQ+AGSCwAeATBD4AJAJAh8AMkHgA0AmCHwAyASBDwCZIPABIBOlBr7tN9rebnuH7YvK3BcAYGylBb7t2ZI+Jek0SUdJOtf2UWXtDwAwtjKv8I+XtCMi7o2I30q6UtKZJe4PADCGMgN/iaRfNNy/P80DAFSg8jdtba+y3Wu7d2BgoOpyAGDGKjPw+yUd0nD/4DTvOSJiTUR0RURXZ2dnieUAQN7KDPxbJR1h+zDb+0g6R9KGEvcHABjDnLI2HBFP236PpI2SZku6LCK2lrU/AMDYSgt8SYqIb0r6Zpn7AAA0p/I3bQEA04PAB4BMEPgAkAkCHwAyQeADQCYIfADIBIEPAJkg8AEgEwQ+AGSCwAeATBD4AJAJAh8AMuGIqLqGZ9gekPSzST58saSHW1hOlWhL+5kp7ZBoS7uabFteHBFN/ZhIWwX+VNjujYiuqutoBdrSfmZKOyTa0q6moy106QBAJgh8AMjETAr8NVUX0EK0pf3MlHZItKVdld6WGdOHDwAY20y6wgcAjKH2gW/7jba3295h+6Kq65ko2/fZvtP27bZ707zn277e9k/Tv4uqrnMkti+zvdP2XQ3zRqzdhX9Px+kO28dVV/nvGqUtq233p2Nzu+3TG5Z9MLVlu+0V1VQ9MtuH2N5k+27bW21fkObX7tiM0ZbaHRvb82zfYrsvteUjaf5htm9ONV9le580f266vyMtXzrlIiKitjdJsyX9j6TDJe0jqU/SUVXXNcE23Cdp8bB5H5d0UZq+SNLHqq5zlNpfK+k4SXeNV7uk0yVdK8mSXinp5qrrb6ItqyV9YIR1j0rn2lxJh6VzcHbVbWio70BJx6Xp/ST9JNVcu2MzRltqd2zS33ffNN0h6eb09/6KpHPS/M9Ienea/mtJn0nT50i6aqo11P0K/3hJOyLi3oj4raQrJZ1ZcU2tcKaky9P05ZJWVljLqCLiRkm/GjZ7tNrPlPTFKPxY0kLbB05PpeMbpS2jOVPSlRHxVET8r6QdKs7FthARD0bEbWn6MUnbJC1RDY/NGG0ZTdsem/T3fTzd7Ui3kHSypHVp/vDjMnS81kk6xbanUkPdA3+JpF803L9fY58M7SgkXWd7s+1Vad6LIuLBNP1LSS+qprRJGa32uh6r96RujssautZq05bUDbBcxdVkrY/NsLZINTw2tmfbvl3STknXq3gFsisink6rNNb7TFvS8l9LesFU9l/3wJ8JXhMRx0k6TdLf2H5t48IoXs/V8qNUda49+bSkl0g6VtKDki6ptpyJsb2vpK9Kem9EPNq4rG7HZoS21PLYRMSeiDhW0sEqXnkcOZ37r3vg90s6pOH+wWlebUREf/p3p6SvqzgJHhp6SZ3+3VldhRM2Wu21O1YR8VB6gu6VdKme7Rpo+7bY7lARkGsj4mtpdi2PzUhtqfOxkaSI2CVpk6RXqehCm5MWNdb7TFvS8gMk/d9U9lv3wL9V0hHpXe59VLyxsaHimppm+3m29xualnSqpLtUtOG8tNp5kr5RTYWTMlrtGyS9I30i5JWSft3QvdCWhvVj/5GKYyMVbTknfYriMElHSLpluusbTern/ZykbRHxiYZFtTs2o7WljsfGdqfthWl6vqQ3qHhPYpOks9Jqw4/L0PE6S9J30yuzyav6neup3lR8wuAnKvrCPlR1PROs/XAVnyjok7R1qH4V/XTfkfRTSd+W9Pyqax2l/itUvJweVNH3eP5otav4hMKn0nG6U1JX1fU30Zb/TrXekZ58Bzas/6HUlu2STqu6/mFteY2K7po7JN2ebqfX8diM0ZbaHRtJfyBpS6r5LkkfTvMPV/Gf0g5JV0uam+bPS/d3pOWHT7UGvmkLAJmoe5cOAKBJBD4AZILAB4BMEPgAkAkCHwAyQeCjVLbD9iUN9z9ge3WLtv0F22eNv+aU93O27W22N5Ww7R+Os3xp4wiew5bdYHtG/J4rpgeBj7I9JemtthdXXUijhm82NuN8Se+KiJNavf+IeHWrtgmMh8BH2Z5W8dNt7xu+YPgVuu3H078n2v6e7W/Yvtf2R22/LY0lfqftlzRs5vW2e23/xPab0+Nn2+6xfWsaXOsvG7Z7k+0Nku4eoZ5z0/bvsv2xNO/DKr788znbPcPWv9L2m4a3J12V32T7tnR79Wj7b2jzvra/k9a/03bjqK9zbK9NrzLW2V4wQu2n2v5RevzVaewZpb/d3env8G+jHyZkoepvn3Gb2TdJj0vaX8W4/wdI+oCk1WnZFySd1bhu+vdESbtUjIU+V8WYIh9Jyy6Q9MmGx39LxYXLESq+ITtP0ipJ/5TWmSupV8XY6CdK+o2kw0ao8yBJP5fUKWmOpO9KWpmW3aARvn2q4iv9l6fpfVSMbDhf0gJJ89L8IyT1NrTrOftvaPMcSfun6cUqvl1pSUtVfNP0hLTsMqVx4IfqSuvfKOl5af6Fkj6s4pu12/XsT5kurPp84FbtjSt8lC6K0Q2/KOnvJvCwW6MYC/0pFV+Tvy7Nv1NFCA75SkTsjYifSrpXxeiDp6oYG+Z2FUPpvkBF8ErSLVGMkz7cKyTdEBEDUQxFu1bFj6KM5VpJJ9meq2K00xsjYreKcc4vtX2niq/GH9XwmNH2b0n/YvsOFcMeLNGzwxf/IiJ+kKa/pOIVR6NXpn38ILX5PEkvVjGc7pMqXp28VdIT47QHM9xE+jGBqfikpNskfb5h3tNK3Yq2Z6m4Sh7yVMP03ob7e/Xc83b42CChIjz/NiI2Ni6wfaKKK+yWiIgnbd8gaYWkP1HxAzxS0X31kKRjVLTvyYaHjbb/t6l4dfHyiBi0fZ+KVyvSyG1sZEnXR8S5wzdq+3hJp6gYfOs9Kn5sA5niCh/TIiJ+peKn3M5vmH2fpJen6beouDKeqLNtz0r9+oer6MLYKOndaVhd2X5ZGo10LLdIep3txbZnSzpX0vea2P9Vkv5c0h+q6F6Siq6rB6MYuvftKn6KczwHSNqZwv4kFVfoQw61/ao0/aeSvj/ssT+WdILtl0rPjML6stSPf0BEfFPFf0LHNFEHZjACH9PpEhX9zUMuVRGyfSrGBZ/M1ffPVYT1tZL+KiKelPRZFW+K3pY+0vhfGufVbBTDAV+kYqjaPkmbI6KZYamvk/Q6Sd+O4mc2Jek/JZ2X2nWkmmvXWkldqRvoHZLuaVi2XcWP42yTtEjFj3801j4g6Z2SrkhdQj9K+91P0jVp3vclvb+JOjCDMVomAGSCK3wAyASBDwCZIPABIBMEPgBkgsAHgEwQ+ACQCQIfADJB4ANAJv4fCrKSITj2ZegAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = range(300)\n",
    "\n",
    "policy = make_epsilon_greedy_policy(estimator_3, 0, actions)\n",
    "ys = [np.random.choice(np.arange(actions), p=policy(i)) for i in xs]\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.xlabel(\"Number of variables\")\n",
    "plt.ylabel(\"Action\")\n",
    "plt.ylim(-0.5, 5.9)\n",
    "\n",
    "tikz_save('td_actions_3.tikz', figureheight='\\\\figureheight', figurewidth='\\\\figurewidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.55820148, -5.63479614, -5.60820623, -5.60889429, -3.03299541,\n",
       "       -8.19452472])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = [0.01, 0.01]\n",
    "\n",
    "estimator.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Q-value')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4VGX6//H3mcmUTGbSO0kIEEICIQkQJBSVZkMREF1ZXbtrF/3ZG3ZUVmzo2tu6q4hfFbAhgvTeWyAQICG918lkMu35/RGJNAMkE2aA53Vdc4XMnPPMfbLrfOY55T6KEAJJkiRJ+isqTxcgSZIkeTcZFJIkSVKbZFBIkiRJbZJBIUmSJLVJBoUkSZLUJhkUkiRJUptkUEiSJEltkkEhSZIktUkGhSRJktQmH08X4A6hoaEiPj7e02VIkiSdVjZu3FgphAg73nJnRFDEx8ezYcMGT5chSZJ0WlEU5cCJLCd3PUmSJEltkkEhSZIktUkGhSRJktSmM+IYhSRJZxe73U5hYSFWq9XTpZwW9Ho9MTExaDSadq0vg0KSpNNOYWEhJpOJ+Ph4FEXxdDleTQhBVVUVhYWFdOvWrV1jyF1PkiSddqxWKyEhITIkToCiKISEhHRo9iWDQpKk05IMiRPX0b/VWR0UZpuZV9a9Qr2t3tOlSJIkea2zOij21e1jVvYsnlz+JC7h8nQ5kiSdZubMmYOiKGRnZx932c8//5zi4uLW32+99VZ27tzZ4RqEEEyePJmEhARSU1PZtGlTh8c80lkdFGlhaTw08CGWFC7hk+2feLocSZJOMzNnzmTYsGHMnDnzuMseGRQff/wxvXv37nAN8+bNIycnh5ycHD788EPuvPPODo95pLM6KACuSbqGMd3G8Pbmt1lVtMrT5UiSdJowm82sWLGCTz75hK+//vqw16ZNm0bfvn1JS0vjscce49tvv2XDhg1ce+21pKen09TUxPDhw1tbD82cOZO+ffuSkpLCo48+2jqO0WjkySefJC0tjczMTMrKyo6qY+7cuVx//fUoikJmZia1tbWUlJS4dVvP+tNjFUXhmcHPkFObwyPLH2HWZbPoYuzi6bIkSTpBz/2Yxc5i9x5n7B3tzzNj+7S5zNy5c7n44otJTEwkJCSEjRs3MmDAAObNm8fcuXNZu3YtBoOB6upqgoODeeedd5g+fToZGRmHjVNcXMyjjz7Kxo0bCQoK4sILL2TOnDmMHz+exsZGMjMzmTp1Ko888ggfffQRTz311GHrFxUVERsb2/p7TEwMRUVFREVFue3vcdbPKAAMGgNvDn8Tl8vFA0seoNnZ7OmSJEnycjNnzmTSpEkATJo0qXX308KFC7npppswGAwABAcHtznO+vXrGT58OGFhYfj4+HDttdeybNkyALRaLZdddhkAAwYMIC8vr5O2pm1n/YzioDj/OKYOm8rkxZN5ae1LPDfkOU+XJEnSCTjeN//OUF1dzaJFi9i+fTuKouB0OlEUhVdffdWt76PRaFpPbVWr1TgcjqOW6dKlCwUFBa2/FxYW0qWLe/eKyBnFIUbEjeCfff/J9znf892e7zxdjiRJXurbb7/luuuu48CBA+Tl5VFQUEC3bt1Yvnw5F1xwAZ999hkWiwVoCRUAk8lEQ0PDUWOdc845LF26lMrKSpxOJzNnzuT8888/4Vouv/xyvvjiC4QQrFmzhoCAALfudgIZFEe5O/1uhkQPYeraqeyo3OHpciRJ8kIzZ85kwoQJhz03ceJEZs6cycUXX8zll19ORkYG6enpTJ8+HYAbb7yRO+64o/Vg9kFRUVG88sorjBgxgrS0NAYMGMC4ceNOuJYxY8bQvXt3EhIS+Oc//8m7777rno08hCKEcPugp1pGRoZw542Laq21XP3T1QgEsy6bRZA+yG1jS5LUcbt27SI5OdnTZZxWjvU3UxRloxAi4y9WaSVnFMcQqA/k9RGvU9VUxSPLHsHpcnq6JEmSJI+RQfEX+oT04anMp1hTsoZ3trzj6XIkSZI8RgZFGyb0nMDEnhP5ePvH/J7/u6fLkSRJ8ggZFMfxxKAnSAlJ4akVT5FXl+fpciRJkk45GRTHoVVreX3462hUGu5bfB9mm9nTJUmSJJ1SMihOQJQxiteGv8aB+gM8vvxx2WlWkqSzitcFhaIoryqKkq0oyjZFUWYrihLo6ZoABkYO5OGBD7OkcAnvbnH/ecqSJJ1+vKHNeHZ2NoMHD0an07Ves+FuXhcUwAIgRQiRCuwBHvdwPa2uSbqG8Qnj+WDbByw8sNDT5UiS5GHe0GY8ODiYGTNm8NBDD3V4rL/idUEhhPhNCHGwockaIMaT9RxKURSmZE4hNTSVJ1Y8QU5NjqdLkiTJQ7ylzXh4eDgDBw5Eo9F02rZ6e1PAm4FZni7iUFq1ljdGvMGknyYxedFkvr7sawJ0AZ4uS5LOXvMeg9Lt7h0zsi9c8kqbi3hLm/FTwSMzCkVRFiqKsuMYj3GHLPMk4AC+/IsxblMUZYOiKBsqKipOVekAhBvCeWPEG5RZynh46cM4XEd3dJQk6cwm24x3MiHE6LZeVxTlRuAyYJT4i2ZUQogPgQ+hpdeTu2s8nrSwNJ7KfIpnVj3Dmxvf5KGBnbd/UJKkNhznm39n8KY246eC1x2jUBTlYuAR4HIhhMXT9bTlip5XMKnXJP6z8z/8tP8nT5cjSdIp4k1txk8FrwsK4B3ABCxQFGWLoijve7qgtjxyziNkRGTw7KpnyarK8nQ5kiSdAt7UZry0tJSYmBhef/11XnzxRWJiYqivd++tYWWbcTeotlYz6adJuISLry/7mlDfUI/VIklnA9lm/OTJNuMeFqwP5q0Rb1HXXMcDSx7A5rR5uiRJkiS3kUHhJskhybww7AU2l2/mudXPcSbM1CRJksD7r6M4rVwcfzG5tbm8u/VdEgITuCnlJk+XJEmS1GEyKNzsjrQ72Fe3jzc2vkG8fzwj4kZ4uiRJkqQOkbue3ExRFF4Y+gK9Q3rz2PLH2F2929MlSZIkdYgMik7g6+PLjJEzMGqM3LvoXqqaqjxdkiRJUrvJoOgk4YZwZoyaQY21hvsX3y/PhJKkM5A3tBn/8ssvSU1NpW/fvgwZMoStW7d2eMwjyaDoRH1C+vDisBfZUrFFngklSWcgb2gz3q1bN5YuXcr27duZMmUKt912W4fHPJIMik52UfxF3J1+Nz/s+4HPsj7zdDmSJLmJt7QZHzJkCEFBQQBkZmZSWFjo9m2VZz2dAren3s7+2v28ufFN4v3jGRk30tMlSdIZY9q6aWRXH3/Xz8lICk7i0XMebXMZb2wz/sknn3DJJZe45W9wKDmjOAUUReH5oc+TEprCY8sfkz2hJOkM4G1txhcvXswnn3zCtGnTOrppR5EzilNE76NnxsgZXPvztdzz+z18NeYrooxRni5Lkk57x/vm3xm8rc34tm3buPXWW5k3bx4hISFurQHkjOKUCvUN5d3R79LsaOau3++iwXZ0y2FJkryfN7UZz8/P54orruC///0viYmJ7tnAI8igOMV6BPbg9RGvk1eXx4NLHsTusnu6JEmSTpI3tRl//vnnqaqq4q677iI9Pf2oYyDuINuMe8icvXOYsnIKE3tO5JnBz7ROLyVJOj7ZZvzkdaTNuDxG4SHjE8ZT0FDAh9s+JMYUw619b/V0SZIkScckg8KD7km/h8KGQt7a9BZdjF24pJv7T2uTJEnqKBkUHnSwgWBpYylPrXiKSL9I+oX383RZkiRJh5EHsz1Mq9by1oi3iDZGM3nRZPLr8z1dkiRJ0mFkUHiBQH0g7456FwWFOxfeKbvNSpLkVWRQeIlY/1hmjJxBuaWce36/B4vd4umSJEmSABkUXiU9PJ1Xz3+VndU7eXCpvMZCkrydN7QZnzt3Lqmpqa3XUKxYsaLDYx5JBoWXGR47nKczn2ZF0QqeXfWsbE0uSV7MG9qMjxo1iq1bt7JlyxY+/fRTbr3V/afae21QKIryoKIoQlGUUE/XcqpNTJzY2pp8xuYZni5HkqRj8JY240ajsfWC3cbGxk65eNcrT49VFCUWuBA4a08Buj31dsot5Xy8/WNCfUO5NvlaT5ckSV6p9KWXaN7l3jbjuuQkIp94os1lvKnN+OzZs3n88ccpLy/n559/duvfArx3RvEG8Ahw1u53URSFJwc9ycjYkUxbN435efM9XZIkSYfwpjbjEyZMIDs7mzlz5jBlyhR3bN5hvG5GoSjKOKBICLG1rSmUoii3AbcBxMXFnaLqTi21Ss2086Zx24LbeHz54wTrgxkYOdDTZUmSVzneN//O4G1txg8677zz2L9/P5WVlYSGum+vvUdmFIqiLFQUZccxHuOAJ4CnjzeGEOJDIUSGECIjLCys84v2EL2PnrdHvk2cKY7Jiyazu3q3p0uSpLOeN7UZ37t3b+tJL5s2baK5udnt96TwSFAIIUYLIVKOfAD7gW7AVkVR8oAYYJOiKJGeqNNbBOgCeP+C9zFoDNy58E4KG9x/T1xJkk6cN7UZ/+6770hJSSE9PZ27776bWbNmuf2Atle3Gf8jLDKEEJVtLXc6thlvj701e7nh1xvw1/rzxSVfEGY4c2dSktQW2Wb85HWkzbi3Hsw+JRw2G5vf/4ammtPjTnMJQQm8N/o9qqxV3LbgNuqa6zxdkiRJZwGvDgohRPzxZhMdcWDWbFZtCeWzR1fzw+SPyP1tJS6X986wAFLDUnl75Nvk1+dz18K7ZKsPSZI6nVcHRWfreukFXBy7lq41Kyk1h/PL9818dvtslj//KbUHSjxd3l8aFDWIV89/layqLCYvnkyzs9nTJUmSdAY7q4NCFRhE5d9v4+Kvn+Ga20MYpPyGX30h24ri+PLlXXxzx2dk/e9H7Fbv67k0Mm4kLwx9gbUla3lk6SM4XG2fNidJktReXncdxam0Mb+Gqz9cQ6S/nsvToxk35XGuCtRQ/tV/2bnoAAc0qSxZ4ceKpb8RH1hM6qRhRPZP8pr7W4/tMZYGWwMvr3uZZ1Y9wwtDX0ClnNXZL0lSJzirgyIlOoC3/96POZuL+HRFLh8u209ihJFx6aMYNzGac+tL2PveF+zer2c/6ez9qAR/5xaSegt63zAWv2CTpzeBa5KvocHWwDtb3sGoMfLYOY95TZBJknRmOKu/fvpq1YxNi+aTGwey7snRvDA+BZNew6vzdzNs2mL+Ma+czRNuZvin/49JV9hIb54PjY2s2x3Jfx5fw9x7PmbfL8txOV0e3Y7bUm/j+t7X81X2V7y56U3ZcVaSThFvaDN+0Pr16/Hx8eHbb79125gHefV1FCfK3ddRFFRbmLuliNmbi9hX0YhGrXB+YjgT+nVhRBcd5Z99ws4NZgoN/bFrTeicdfSMrib1hjEEdY9yWx0nQwjBi2te5Js933BH2h3cnX63R+qQpFPBW66juPrqqykuLmbkyJE899xzbS47fPjwYzYFdAen08kFF1yAXq/n5ptv5sorrzxqGXkdRTtZzWa+e/kZ9qxZgfOQHiqxwQbuGdmThQ+cz0/3DuOGwfFsK6zl7q82cc6M9bzT9UL8X7iXa+6NYoh2Iab6fLJK4/jqX7uYdfvnbP90LramU3sAXFEUnsx8kgkJE3h/6/t8sPWDU/r+knS28ZY24wBvv/02EydOJDw8vFO29aw+RlFbWkx1UQE/vvEKfkHB9B15IX1HXoR/aMsVz4qikNIlgJQuATw+JpnV+6qYs6WIX3eU8u3GQsJNOi6/8B+M7xtO2Iof2PnrXvKUvixbZ2Ll6gXE+xfS92+ZRJ/T95QcN1ApKp4Z/AwOl4N3tryDVq3lppSbOv19JcmTln+zh8oCs1vHDI01cu7fEttcxlvajBcVFTF79mwWL17M+vXr3fp3OOisDorIhERumfEReVs2sXXBL6z5fhZrv/+G7gMGknbBGOJT+6GoWiZdapXCsJ6hDOsZyovjU/h9VzmzNxfxn9V5fLwil4TwHoy/6VzGRgmaZs4ke7eWPNLZ91klxo9mkdjdSspNYzFFubdZ15HUKjXPD30eu8vO6xtfR6PS8I/e/+jU95Sks9HMmTO57777gD/bjA8YMKBDbcaB1jbj48ePP6rN+IIFC45a//7772fatGmoVJ23g+isDgoAlUpN9/4D6d5/IHXlZWz7/Vd2LF7Avg1rCYiIJHXUxaSMuACDf0DrOnqNmktTo7g0NYqaRhu/7ChhzuYipv+2h+lARtcLGHdJNJfXZ3Hgu4Xst8SzKT+BTc9uJpx8kgeH0uvvY9DoOufP76Py4aVzX8LhcjBt/TR8VD5MSprUKe8lSZ52vG/+ncGb2oxv2LCh9b4YlZWV/PLLL/j4+DB+/Hi31XFWH6M4UkB4BOf+/QZue/czLp38MKaQUJZ/9Tkf3nkDv7w9naLsnUedURTkp+XaQV35vzuGsPyRETx8US/qmuxMmZvFeUsVPhoyAeN9o7g0fSeJjcuotxpZusbIp/fMZ979H5C/bCOiE9qGaFQa/nXevxgeM5ypa6fy3Z7v3P4eknS28qY247m5ueTl5ZGXl8eVV17Ju+++69aQADmjOCa1j4akoeeTNPR8qgrz2bpgHllLf2fXiiWExsWTdsEYkocNR/fH1PKg2GADd49I4K7hPdhZUs/cLcX8uLWYRdnl6Hx6MOqSwUyIdhG9aB57czQcEGns/6oOwxffkhBTT98bxxAY776zpjRqDa8Nf43Jiyfz3OrnUCkqJvSccPwVJUlq08yZMw876Ax/thl/77332LJlCxkZGWi1WsaMGcNLL73U2mbc19eX1atXt653aJtxIQSXXnrpSbUZPxXk6bEnyG61smvlUrYu+IXy3H1o9L4kDzuftAvGEB7f/S/Xc7kEG/Nr+HFrMb9sL6HSbMOo8+HC3hFMVOejWbyGfdUxVPsngqIixJlP8gAjSf8Yi86oc0vtVoeV+xbfx6riVUzJnMLfev3NLeNKkqd4y+mxp5OOnB4rg+IkCSEo3beHrb/NY/eqZTjsNiK6J9B35EUkDT3/qFnGoRxOF2v2V/Pj1mLm7Sih3uog0KBhTHIYV5Ston59CQdEHyyGCFQuG7G6A/S5NIWuFw5BperYWVPNzmYeWPIAywqX8fg5j3NN8jUdGk+SPEkGxcmTQeGhGxdZzWZ2rVjM9t/nU5Gfh49OR6/Mc+k76iKiE9vuCdXscLJ8TyU/bitmwc4yLDYnYSYdV3bXMnLnEkr3qSj2TcehMaB31NI9rJLU60cTkvzXs5fjsTvtPLj0QRYXLObhjIe5vs/17R5LkjxJBsXJk0Hh4TvcCSEo25fDtkXzyV65DLu1iZCYOPqOvJDkc0ccdsbUsTTZnCzKLm85nrG7HJvDRZdAX24MrSFlywbyq6Ko8k9GKGoCHUUkJLroc/1YjJFtn3Z3LHaXnUeXPcqCAwu4v//93NL3lvZutiR5jAyKkyeDwotuhWqzNrF71XK2L5pPSc5u1D4+JAwcTN+RFxGXktp6XcZfabDa+S2rjB+3FbMipxKHS9A9xJe72E3wziIK7Qk0GONAuAgXB+g1wJ9e/7gcnd+JH89wuBw8seIJ5uXO4+70u7kj7Y6ObrYknVIyKE6eDAovCopDVeTnsWPRb+xctghro5mA8AhSRlxIn+GjMAWHHnf96kYbv+4o5cetxazJrUIISA5Sc2fDJrR5zRT59MGqD0XlstHFJ4/kkT3oPmEUavXxz3p2upxMWTmFH/f/yO2pt3N3+t2y66x02pBBcfJkUHhpUBzksNnIWb+aHYvmk79jG4qiIq5vGn2GjyZhYCYa7fFnA+UNVuZnlTFvewlr9lfhEpButPPPqo24ynQU+6bi0BjROszEmYroM34gXc4b0OaHv9Pl5Pk1z/N9zvfc0PsGHsx4UIaFdFqQQXHyZFB4eVAcqqa0mJ1Lfydr2SIaKivQ+hroNeRc+pw3iuheySf0QV1pbua3rDLm7Shh1b4qnC7BMF0V15bvxFIbSrkxBZdai8FeSfeIGlL+MZqQ3j2OOZZLuHh57ct8vftrruh5BU9nPo1apXb3ZkuSW3lLUMyZM4cJEyawa9cukpKS2lz2888/58ILLyQ6OhpoaTP+wAMP0Lt37w7VsGTJEsaNG0e3bt0AuOKKK3j66aePWk4GxWkUFAcJl4uCndvJWvo7e9auxNHcTGBkFH3OG0Xv80biH3ZiXSCrG20s2FnKz9tLWbW35ZjGZSKXSysLqW2Ko9rUcn1GgL2Qnt2a6X3DZZhiD7+oTwjBv7f8mw+2fcAFXS/glXNfQavWdsZmS5JbeEtQeEOb8SVLljB9+nR++umnNpeTQXEaBsWhbE0W9qxdxc6lv1OwczsAcSmp9D5vFImDhqLR609onFqLjd92tuyeWrG3ErvDyXXN28msMVPlSqTBr+UgeKjzAD0SFZKvvxy/yD+PlXyR9QWvbniVzKhM3hrxFgbNX18TIkme5A1BYTab6dWrF4sXL2bs2LHs3r279bVp06bxv//9D5VKxSWXXEJGRgY33ngjXbp0ab0y+5JLLmkNjpkzZ/LSSy+1Xpk9bdo0oKXN+H333cdPP/2Er68vc+fOJSIi4rA6ztqgUBTlXuBuwAn8LIR4pK3lT/egOFRdeRk7ly0ia9nv1JWVotHpScwcStKw4cT1SUWlPrHdQnVNdhbubNk9tWxPJU57Mzc3bKVvvYMqdTIWQyQIF2HOXHr21pJ0/Th8QwOZnTObZ1c/S0pICu+OfpcAXdun9kqSJxz6obf48w8pP7DfreOHd+3OiBtva3OZL7/8kkWLFvHJJ58wZMgQ3n777dY24y+88AILFy48rM34kTOKg79HR0eTmZl5WJvxyZMnM378eBRF4YcffmDs2LE88sgj+Pv7H9VmfMmSJUycOJGYmBiio6OZPn06ffr0OarejgSF1/V6UhRlBDAOSBNCNCuK0jl34vBSAeERDL7y72ROnERRdhZZSxexZ80Kspb+jiEgkF5DziV56HAiExLbPJ4R4Kth4oAYJg6IocFqZ1F2Ob9lxfHV7nLsliZuqltMb4tClU9vVu0JZ/UT6wkXufTsa+DVUS/z2KanuPHXG/nggg8IN5xV/xNI0gnxljbj/fv358CBAxiNRn755RfGjx9PTk6OOzfV+4ICuBN4RQjRDCCEKPdwPR6hKAoxySnEJKcw6uY7yN28gV0rl7Bt4a9snvcjARGRJA05n+Rh5xMSE9fmWCa9hnHpXRiX3gWr3cnqfVX8trMHL+wso7G2jhurF5Bo1VGt7cOKnSGodth5WNzC2rD13GS5kbcveYfuge2/IlySOtPxvvl3Bm9qM+7v79/67zFjxnDXXXdRWVlJaOjxT8E/Ud4YFInAuYqiTAWswENCiM65bdNpwkerpeegIfQcNIRmSyM561aTvXIp6+b8H2tnzyKsa7c/ut2eh39o29/+9Ro1I5LCGZEUzovjBZvza/htZx/ezCqlurScG6p/o7vVQLU+hZ7V15O4yMYvC2eT1FfDebfcjNZkPEVbLUne62Cb8Q8++POWw+eff35rm/Hnn3+ea6+99rBdT221GZ88eTKVlZUEBQUxc+ZM7r333hOupbS0lIiICBRFYd26dbhcLkJC3HuDtBMOCkVRfIE4IcTu4y58/LEWApHHeOnJP2oKBjKBgcA3iqJ0F0ccTFEU5TbgNoC4uLa/UZ9JdAY/UoaPJmX4aBpra9i9egXZK5ew/KvPWf7V53RJ6k1i5rn0HDT4uBf1qVUKGfHBZMQH8/glSeSUm/ktqz+fZZWRn1fIDVW/0cVmpE6fwu5sf3IeXEGEaz8JKXoS/zEOfWjn3q1PkryVN7UZ//bbb3nvvffw8fHB19eXr7/+2u3XQ53QwWxFUcYC0wGtEKKboijpwPNCiMvdWk3Le/0KTBNCLP7j931AphCi4q/WOZMOZrdXbWkJ2auWkb1yKVWF+QBEJyaTmDmUnoOGHHemcaTi2iYW7Czjt52l7MrJ5qKmX4mvSUTlk4ZNF4TichLm3E/3BOh13WUYY7p0xmZJ0jF5w1lPp5tOP+tJUZSNwEhgiRCi3x/PbRdC9G1fyW2+1x1AtBDiaUVREoHfaZnJ/GWhMigOV1VUQM7aVexZu5KKvJazQSITEkkcNJSeg4YSGHGsydxfa7DaWbS7kBnbn6O2aSOjt2UwoCIOsy6ZJt9wEC5C7Hl0i2sm6e8XEdAroTM2S5JayaA4eaciKNYIITIVRdl8SFBsE0KktrfoNt5LC3wKpAM2Wo5RLGprHRkUf62mtLglNNaspGx/y5kQ4d16kDhoKAkDBxPcJeaEp6lOl5OX177MrD2z6KYfiigaT9+sNaRaXFg1iTQaWq44DWw+QHxELb0mZBJ6TibItiCSm8mgOHmnIig+oeWb/WPARGAyoBFCeEXbURkUJ6auvLR1plGS03KoKTAyih4DBpGQkUl0r+TjXqchhODzrM95Y+Mb9Anpw5RzXmX7ARe/Z5UQsPZ3+tVacPj0oMGvKwB+zaXEmEroeW43Yi6/DLVOXvEtddzBlhmyN9mJEUKQnZ3d6UFhoOVA84WAAswHXhBCWNtVtZvJoDh5DVWV7Nu4jn0b11KwYytOhwO90UT3fhn0yBhEfFp/tL5/fWX2ovxFPLb8Mfy1/rw98m2SQ5JpdjhZu7+aRbvKqF+xgrSiQnyIps6YgFD5oHGYiVT20yPFQMLfx6ELj/jL8SWpLbm5uZhMJkJCQmRYHIcQgqqqKhoaGlr7QR10Wl+ZfbJkUHSMrclC3rbN7Nuwlv2bN2BtqEft40Nsn1S69RtIfFp/gqKij/oPMrs6m3sX3Utdcx0vD3uZUV1HHfZ6QbWF5TmV7Fq9mS6bNxBo86fO0AuHxojichBi20/X2CZ6TRhGUL8MuYtKOmF2u53CwkKsVq/4rur19Ho9MTExaDSaw55394xiMXDUgkKIkSdRa6eRQeE+LqeT4j27WmYbG9ZSU1IEtFwxHp82gPi0/sSlpLbONiqbKpm8aDLbK7dzX//7uCXllmN+w3M4XWwtrGP11lyUhfMJrrBj1SZg8W05sG60FhFlKCRxWCyx48ai9pOtQySps7k7KAYc8queluMUjuP1YDpVZFB0ntqyUvK2biJv6yZ0CkumAAAgAElEQVTyd2zFbm1CpVYT3SuZ+LQBdEsfgKlLFM+seoZ5efO4rPtlPD34aXx9fNsct67Jzqo95Rz4ZQHGnbkIEU2DX3eEosbHYSHEsZfoGBu9rxhGYL/BcrYhSZ2g03c9KYqyTghxTrtWdjMZFKeG02GnePcu8rZuInfrptZTb339A4jtnUJeQB3fNP1GZGx33hjxJjGmmBMaVwjBgSoLG1Zup3nBElTVKhp1PWjWBQEts40QTQFx/ULoPWkcPsEnd3qvJEnH5u4ZxaFdrVTAAGCGEKJX+0t0HxkUnmGuqebAts3kb99C/s7tmKsqAWjSuagMdXDekMsZMXQCgZFHH99oixCCnOIadn43H9vmfdhtIdT5dUeoNKiczYQ05xAUWE3X4UkkjBmDSu9//EElSTqKu4Mil5ZjFArgAHJpuTJ7RUcLdQcZFJ4nhKCurJT8rG3s3rKGvdvXo21qec0YHEJMcgrRvZKJTkwmLC7+hNulA7hcgqxte8n9Zh7WAisN6q5Y9S2dNnW2GoKc+zCFWogakUrSBZeg0bW920uSpBbyrCfJoxptjUyd9yS7t60lrSmOsGotlpoaADQ6PZEJiUQnJhPdK4monkn4Gk0nPLbT6WL7r6sonL8Wc7UP9dp47NqW9Q3NZQS4cvENsxE6Io2k80djOomxJels4pagUBTlirZWFkJ8347a3E4GhXcSQvDlri+ZvmE6McYYnk95AkOFneI92RTv2UV53n6EywVAUHQMEd16ENE9gYjuCYTH90BnOLE77Lmam8n+aTl5S7ZQV6OnTt8N5x8H001NBQSI/fiE2tAO6kPsoJEkxEbio1Z12nZL0unCXUHxWRvrCiHEze0pzt1kUHi3jWUbeWTZI9RYa3gw40GuSboGRVGwW62U7ttD8Z5sSvbupmz/XszVVa3rBUV1aQmObj0I75ZAaFxXDP7HP23W0djEvh+XsH/5LqrrjdTr43D9cQ9wo7UYkzMXxdiAPTmWwEHnktwzkZggX3nhlnTWkbueJK9SY61hysopLC1cyojYEbww9IVj3ma1sbaGsty9lO3fS9n+fZTl7m09SA5gCAgkNLYrIbFxhMZ2bfl3TNc2Zx+22noK5q0id81uKmu01Gljcfi0LK+3VRNo34taU05TtB5H33RCEgeSHBtO12ADKpUMD+nM5fagUBTlUqAPLddRACCEeL7dFbqRDIrTgxCC/+36H69vfJ1Q31D+dd6/6Bfe77jrWepqKc/dR2VhPpUFB6gqzKeqIB97859X5RpDQgmO6kJgZBSBkdEERUYTGBlFQEQkGq3usPGcTVZKlm4if/k2SoocVKuisWkDAfBxNBFoy8WXQiyGRipjI3D2zCAyPpk+XQLpGWFE53PiB+IlyZu5+6yn9wEDMAL4GLgSWCeEuKWjhbqDDIrTS1ZlFg8ve5hiczF3pd/FLSm3oFad3IevcLmoryynsuDP8KgtLaamtARrQ/1hy5pCwgiMjMI/NBxTSAimkDBMIaEtj9AwfLQ6qjbtoWDpVkr2VlNt9cesj0QoLTX5NlcS6MhFoy6lxq+Z4ugo7F36EhiTRM/IABIjTHQN8UMtZx/SacbdQbFNCJF6yE8jME8Ica47iu0oGRSnH7PNzPNrnmde7jzSw9KZOmwqcf7uuVOh1WxuCY2yEmpLi6ktafl3Q2UFjTU1COE6bHmN3hdTSCjGoCB8TQEYAgLRqDU0l9RjKarDXOuDWYnEposERYtKgKm5kEBXPmpNBdW+NnYGBFMbkowuujcJkUH0DDfSM8JETJAvGnngXPJS7g6KtUKIQYqirAGuAKqALCGEV9yhRgbF6UkIwS+5vzB17VQcLgcPZTzEVYlXdepBZZfTibmmmoaqShqqKmioqsRcVUlDVSWNtTU0NdRhqauj2dL4l2MoqFDQIBQdqHxRFC0oWnxcTnSiCY3ShFPjoE6rptLHH6shArUpjOAAI6EBfoT76wnz1xPkq0WlVqEoSss2H/JTuFy4nE6E04nL5cLlciKcrpZ/O50tr7ucf/7b6US4nDidzkPWa/n3YQ+X68/XHI7W8Vytzzn/eK8/xgFUKhUqtbrloVKj8jn40wet3heNXo/W1xeN3hetTo/WYMDXPwDDwUdAIL4m/5O6dkY6NdwdFFOAt4FRwL9pufjuIyHE0x0t1B1kUJzeShtLeXrl06wuWc3Q6KE8N+Q5Ivw824LcYbfT1FBHU309lrpaLPV1WM1mbJZGmpss2CwWmhvNmMsraayqwWqxYHc4cAkQiguEk5ZrU08dRVG1BI9ajVrtg6JWH/4hf/CDXq3+47VDPvRbX1eh8vFBpWpZBkAcETgtv7tw2G3YrVbszVZsVit2axNOu/0vazMGh+AfFk5AeAT+YREERkQSEhNHSEwsGp3+mOtJnavTznpSFEUH6IUQde0tzt1kUJz+hBDM2j2L1za8hkat4eGMhxmfMP60O2VVCIF5XwHF6/dStrOIqpJG6mw6LNogXCoFIZwgnOjttRidJfgrZfhoa7HomynRayhSgil2hVJAGHZ9CBGBfkQE+BIZaCAqyI/oIAMRAQYiAg0E++lQa3xaPtxVahSV53dxOR12mi0Wmurraaqvw1Jfi6W+nsbaauoryqmvKKeuvIyG6ko4+NmjKARFRhEaG09oXDzRPXsRlZiEzuDn2Y05C7j9GAXwNTBLCLHPDfW5lQyKM8eB+gM8vfJpNpVvYlDkIJ4Z/Ayx/rGeLqvDHA2NVG7JoSKrkMrcSmqr7NQ7/GjUhiJUPq3L6Ww1GB2l+FOKyacMH18LjUY7eRoNB0QIBSKMwj8eLrUvYSYdkQF6Iv31RPjriQzQtfz01xMZ0PKcXuN9u3ycDjt15eVUFRygIj+PyoI8KvPzqCktaQkQRSEstivRSX3o2jeNrn3T27yRltQ+7g6KrsDVfzxcwCzgGyFEfkcLdQcZFGcWl3Dx7Z5veWPjG9hddu5Ov5vrel+HzyEfqGcKe30DFZv3UplVSHVBDfXVzTQ0a2lUB2HXGP9cULjwtVVhcpZiohyTTzkGfS3C6MBsVFOoMrHHFkyeI4gyEUyJCKYWI6Bg0vsQatQRatQS4qcj1KQl1KgjxKgjzKglxKhrfd2o8/HoLM5mbaIkZzdF2Tsp3rOL4j3Zf7S296FLUm+6pQ+g5zlDCIyM8liNZ5LO3PXUE5gCXCuE8IqvKjIozkxljWVMXTuVxQWLSQ5O5snMJ0kLS/N0WaeEcLkw7y+kKiufqv3l1JWYqat1YLbpsKj9cWgO3y2jdlrxtVfh56rARAUmdTn++kq0pmac/moa9HpKRSCFjkD22wLYZ/WnRARTSQAODpnR+Kj+DBWjjhC/g0GiJdjvz+dCjTqC/bRofTp3d5fT4aB4zy5yN28gd8tGKvPzAIhK6EXSsPPpNfhc/AKDOrWGM1lnXHB36KzCSctuqNc6VKWbyKA4cwkhWJi/kJfXvkxFUwXjE8Zzf//7CfEN8XRpHiMcDiwHiqneU0RtfhX1JfU0VDdjbhQ0OvU0+QS09ro6SBFOdPY6fJ01+Ipq/JQq/NTVmDRVGPwsaANcCJMKs8afChFImcufIruJfJuRXIsfxU5/qvDHxeHBcHC20hIof4SK3yGhYtS2vh5o0Hb4WpP6inKyVy0je9UyKvL2oygquvUbQL+LLqNraj+vOE5zOnH76bGABviGll1O+zteovvIoDjzNdob+WDbB/w367/4+vhyd7+7ubrX1Wfk7qiOctntWA6UUL2niPr8ShoqzDTWNmNpdGFpVmEVeqw+/jh9jj7TSOMwo3PUoxd1+IpafJVaDOpa/Hxq8NPW4muyoQlQ4TT4Uu8TQBVBlIsAih0mCmwmcq1+7LUYqBZGxBGholIgyPBHoPj9GSLBf8xQIgN0RAX4Eh3gi7/v8XeBVRXms3P5YnYsXoClrpagqGjSL7yUPsMvOOGGkmc7dwdFLyHEbrdUdvz3Sgfep6VViAO4Swixrq11ZFCcPfbX7eeVta+wumQ1PYN68lDGQwyJHuLpsk47wmbDUlhKXW459YWVNJQ10FhtxWK202QFq8OHZvTYNCacat0xBnChdZjRO+vQu2rxpQ5fVS0GVQ1+mhr8dPX4+TvQBPlg9/WjQRNMNYGUiwBKnQEU2I0csPqRY/Gj2Kqh5VY3fzJo1UQF6IkK8G35GehLdICeuGADXUP9iPLXt/bhctjt5Kxdyeb5P1GyJxudnx/9LxlH/0suR280Hl271Kozj1H8JIS4rN2VHX/834A3hBDzFEUZAzwihBje1joyKM4uQggW5S/i1Q2vUmQuYnDUYB7IeICk4CRPl3bGcTU3Yy0up6GgAnNpLeayeiw1Fiz1NpoaXVhtClanhmZFT7PGhFBpjhpD5bK1zFKctehFLQZqMahr8FPXYNRWYTSYMQSD2l9Poy6MSnUYxa4Q8hxB7LEGkmU2sadRh0v8OUPR+qiICzYQH2Kga4hfy89QHVTvZP/CeVRty0bRaVAyYrH2C8fm48TmtGF32lEUBb2PHp1ah1FjJMwQRphvGFHGKLr5d8OgOXtmI50ZFJuFEMfv5NZOiqLMBz4VQsxSFOXvwFghxDVtrSOD4uxkc9r4OvtrPtz+IfXN9VzW/TLu6XcP0cZoT5d2VnKazViKK2gorMRcXIu5sgFLdROWBhtNFkGTXY3VpaNZ7XfUwXjgiFlKDX5UY1KVY9JW4K+vwhQG6mA9JboINigGNjoF2a5GSkQDLp8aFE0NitLyeRZUryFtbwDxpX406Vzs7mOjrLsKrY8Wl3DR7GjG6rRitptxHdHSpYuxC4lBiQyIGED/8P4khSShOUYAngncvevJABxs13FfZzYDVBQlGZhPy1xUBQwRQhxoax0ZFGe3els9n2z/hC93fYkQgisTr+TmlJs9fnW3dGzC6cRWXkn9gXLMRVWYy+porLJgqWs5jtJkU7A6tTSpjK13LvxzZRc+jjqEqwa7UoNVU4FLXwr+VWjCLRh8jVhdUeRZY1hXHYur1sGw6jVENZfR4BeOa8iVpKT1JTU2gJ7hJsBFTXMNlU2VFDYUsq92H/vq9pFVmUV+Q8vZ/yaNifNjz2d019EMjR6K/hjHdk5X7rpxkQZ4FbielvtkK0AkMEMI8YqiKOlCiC3tKG7hH+Mc6Ula2oQsFUJ8pyjK34DbhBCjjzHGbcBtAHFxcQMOHGgzS6SzQGljKe9tfY8f9v6AoihM7DmRW/reQqTfsf6vJnmjZmczW8q3sKl8E1vKNpO/P4ugci0R9UFEWSMJtUeicwQinEaaMdGsC2zt8gstB+P9bGX4i1ICVMUEGavwjXSx2+nL7r1mXHY72/xTWB00CL2vgYz4IDK7hzCoewgp0f6H3fmwwlLBxvKNrCxayeKCxdQ11+Gn8ePyHpdzda+r6RHYwxN/IrdyV1DMoKW9+P8TQjT88Zw/MJ2WU2QvFkJ0c0/Jre9ZBwQKIYTSctpDnRDCv6115IxCOlSRuYiPtn3E3L1zURSFCQkTuCnlJmJMMZ4uTTqC0+UkuyabNcVrWFOyhs3lm2l2NqOgkBCUQHpYOv3C+5Eenk6MMeaoM6FsdfXU7Mijak8JNQU11FU2U9+oYBZGmv+4xwiAytmM0ZqLzbGeWlcFerWKmF7hrNf35JeaOKrxx0+rZlD3EEb0CmN4r3Big/88VmF32dlQuoEf9v3A/Lz52F12BkUN4o7UO8iIPO7nrNdyV1DsBXqKIxZSFEUNVAKXCCHWdLTYI8beBdwphFiiKMoo4F9CiAFtrSODQjqWYnMxH2//mNl7Z+MSLkbFjeL63teTFpZ22vWQOpMUNBSwung1a0rWsK50HXXNLW3jEgITGBw9mMyoTNLD0/HXtvn98Liayiqp2LiXsp3FVBU1UFsHdUowNqUOe+OvCFctBnUiXRUtIaYKrJEaFmhi+bmhOzX40zPcyIikcEYmhTMwPrj1GpBqazXf53zPV7u+oqKpgsFRg7m33730Devb4b/NqeauoNgjhEg82dc6QlGUYcBbgA9gpeX02I1trSODQmpLWWMZM7Nn8s2eb2iwNZAamsp1fa5jdNxoeR3GKVBrrWVN6ZrWWUORuQiAcEM4g6MGkxmdSWZUJqG+oZ1ei8vppG5XHvlrstm85jeqGvahUoWhMY5DUfujsZsJte4iVH+A6jCFL1U92ejqQajJlzF9oxibFkW/2CBUKgWrw8qs3bP4ZPsn1DTXMCFhAg8MeIBAfeDxC/ES7gqKOcD3Qogvjnj+H8BVQohxHa7UDWRQSCfCYrcwd99c/rvzvxQ0FBDmG8b4hPFM6DmBWNPp33jQW9icNraUb2F1yWpWFa9iV9UuBAKjxsg5kee0BkO8f7zHZ3Y561fz67/fAAG94s+juVxPuS0Yq6blw15nqyXMlo3eUMLv/gHM9RlASIA/Y9OiuSojloRwIxa7hQ+2fcAXWV9g0pp4aOBDjO0+1uPbdiLcFRRdgO+BJuDgt/oMwBeYIIQockOtHSaDQjoZTpeTZYXL+DbnW1YUrcAlXGRGZTIxcSIjY0eiVWs9XeJpRQjBvtp9rcGwsWwjTY4m1IqatLA0MqMzGRw1mJTQFK+cwdWUFPHDay9RVVjAsL9fT8bYK6jacYC8BZso2l1FuTMSu8aI4nISbMnBpMljpZ+eb/z6069bOFcPjOPSvlEUNO7j+dXPs7ViKxd0vYBnhzzb4d1nnc3dp8eOBPr88etOIcTvHazPrWRQSO1V2ljK7L2zmZ0zm5LGEkwaE6O6juLi+Is5J+qcM/b8+Y6qbKpkbclaVhevZnXxasqbygGI948nMyqTIdFDGBg5EKP29Lgy2m61Mv/9t9i9ejl9R17IqFvuQu3TEmpOp4vCRVvY+9smCiv9MOtaTrv2N+diZDe/+geyKrw/fz+nK9cNjmNB0SxmbJpBpF8kr573qlcfu+i0C+68kQwKqaOcLidrS9byc+7PLMpfhNluJkgXxOiuoxnddTQZERln9Uyj3FLOhtINbCjbwPrS9eTV5wEQoAtgUOQghkQPYXD04NP6YkchBCtn/Y+1s2cRn9afsf/vsWPeA6Mqaz+7Z/3O/kI9ddouIFwEmXOwKgV8GdqTpHPSOL9vIx/vfoEKSwVPD36aCT0neGCLjk8GhSS1U7OzmRVFK/g191eWFi6lydGEwcdAZlQm58acy7Auw87oazNcwsWB+gNsr9zOprJNbCjbwIH6luuUjBoj/cL7MTByIAMjB5IcnIxa5RV3G3Cbbb/PZ+HH/yYsrhsTn3weg3/AXy5bsSWbnV8uZH9VKBZtOGpHE0Hmraw1KJRkDkREfklWzQZuT72du9Pv9rrjFjIoJMkNLHYL60rXsbxwOcuKllHaWAq0nMrZP7w//SP6MyBiwGkdHDXWGrKqsthWsY1tFdvYXrmdels90HJV8oCIAWREZpARmUFSUNIZFwzHkrt5Az+89hIBEZFcNWXqce95IVwuCn+az9Zf9lDg6oVLpcVkzqPOmce8ocUUmNYytvtYnhvyHBq19+zOlEEhSW4mhGBv7V6WFS5jfel6tlRsodHeCEC0XzRp4WkkByfTK6gXvYJ7ed09M+xOO7n1ueyp2fPno3oPFU0VAK0XuaWGppIalkpqaCrdArqdFcFwLPk7tjHnX89jDA7hqqenYgo+sdN3m4oPsO3fs9hVHEOjLhKdtRqbfT0/9F9ITJ9M3rvgTa8JCxkUktTJHC4He2r2sKlsE5vKN7G9cnvrjAMgzDeMhMAE4vzjiDHGEGuKJcYUQxdjF/w0fm7fDeFwOahqqqKyqZIySxmFDYXkN+RT0FBAfn0+JY0lOIUTAI1KQ4/AHiQGJZIYlEhScBIpoSn4HatZ31msKHsn37/yDL7+AUx6dhrG4BMPf2E1s/ez/7BpnZpKXSI+DgtYl7AuvYyXb3+fcJPn/9YyKCTJA2qtteyp2UN2dTa7a3azr3YfBQ0FrbtyDtKqtAT7BhOkC2r9qffRo1e3tL/W+ejQqXW4hAuXcOEUTpwuJ07hpNHeiNlmpsHegNlmxmw3U9lUSVVTFYLD/3s2aUzE+ccRZ4ojxhTTGg7xAfHyjK4TVJKzm/978SkCwsL527Ov4Gs0HX+lQ9ksFP3fp6xfaKVI1x8fuwWlaQXGcRdy9VUjOnzXv46QQSFJXqSuuY5CcyEFDQWUmEuosdZQZa2i2lpNjbWG2uZarA4rzc6W9tcOl+OY46gVNX4aP0xaE0aNEaPWiEljIsQ3pPW+CuGGcMJ8w+hi7EKALsDrDqCejvJ3bOX7V54lvGt3rpzyIlq97/FXOpKtkbLvPuTXhQKzJh0fuxmtZQfnPHgFfTI8cy8VGRSSdBpzuBzYnDZUigq1okalqFApKvmh70F716/hh9dfIrZ3X654/FnUPu2ckTWU8f6nj2HbMRC1OglfSxm+/uWMm3ozhoCTnK100IkGhbwTuSR5IR+VDwaNAb2PHo1ag1qlliHhYQkDM7nojvvI37GVhR+/S7u/ZJsiuH3yp5RcuY0VsR/g0kC1oy/f3fEl6z/4tv3jdiIZFJIkSSeoz/mjyJw4iR2LF7D+h+/aPY6iKDw3egb6AQbeP3c6XbVfYzHGsGGjiTnXvkLjvjz3Fe0GMigkSZJOwpCrrqXX4HNZPvM/5Kxb1e5xtGotb454kwj/SN4YmsOFmd/RxbWJYv9B/N+zy9n86ucIx7GPVZ1qMigkSZJOgqIoXHTX/UT1SOSXt1+jIj+v3WMF6AJ4bfhr1NrqeTlWw5j7ezHSNAOHzsCqvTH8eP3rWLL3uK/4dpJBIUmSdJI0Wh3jHn4KncHAj6+/RLOlsd1jJQUn8cSgJ1hdspqPHGUkP/VvJg74ggTXEgr8M/j2hVUc+HiWR49dyKCQJElqB7/AIC6771Fqy0qZ/95bHfogv6LnFVze43Le2/oeaywFBN0+m+HXhTLKMJ0mQwjz1vqz/M5/Ya+uduMWnDgZFJIkSe0U0zuFc/9+AznrVrHx5zntHkdRFJ4c9CTxAfFMWTkFs8OC7rz76fXA84yLfYFg1z62M5C5d/2XulVr3bgFJ0YGhSRJUgdkjL2ChIGZLPvyM0pydrd7HIPGwItDX6TcUs70DdMBUGIyiHzgZ0b3/4H+6pmUBfRhzru7yf9o5indFSWDQpIkqQMUReGiO+/HGBTCL+9Mx2ZtavdYqWGp3NTnJr7L+Y7lhctbnjSGEXzHzySOMDHGNBWrbzDz1vix9eHXcDU3u2kr2iaDQpIkqYP0fkYuufv/UVtWytIvPunQWHel30VCYALPrnqWuua6lifVGkKufJ2gK25gYvgj6JR6Vjaks/jW6dhKStywBW2TQSFJkuQGsX1SybhsAtt+/5V9G9t/HEGr1vLisBepslbxxsY3DnstcMiN+P7jLSZ0eYoosYlsv8EseGZuR0s/LhkUkiRJbjL06usI69qN+e/PwFJX2+5x+oT04drka/k+53u2V2w/7DW/5AvQ3zqHETEf0Fs9l4aEzu8P5ZGgUBTlKkVRshRFcSmKknHEa48rirJXUZTdiqJc5In6JEmS2sNHo2HMPQ/S3NjI4v981KGx7ky7k1DfUKaunYrT5TzsNV1sOsZ7FpHUZQkD/Np/ttWJ8tSMYgdwBbDs0CcVRekNTAL6ABcD7yqKcnbeXkuSpNNSaFw8gyb8jeyVS9m/aX27xzFqjTyY8SBZVVl8v/f7o17XBHcl8v4l9Lzti46Ue0I8EhRCiF1CiGOdRzYO+FoI0SyEyAX2Auec2uokSZI65pzxVxESE8fCj9/F1mRp9zhjuo0hIyKDtza9RY215qjXFUMQaNpxb4yT5G3HKLoABYf8XvjHc5IkSacNH42GC2+/l4bqSlZ8/d92j3PwQjyzzcy/t/zbjRWenE4LCkVRFiqKsuMYj3FuGv82RVE2KIqyoaKiwh1DSpIkuU10YjL9LrqMzfN/6tCFeAlBCVyZeCXf7fmO/Pp8N1Z44jotKIQQo4UQKcd4tHUuVxEQe8jvMX88d6zxPxRCZAghMsLCwtxZuiRJklsMm3QdxsAgFn32PsLlavc4d6TdgUat4e3Nb7uxuhPnbbuefgAmKYqiUxSlG9ATWOfhmiRJktpF62vgvGtvonRfDjuWLmz3OKG+oVzX+zp+zfuVrKosN1Z4Yjx1euwERVEKgcHAz4qizAcQQmQB3wA7gV+Bu4UQzr8eSZIkybslDRtOdK/eLP/qP1gbze0e56Y+NxGoC+TNjW+6sboT46mznmYLIWKEEDohRIQQ4qJDXpsqhOghhOglhJjnifokSZLcRVEURt50O00N9az+v6/aPY5Ra+Sfff/JmpI1rCpu/5312sPbdj1JkiSdcSK69SB11EVsnv8TVYXtPyA9KWkSUX5RvLvlXdk9VpIk6Uwz9Orr0Oj0LJ/5n3aPoVVruTnlZrZWbGV9afsv5jtZMigkSZJOAYN/AOeMu5J9G9ZSmN3+A9ITek4g1DeUD7d96Mbq2iaDQpIk6RTpP+Zy/IKCWfblZ+3edaRT67ixz42sLV3L1oqtbq7w2GRQSJIknSIanZ4hV11DyZ5s9v7/9u4+xqr6zuP4+8MAw8NgkYdSFVAQpIyiSKcCCiq4oJB2qVY3smlq001sdrfp9g+TunFj6Gb/6SbrJvuQNjbbrNvstvRBUlvTqiiCiIIUkAcBgQW6PMhDERS2Syvz3T/Ob3Qc5t55Yu7vXvm8kpu595xz7/n8/A3z9XfuOb+z/tVuf85919zH0PqhfHdzzyYe7CwXCjOzCrru9nkMu3w0q//rCZrPde/s/0H9BvGFyV9g5YGV7Dix4wInPJ8LhZlZBfWpq2PWnz7AiUMH2Lbq+W5/zuLJi2no11CRUYULhZlZhU1omsGo8RNYu+xHnHvvvW59xiX9L+HRmY/y5SlfvsDpzudCYWZWYZKYee9iTh15i+2rX+z25ywYt4Brh1974djxj2QAAArVSURBVIKV4EJhZpbB+Gk38fFxV7P2yaXd/q6iUlwozMwykMTMzy/m5JHDPRpVVIILhZlZJlc3TWfkVeNZu6y6RxUuFGZmmbR8V/H24UPsXLMqd5ySXCjMzDKa0DSD4aPH8tpTP63oRH9d4UJhZpaRJJo+ew/HfrOP/Zs35o7TLhcKM7PMJs+6jYZLh/Haz5/MHaVdLhRmZpnV9e3HjQv+mN9s2cSRvXtyxzmPC4WZWRW4Yd4C+g8cyPoqHFW4UJiZVYH6QYOZcsdd7HzlJd45djR3nA9xoTAzqxKfWrgISWz41c9zR/kQFwozsyoxZPgIJt50M1tXPMsfzv5f7jjvc6EwM6siU+/6DGfPnGH76pW5o7zPhcLMrIpcMamRkVeOY9Mzv6iaC/CyFApJ90naJqlZUlOr5fMk/VrSlvRzbo58Zma5SGLqnZ/h2P69HNyxLXccIN+IYitwD9B2cpPjwGcjYgrwAPD9SgczM8tt8qzbGDC4gY3PPJ07CpCpUETE9ojY2c7yjRFxKL3cBgyUVF/ZdGZmefWrH8B1c+eze90a3j1xPHecqv6O4vPAhog4295KSQ9KWi9p/bFjxyoczcysd90wbyHNzc1sef6Z3FF6r1BIWi5pazuPRZ1477XAt4CvlNomIh6PiKaIaBo5cuSFjG5mlt3QUZ/gqutvZOuK5TQ3571XRa8Vioj4o4i4rp3Hz8q9T9JoYBnwxYiovklPzMwqZMrc+bz722Ps37wpa46qOvQkaSjwNPBwRLycO4+ZWU5XN01n4JBL2PJC3sNPuU6PvVvSAWAm8LSklv8KXwUmAI9K2pQeH8+R0cwst7q+/Wi87Q72rF/L/546mS1HrrOelkXE6Iioj4hREXFnWv53ETE4Iqa2elTX7FhmZhU0Zc58ms+dY9vK57NlqKpDT2Zm9mHDR4/h8kmNbHnh2WxXartQmJlVuSlz5/P24YPZrtR2oTAzq3KTZsyi/8CBbF2xPMv+XSjMzKpcvwEDmDj9FnateznL9OMuFGZmNaBx9lx+/7vfsWf92orv24XCzKwGjGm8jobhI3jjpRUV37cLhZlZDVCfPkyedTv7Xt9Q8WsqXCjMzGpE4+w5RHMzO9a0vUND73KhMDOrESPGXMnIq8azvcKHn1wozMxqSOPsOby1ZxcnDh2o2D5dKMzMasgnb7kNqQ9vrKrcqMKFwsyshjRcOoyxU25g55pVFZvSw4XCzKzGXDNjFiePHObo3srcsseFwsysxkycfjN96uoqdvaTC4WZWY0Z2DCEK6dM5c1XV1fk8JMLhZlZDZp08628c+woh3ft7PV9uVCYmdWgCZ+eQV3fvux85aVe35cLhZlZDaofNJjr5y3gYyN7/27RfXt9D2Zm1ivmfukrFdmPRxRmZlaWC4WZmZXlQmFmZmVlKRSS7pO0TVKzpKZ21o+VdFrSQznymZnZB3KNKLYC9wClLit8DPhl5eKYmVkpWc56iojtAJLOWyfpc8Be4EyFY5mZWTuq6jsKSQ3AN4Bv5s5iZmaFXhtRSFoOfKKdVY9ExM9KvG0J8I8Rcbq90Uabz38QeBBg7NixPUhqZmblqFLzmbe7c+lF4KGIWJ9evwSMSauHAs3AoxHxLx18zjFgfw+ijACO9+D91eKj0g5wW6qV21KdutuWKyNiZEcbVdWV2RExu+W5pCXA6Y6KRHpfhw0tR9L6iDjv7Kta81FpB7gt1cptqU693ZZcp8feLekAMBN4WtIzOXKYmVnHcp31tAxY1sE2SyqTxszMyqmqs54yejx3gAvko9IOcFuqldtSnXq1LVm/zDYzs+rnEYWZmZV1URcKSXdJ2ilpt6SHc+fpKkn7JG2RtElSyynGwyQ9J2lX+nlp7pztkfQ9SUclbW21rN3sKvxT6qfNkqblS36+Em1ZIulg6ptNkha2WvfXqS07Jd2ZJ/X5JI2RtELSG2kutr9Ky2uuX8q0pRb7ZYCkdZJeT235Zlo+TtLalHmppP5peX16vTutv6rHISLionwAdcAeYDzQH3gdaMydq4tt2AeMaLPs74GH0/OHgW/lzlki+63ANGBrR9mBhRRzfwmYAazNnb8TbVlCcY1Q220b0+9aPTAu/Q7W5W5DynYZMC09HwK8mfLWXL+UaUst9ouAhvS8H7A2/ff+EXB/Wv4d4M/T878AvpOe3w8s7WmGi3lEcROwOyL+OyJ+D/wQWJQ504WwCHgiPX8C+FzGLCVFxCrgRJvFpbIvAv4jCq8CQyVdVpmkHSvRllIWAT+MiLMRsRfYTfG7mF1EHI6IDen5u8B24ApqsF/KtKWUau6XiIjT6WW/9AhgLvCTtLxtv7T010+AO9TRVBcduJgLxRXA/7R6fYDyv0jVKIBnJf06TWkCMCoiDqfnbwGj8kTrllLZa7WvvpoOyXyv1SHAmmhLOlxxI8X/vdZ0v7RpC9Rgv0iqk7QJOAo8RzHiORkR76VNWud9vy1p/SlgeE/2fzEXio+CWRExDVgA/KWkW1uvjGLsWZOntdVy9uTbwNXAVOAw8A9543Rempzzp8DXI+Kd1utqrV/aaUtN9ktEnIuIqcBoipHOJyu5/4u5UBzkg3mloOiAg5mydEtEHEw/j1JcwHgTcKRl+J9+Hs2XsMtKZa+5voqII+kfdzPwXT44jFHVbZHUj+IP639GxJNpcU32S3ttqdV+aRERJ4EVFLNaDJXUctF067zvtyWt/xjw257s92IuFK8BE9OZA/0pvvR5KnOmTpM0WNKQlufAfIobQj0FPJA2ewAoNVNvNSqV/Sngi+ksmxnAqVaHQqpSm2P1d1P0DRRtuT+dmTIOmAisq3S+9qTj2P8GbI+Ix1qtqrl+KdWWGu2XkZKGpucDgXkU37msAO5Nm7Xtl5b+uhd4IY0Euy/3N/o5HxRnbbxJcbzvkdx5uph9PMVZGq8D21ryUxyLfB7YBSwHhuXOWiL/DyiG/n+gOL76Z6WyU5z18a+pn7YATbnzd6It309ZN6d/uJe12v6R1JadwILc+VvlmkVxWGkzsCk9FtZiv5RpSy32y/XAxpR5K8WM2i1/A9ZRfPH+Y6A+LR+QXu9O68f3NIOvzDYzs7Iu5kNPZmbWCS4UZmZWlguFmZmV5UJhZmZluVCYmVlZLhRmXSTpkTSL5+Y0A+l0SV+XNKgT7+3UdmbVxKfHmnWBpJnAY8DtEXFW0giK2YfXUFxHcLyD9+/rzHZm1cQjCrOuuQw4HhFnAdIf/HuBy4EVklYASPq2pPVt7h/wtXa2my/pFUkbJP04zU1kVlU8ojDrgvSHfDUwiOIq5aURsbLtSEHSsIg4IamO4qrmr0XE5tbbpdHIkxRXAZ+R9A2Kq2v/NkPTzErq2/EmZtYiIk5L+hQwG5gDLFX7d0f8kzT1e1+KUUgjxRQMrc1Iy19OtwvoD7zSW9nNusuFwqyLIuIc8CLwoqQtfDABG1DcohJ4CPh0RLwt6d8p5t9pS8BzEbG4dxOb9Yy/ozDrAkmTJE1stWgqsB94l+KWmwCXAGeAU5JGUdwvpEXr7V4FbpE0IX32YEnX9GZ+s+7wiMKsaxqAf07TPr9HMUPng8Bi4FeSDkXEHEkbgR0Udxp7udX7H2+z3ZeAH0iqT+v/hmJGY7Oq4S+zzcysLB96MjOzslwozMysLBcKMzMry4XCzMzKcqEwM7OyXCjMzKwsFwozMyvLhcLMzMr6f1MLB5dufy1kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(10, 12))\n",
    "\n",
    "q_values = np.array([estimator_2.predict(s) for s in xs])\n",
    "\n",
    "for i in range(actions):\n",
    "    plt.plot(q_values[:, i], label='Action '+str(i))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Q-value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing time taken to use a heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011689195871353151\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "heuristic = jw_2\n",
    "directory = '../Tests/SATLIB_20/'\n",
    "files = os.listdir(directory)\n",
    "files = list(map(lambda x: os.path.join(directory, x), files))\n",
    "\n",
    "split = int(len(files) * 0.1)\n",
    "training_files = files[:split]\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for file in training_files:\n",
    "    env = Env(file)\n",
    "    env.reset()\n",
    "    a, b, c = env.state\n",
    "    \n",
    "    s = time.time()\n",
    "    for _ in range(1000):\n",
    "        heuristic(a, b)\n",
    "    e = time.time()\n",
    "    total_time += (e - s) / 1000\n",
    "    \n",
    "print(total_time / split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{0: 'maxo', 1: 'moms', 2: 'mams', 3: 'jw', 4: 'jw_2', 5: 'bohm'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
